\documentclass[10pd,hyperref={colorlinks=true}]{beamer}
\usepackage{multimedia}
\usepackage{amsfonts,amssymb,amsthm,amsmath}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{color}
\usepackage{beamerthemesplit}
\usepackage{lmodern}
\usepackage{color,epsfig,bm}
\usepackage{amsmath}
\usepackage{multicol}

\usepackage[spanish]{babel}
\selectlanguage{spanish}

\usepackage{pict2e}

\usepackage{pstricks-add}
\usepackage{pst-solides3d}
\usepackage{pst-3dplot}
%\usepackage{pst-vue3d}
\usepackage{pst-grad}
\usepackage{pst-func}
\usepackage{pst-coil}
\usepackage[T1]{fontenc}

\usepackage{calculator}

%-------------------------------------------------------------------

\setbeamercovered{dynamic}
\mode<presentation>
{
%\usetheme{Berkeley}
%\usetheme{Boadilla}
\usetheme{AnnArbor}
\setbeamercovered{transparent}
}
\usecolortheme{dolphin}
\setbeamertemplate{footline}[page number]

\definecolor{darkblue}{rgb}{0.0,0.0,0.6}
\definecolor{mybrawn}{rgb}{0.3,0.5,0.0}
\definecolor{mygrey}{rgb}{0.4,0.3,0.3}
\definecolor{refcol}{rgb}{0.8,0.6,0.6}
\usefonttheme{structuresmallcapsserif}
\newcommand\bfttcol[1]{\bf\tt\textcolor{darkblue}{#1}}
\newcommand\ttxt[1]{\textcolor{mybrawn}{#1}}
\setbeamercolor{normal text}{fg=mygrey}

\let\oldAA\AA
\renewcommand{\AA}{\text{\normalfont\oldAA}}

\newtheorem{definicion}{\it Definici\'on}[section]
\newtheorem{teorema}{Teorema}[section]
\newtheorem{ejemplo}{\it Ejemplo}[section]
\newtheorem{ejercicio}{\it Ejercicio}[section]
\newtheorem{lema}{\it Lema}[section]

%-------------------------------------------------------------------

\parindent=0pt
\centerline{\bf Curso 
Inteligencia Artificial Cl\'asica y Cu\'antica}
\centerline{Nodos de Inovaci\'on Especializados. Ruta N. Medell\'{\i}n, 
Colombia}
\vfill
\title{\bf ?`C\'omo Funciona la ``Inteligencia Artificial''?}
\vfill
\author[] %
{\scriptsize Jorge~Mahecha~G\'omez\inst{}
\vspace{-0.5cm}}
\institute{
\it Grupo de F\'{\i}sica At\'omica y Molecular\\
\it Instituto de F\'{\i}sica, Universidad de Antioquia\\
Medell\'{\i}n, Colombia\\
\texttt{jorge.mahecha@udea.edu.co}}
\date[Medell\'{\i}n] %

% height=2.5cm

\titlegraphic{
%\includegraphics[width=2.cm]{LogoMinciencias.png}\hspace{1cm}
%\includegraphics[width=2.cm]{LogoRutaN.png}\hspace{1cm}
\includegraphics[height=1.cm]{LogosVarios.png}\hspace{-0.15cm}
\includegraphics[height=.9cm]{LogoUdeA.png}
%\includegraphics[height=1.cm]{LogoUAntioquia.png}
%\includegraphics[width=2.cm]{LogoUNacional.png}
}

\date{\scriptsize Agosto 31, 2023}

\vfill

%-------------------------------------------------------------------

\AtBeginSubsection[]
 {
  \begin{frame}<beamer>{Outline}
    \tableofcontents[current¬section,currentsubsection]
  \end{frame}
 }

\setbeamertemplate{background canvas}[vertical
shading][bottom=red!20,top=yellow!30]

%-------------------------------------------------------------------

\begin{document}

%-------------------------------------------------------------------

\begin{frame}
 \titlepage
\end{frame}

%-------------------------------------------------------------------

\begin{frame}{Resumen}

\vfill

La llamada {\bf ``inteligencia artificial''} (IA), es un campo 
interdisciplinario que involucra la estad\'{\i}stica, problemas 
matem\'aticos de optimizaci\'on, las ciencias de la computaci\'on, 
algunas ramas de la ingenier\'{\i}a, ciencias de la cognici\'on y el 
lenguaje, y ramas de la filosof\'{\i}a tales como la l\'ogica y la 
epistemolog\'{\i}a. Consta de diferentes m\'etodos para realizar 
inferencias a partir de ciertos datos, la m\'aquina debe ``aprender'' de 
los datos de entrada y luego ``tomar decisiones''. Puede decirse que la 
IA se implementa con ayuda de los m\'etodos del aprendizaje autom\'atico 
(AA) o machine learning (ML).

Se presentan los conceptos b\'asicos del aprendizaje autom\'atico. Se 
comentan los m\'etodos llamados {\bf Redes Neuronales}, con \'enfasis en 
las redes neuronales de muchas capas. Se ilustra lo anterior con algunos 
ejemplos. Se comentan algunos paquetes de redes neuronales como el 
Pytorch y se ilustra su uso con algunos ejemplos, entre ellos el 
reconocimiento de im\'agenes.

\vfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Computaci\'on}

La computaci\'on digital se basa en la idea de utilizar m\'aquinas 
universales que pueden resolver cualquier problema l\'ogico o 
matem\'atico. Una de esas m\'aquinas es {\bf la m\'aquina universal de 
Turing.} Otro tipo de m\'aquina que utiliza {\bf los circuitos 
digitales} se basa en puertas l\'ogicas, con las \'unicas puertas 
l\'ogicas de un bit, la identidad y la NOT. Adem\'as, existen muchas 
puertas l\'ogicas de dos bits, incluidas AND, OR, NAND, NOR, XOR y XNOR. 
Estas puertas l\'ogicas se implementan utilizando dispositivos 
electr\'onicos como transistores y diodos, y \'opticos. elementos. Su 
escalabilidad permite la implementaci\'on de l\'ogica y de funciones de 
complejidad arbitraria. Se ha demostrado que AND, OR, NOT y COPY forman 
un conjunto de puertas universales que se pueden utilizar para computar 
cualquier funci\'on booleana.

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{Componentes de la M\'aquina de Turing}

\vfill

Una {\bf Cinta} dividida en celdas. Cada celda puede contener un 
s\'{\i}mbolo perteneciente a un alfabeto.

Una {\bf Cabeza} ubicada frente a la cinta que se puede mover a la 
izquierda o la derecha y sirve para leer los s\'{\i}mbolos grabados en 
la cinta.

Un {\bf Registro de Estados} que almacena el estado de la m\'aquina.

Una {\bf Tabla de Instrucciones}, que contiene instrucciones 
predeterminadas dependientes del Estado de la m\'aquina y del valor de 
la celda ubicada al frente, una de las cuales se ejecuta dependiendo de 
dicho estado y del valor de la celda.

Ejemplos de instrucciones son escribir un s\'{\i}mbolo en la celda, 
mover la cabeza a la derecha o a la izquierda, permanecer al frente de 
la misma celda, ctc.

Una m\'aquina de Turing tiene 7 caracter\'{\i}sticas: Un conjunto finito 
y no vac\'{\i}o de estados; un conjunto finito y no vac\'{\i}o de 
s\'{\i}mbolos; el s\'{\i}mbolo en blanco; la funci\'on de transici\'on 
(L o desplazamiento a la izquierda, R o desplazamiento a la derecha, N o 
no desplazamiento); el estado inicial; el conjunto de estados finales o 
aceptables; el conjunto de instrucciones.

\vfill

\end{frame}

%-------------------------------------------------------------------

\begin{frame}

 \vfill
 \centerline{\psfig{figure=LibroIvanCastro.png,height=0.9\vsize}}

 \vfill

\end{frame}

%-------------------------------------------------------------------

\begin{frame}

 \vfill
 \centerline{\psfig{figure=MaquinaDePost.png,height=0.9\vsize}}

 \vfill

\end{frame}

%-------------------------------------------------------------------

\begin{frame}

 \vfill
 \centerline{\psfig{figure=PostTuring.png,height=0.9\vsize}}

 \vfill

\end{frame}

%-------------------------------------------------------------------

\begin{frame}

 \vfill
 \centerline{\psfig{figure=MaquinaDeTuring.png,height=0.9\vsize}}

 \centerline{\tiny Imagen de Google}
 \vfill

\end{frame}

%-------------------------------------------------------------------

\begin{frame}

\vfill

ChatGPT

\vfill

Please state the differences between a Post machine and a Turing 
machine.

\vfill

Please cite some references about physical implementations of a Post 
machine or a Turing machine.

\vfill

The ``Game of Life'' can be simulated in a Turing machine, or viceversa?

\vfill

A Neural Network can simulate a Turing machine and viceversa?

\vfill

Beginner’s Guide to Universal Approximation Theorem. Khushee 
Upadhyay. 2021. 
\url{https://www.analyticsvidhya.com/blog/2021/06/beginners-guide-to-universal-approximation-theorem/}

\vfill

\end{frame}

%-------------------------------------------------------------------

\begin{frame}{Puertas L\'ogicas}

\vfill

Dos modelos equivalentes para cualquier computador: M\'aquina de 
Turing. Modelo de circuito.

Un circuito est\'a formado por puertas y conexiones entre puertas. 
Las ``Conexiones'' transportan informaci\'on y las ``Puertas'' 
transforman la informaci\'on.

Ejemplos de puertas de un bit ($f:\{0,1\}\rightarrow\{0,1\}$) son 
la \textit{Identidad\/} (llamada tambi\'en puerta de Buffer), y la 
\textit{NOT\/}.

\hspace{2cm}
\begin{tabular}{|c|c|}
\multicolumn{2}{c}{Puerta Identidad}\\
\hline a & a\\
\hline 0 & 0 \\
1 & 1 \\
\hline
\end{tabular}
\hfill
\begin{tabular}{|c|c|}
\multicolumn{2}{c}{Puerta NOT}\\
\hline a & a'\\
\hline 0 & 1 \\
1 & 0 \\
\hline
\end{tabular}
\hspace{2cm}

\vfill

Relaci\'on entre l\'ogica y aritm\'etica: NOT(a) = a' = 1 - a

\vfill

\end{frame}

%-------------------------------------------------------------------

\begin{frame}

\vfill

Ejemplos de puertas de 2 Bits ($f:\{0,1\}^2\rightarrow\{0,1\}$) 
son \textit{OR\/}, \textit{XOR\/} (OR exclusivo), \textit{NAND\/} 
(AND negado) and \textit{NOR\/} (OR negado). Esas puertas tienen 2 
bits de entrada y 1 bit de salida. Por lo tanto son no 
invertibles.

\vfill
$$
\epsfig{file=LogicGates.eps,width=0.7\textwidth}
$$
\vfill

Relaci\'on entre l\'ogica y aritm\'etica:

\begin{tabular}{cc}
a AND b = a$\wedge$b = ab, & a OR b = a$\vee$b = a + b - ab, \\
a XOR b = a$\oplus$b = a + b, & a NAND b= a$\uparrow$b = (a$\wedge$b)' = (ab)' = 1 - ab, \\
\multicolumn{2}{c}{a NOR b= a$\downarrow$b = (a$\vee$b)' = (a + b - ab)' = 1 - a - b + ab}
\end{tabular}

\vfill

\end{frame}

%-------------------------------------------------------------------

\begin{frame}{Redes Neuronales}
 \vfill

 {\bf El perceptr\'on.} La neurona $\Sigma$ tiene 
 entradas de intensidad $x_i$ a trav\'es de enlaces 
 que tienen peso $w_i$. La suma de todas las entradas 
 vale $z$. Se muestra la ``funci\'on de activaci\'on'' 
 y la salida \'unica (binaria) $o$.

 \vfill
 \centerline{\psfig{figure=ElPerceptron.png,width=\hsize}}

 \centerline{\tiny Imagen de Google}
 \vfill

\end{frame}

%-------------------------------------------------------------------

\begin{frame}{Redes Neuronales Biol\'ogicas}
 \vfill

El perceptr\'on es una caricatura de una neurona 
biol\'ogica (llamada regla de Hebb, 1949). A trav\'es 
de las {\bf dendritas} la neurona recibe ``impulsos 
el\'ectricos''. Se dice que cuando la suma de tales 
impulsos supera cierto valor umbral, la neurona 
produce ``impulsos el\'ectricos'' que salen a trav\'es 
de su {\bf ax\'on}, el cual se conecta a las dendritas 
de otras neuronas.

 \vfill
 \centerline{\psfig{figure=NeuronaBiologica.png,width=0.7\hsize}}

 \centerline{\tiny Imagen de Google}
 \vfill

\end{frame}

%-------------------------------------------------------------------

\begin{frame}{Preguntas a ChatGPT}
 \vfill

1. En una neurona biol\'ogica se identifican las dendritas, el n\'ucleo 
y el ax\'on. Se dice que cada dendrita aporta cierto ``potencial 
el\'ectrico'' con un peso determinado como entrada al n\'ucleo, en donde 
se realiza una suma de todas las contribuciones; si dicha suma supera 
cierto valor umbral entonces se emite una señal el\'ectrica por el 
ax\'on. Esta descripci\'on es usada para definir las llamadas ``redes 
neuronales'' de las ciencias de datos. ¿En la actualidad se considera 
v\'alida esta descripci\'on del funcionamiento de las neuronas 
biol\'ogicas, o hay descripciones alternativas? ¿Hay soporte 
experimental de este modelo?

2. Dices que ``la realidad biol\'ogica es mucho m\'as compleja y sutil 
que esta simplificaci\'on.'' ¿Podr\'{\i}as dar algunos de los detalles 
de dicha complejidad que hacen incompleto el modelo de ``redes 
neuronales'' para describir las redes neuronales biol\'ogicas?

 \vfill

\end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Perceptr\'on y Funci\'on de 
 Activaci\'on Sigmoide}

 \vfill
 \centerline{\psfig{figure=Perceptron.eps,height=0.4\hsize,width=0.5\hsize}\psfig{figure=Sigmoide.eps,height=0.4\hsize,width=0.5\hsize}}

 \centerline{Perceptr\'on de una sola capa. \hfill Sigmoide\hfill}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

 \section{}
 \begin{frame}{Regresi\'on Log\'{\i}stica}

Se define
 $$
 h_{\bm{w}}(\bm{x}) = f(\bm{w}\cdot\bm{x}),
 $$
 donde $f(z)$ es la funci\'on de activaci\'on 
log\'{\i}stica [$1/(1+e^{-x})$] y $\bm{x}$ y $\bm{w}$ son 
vectores de dimensi\'on $D+1$, con $x_0=1$,
 $$
 \bm{w}\cdot\bm{x} = w_0 + \sum\limits_{i=1}^Dw_ix_i.
 $$

El problema de regresi\'on consiste en ajustar 
$\bm{w}$ conociendo $N$ series de datos $\bm{x} = 
\{1,x_1,...x_D\}$. Una manera simple es usar el ajuste 
de {\bf m\'{\i}nimos cuadrados.} Otra es maximizar una 
funci\'on de \textbf{plausibilidad}. Llamamos $x_i$ a 
las componentes del vector $\bm{x}$ y 
$\bm{x}_\lambda$, con $\lambda=1,...N$ las N 
realizaciones del mismo.

Suponemos que a la entrada $\bm{x}_\lambda$ le 
corresponde una salida del perceptr\'on $y_\lambda$, 
la cual puede ser $y=0$ o $y=1$ (perceptr\'on 
binario).

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{Un ``Perceptr\'on'' que Produce la 
Puerta NOT}

La entrada es $x$ y la salida $y$, binarias. La salida 
deseable es el NOT de la entrada. Es decir, que si 
$x=0$ entonces $y=1$ y si $x=1$ entonces $y=0$.

Si se hace $w=1$, entonces $s=x$. Si se toma como 
funci\'on de activaci\'on la \texttt{identidad} 
entonces $f(s)=s$. Resulta as\'{\i} la puerta l\'ogica 
identidad. Sin embargo, si se suma cierta cantidad 
$b$, llamada en ingl\'es ``\textit{bias}'' (que 
se puede traducir como ``sesgo'', ``polarizaci\'on'' o 
``desplazamiento''), puede lograrse la puerta l\'ogica 
NOT. $ s = w\cdot x + b,\ y= f(s). $ Tomando 
$f=Id$, $w=1$, $b=1$ se obtiene $f(s)=w\cdot x + 
b=1\cdot x+1=x+1$, lo cual, con suma en la base 
binaria, da $0+1=1$ y $1+1=0$.

\vspace{0.2cm}
\setlength{\unitlength}{1.5mm}
\thicklines
\hspace{3.5cm}
\begin{picture}(40,1)(0,0)
\put(2,0){\vector(1,0){36}}
\put(0,0){\circle{4}}
\put(40,0){\circle{4}}
\put(-0.7,-0.5){$\bm{x}$}
\put(39.3,-0.5){$\bm{y}$}
\put(20,1){$\bm{w}$}
\put(40,-5){\vector(0,1){3.4}}
\put(39.5,-7.5){$\bm{b}$}
\end{picture}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{``Deep Learning'' o Aprendizaje Profundo}

 \vfill

Preguntar a Bard: Explique el deep learning o 
aprendizaje profundo.

 \vfill
 \centerline{\psfig{figure=ImagenDeGoogle.eps,width=\hsize}}

 \centerline{\tiny Imagen de Google}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{El M\'etodo de los M\'{\i}nimos Cuadrados}

La \textit{media aritm\'etica} o \textit{valor medio aritm\'etico} se 
define mediante la relaci\'on

$$
\bar {x}={1\over n}\,\sum_{i=1}^n\ x_i.
$$

La \textit{desviaci\'on est\'andar} es una funci\'on de las desviaciones 
que sirve de indicador de la dispersi\'on. Se define como

$$
\sigma=\sqrt{\,{1\over {n-1}}\,\sum_{i=1}^n\ (x_i-\bar
{x})^2}.
$$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

\begin{table}
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
$R\,(\Omega )$  &$I\,(A)$       &$\Delta\,I\,(A)$       &$1/I\,(A^{-1})$        &$(1/I^2)\,\Delta\,I\ (A^{-1})$ \\ \hline \firsthline
2               & 0.9           & 0.06                  &  1.11                 & 0.07  \\ \hline
3               & 0.6           & 0.03                  &  1.67                 & 0.09  \\ \hline
4               & 0.5           & 0.08                  &  2.0                  & 0.3   \\ \hline
5               & 0.4           & 0.06                  &  2.5                  & 0.4   \\ \hline
6               & 0.3           & 0.06                  &  3.3                  & 0.7   \\ \hline
7               & 0.3           & 0.06                  &  3.3                  & 0.7   \\ \hline
8               & 0.2           & 0.08                  &  5                    & 2     \\ \hline
9               & 0.2           & 0.08                  &  5                    & 2     \\ \lasthline
\end{tabular}
\centerline{Datos de las medidas de corriente y resistencia en un 
circuito el\'ectrico.}
\end{table}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 \vfill
 \centerline{\psfig{figure=GraficaCorrienteResistencia.png,width=0.9\hsize}}
 \centerline{}
 \vfill

{Gr\'afica de $1/I$ contra $R$ elaborada con los datos de la tabla 
anterior. Las l\'{\i}neas verticales alrededor de cada punto representan 
el error en $1/I$. El cambio de variable, $1/I$ en vez de $I$, llev\'o a 
la no uniformidad del margen de error.}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

A la l\'{\i}nea recta de la figura anterior le corresponde una 
ecuaci\'on de la forma:

$$
y = m\cdot x + b,
$$

en donde ``$y$'' es la variable dependiente, $1/I$ en este caso, ``$x$'' 
es la variable independiente, $R$ en este caso, ``$m$'' es la {\bf 
pendiente} y ``$b$'' es el {\bf intercepto} de la recta con el eje $y$.

En los estudios de los datos se acostumbra escribir dicha recta en la 
forma

$$
y = w\cdot x + b,
$$

donde a ``$w$'' lo llaman el {\bf peso} (weight) y a ``$b$'' el {\bf 
sesgo} (bias).

Sin embargo, se pueden definir 2 vectores bidimensionales, el vector de 
``puntos'' ${\bm x}=\{x,1\}$ y el vector de ``pesos'' ${\bm w}=\{m,b\}$, 
con lo cual

$$
y = {\bm w}\cdot{\bm x}.
$$

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{Rectas de la Forma $mx-y+b=0$}

\vspace{1.0cm}
\setlength{\unitlength}{1.5mm}
\thicklines
\hspace{3.5cm}
\begin{picture}(40,40)(0,0)
\put(0,0){\vector(0,1){40}}
\put(0,0){\vector(1,0){40}}
\put(-10,0){\line(1,1){30}}
\put(-10,15){\line(1,1){30}}
\put(-10,35){\line(1,-1){30}}
\put(42,0){$x$}
\put(0,42){$y$}
\put(-3,24){$b$}
\put(-3,10){$b'$}
\put(4,22){$d$}
\put(-0.5,24.3){\color{red}$\bullet$}
\put(-0.5,9.5){\color{red}$\bullet$}
\put(15,38){$y=mx+b$}
\put(15,22){$y=mx+b'$}
\put(15,3){$y=\displaystyle-\frac{1}{m}x+b$}
\put(31,40){La distancia vale}
\put(31,35){$\displaystyle d = \frac{\vert b-b'\vert}{\sqrt{1+m^2}}$,}
\put(31,30){es m\'axima si $m=0$,}
\put(31,25){rectas paralelas.}
\put(31,20){Generalizaci\'on:}
\put(31,15){$\displaystyle d = \frac{\vert w_0-w_0'\vert}{\vert\bm{w}\vert}$.}
\put(31,10){$\bm{w}=m\bm{\hat{x}}-1\bm{\hat{y}}$, $w_0=b$.}
\end{picture}

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{La Recta \'Optima}

 \vfill
 \centerline{\psfig{figure=RectaOptima.png,width=0.85\hsize}}
 \vfill

{Gr\'afica de $1/I$ contra $R$ elaborada con las datos de la tabla, de 
acuerdo a la teor\'{\i}a de m\'{\i}nimos cuadrados. N\'otense las dos 
l\'{\i}neas l\'{\i}mites entre las cuales deben estar todos los datos, 
determinadas por las barras de error.}

 \vfill

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{La Soluci\'on Obtenida Aplicando el LSM}

Las variables de ese ejemplo est\'an relacionadas por la ecuaci\'on de 
la l\'{\i}nea recta, $y= m\cdot x + b$. Si se conocen los par\'ametros 
$m$ y $b$ (pendiente e intercepto con el eje de las ordenadas), podemos 
trazar f\'acilmente la recta. Como se espera una \'unica recta 
experimental, los datos experimentales han de dar lugar a valores 
\'unicos de $m$ y $b$. Para hallar por el m\'etodo de los m\'{\i}nimos 
cuadrados tales par\'ametros es necesario calcular la suma de los 
cuadrados de las desviaciones verticales de los puntos experimentales 
respecto a la recta buscada y luego minimizar tal suma respecto a los 
par\'ametros $m$ y $b$.

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{}

Consideremos que $(x_i, y_i)$, $i= 1, 2, 3, ... n$, son las $n$ parejas 
de datos obtenidos experimentalmente. Se quiere encontrar la recta 
\'optima, cuya coordenada vertical $y$ es una funci\'on de $x$ dada por 
$y = m x + b$. Se deben encontrar {\bf valores \'optimos} de $a$ y $b$. 
Para ello se define la ``funci\'on de costo''

$$
Q = \sum\limits_{i=1}^n\left[y_i - (mx_i + b)\right]^2 = 
\sum\limits_{i=1}^n(y_i^2 + m^2x_i^2 + b^2 - 2 mx_iy_i -2 by_i + 2 mbx_i)
$$

y se requiere que los par\'ametros $a$ y $b$ sean tales que $Q$ sea 
m\'{\i}nimo,

$$
\frac{\partial Q}{\partial m} = 0, \quad
\frac{\partial Q}{\partial b} = 0.
$$

Si se define un vector bidimensional $\bm{u}$ con componentes $m$ y $b$, 
la minimizaci\'on de la funci\'on de costo se puede escribir en 
t\'erminos del {\bf gradiente} respecto al vector $\bm{u}$,

$$
\bm{\nabla}_{\bm{u}} Q = \bm{0}.
$$

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{}

Expl\'{\i}citamente,

$$
\sum\limits_{i=1}^n(2mx_i^2 - 2 x_iy_i + 2 bx_i) = 0,\quad
\sum\limits_{i=1}^n(2 b -2 y_i + 2 mx_i) = 0.
$$

Estas dos ecuaciones se pueden escribir como

$$
m\sum\limits_{i=1}^n2x_i^2 + b \sum\limits_{i=1}^n 2 x_i = 
\sum\limits_{i=1}^n 2 x_iy_i,\quad
m\sum\limits_{i=1}^n 2 x_i + b \sum\limits_{i=1}^n2 =
\sum\limits_{i=1}^n2 y_i,
$$

lo cual se expresa como un sistema algebraico de 2 ecuaciones lineales 
con 2 inc\'ognitas,

$$
\left(\begin{array}{cc}
2\sum\limits_{i=1}^nx_i^2 & 2\sum\limits_{i=1}^n x_i \\
2\sum\limits_{i=1}^n x_i & 2n
\end{array}\right)
\left(\begin{array}{c}
m \\ \\
b
\end{array}\right) =
\left(\begin{array}{c}
2\sum\limits_{i=1}^n x_iy_i \\
2\sum\limits_{i=1}^n y_i
\end{array}\right).
$$

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{}

$$
\left(\begin{array}{cc}
2n\overline{\mathstrut x^2}\ & 2n\overline{\mathstrut x} \\
2n\overline{\mathstrut x} & 2n
\end{array}\right)
\left(\begin{array}{c}
m \\
b
\end{array}\right) =
\left(\begin{array}{c}
2n\overline{\mathstrut x\cdot y} \\
2n\overline{\mathstrut y}
\end{array}\right).
$$

$n$ es el n\'umero de puntos de la gr\'afica, $(\overline{\mathstrut 
x},\overline{\mathstrut y})$ es la coordenada del ``centro de gravedad'' 
del conjunto de datos y \raisebox{1.5ex}{\_} denota la media 
aritm\'etica.

Con ayuda del determinante de la matriz $2\times2$ se calcula la inversa 
y luego se halla la siguiente soluci\'on para las inc\'ognitas $m$ y 
$b$.

$$
m = {{\overline{\mathstrut x\cdot y}- \overline{\mathstrut x}\ 
\overline{\mathstrut y}}\over {\overline{\mathstrut x^2}- 
\overline{\mathstrut x}^2}},\quad
b = {{\overline{\mathstrut y}\ \overline{\mathstrut x^2} - 
\overline{\mathstrut x}\ \overline{\mathstrut x\cdot y}}\over 
{\overline{\mathstrut x^2}- \overline{\mathstrut x}^2}}
= \overline{\mathstrut y}-m\ \overline{\mathstrut x}.
$$

Los errores de estas cantidades se calculan mediante las f\'ormulas 
siguientes:

$$
s_m^2 =\left\vert {{\overline{\mathstrut y^2}+m^2\ \overline{\mathstrut 
x^2}+b^2- 2 m\ \overline{\mathstrut x\cdot y}-2\ b\ \overline{\mathstrut 
y}+2\ m\ b\ \overline{\mathstrut x}}\over {(n-2)\,(\overline{\mathstrut 
x^2}- \overline{\mathstrut x}^2)}}\right\vert,
$$
$$
s_b^2 =s_m^2\cdot \overline{\mathstrut x^2}.
$$

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{}

En la siguiente tabla est\'an transcritos los datos del experimento, 
llamando $x_i$ a los valores de la resistencia y $y_i$ a los inversos de 
las corrientes.

\begin{table}
\centering
\begin{tabular}{c|c@{\quad}|@{\quad}c@{\quad}|@{\quad}c@{\quad}|@{\quad}c@{\quad}|@{\quad}c@{\quad}|c|}\cline{2-7}
        &$x_i$  &$y_i$  &$x_i^2$        &$y_i^2$        &$x_i\cdot y_i$ &               \\ \cline{2-6}
        &2      &1.1    &4              &1.2            &2.2            &$n = 8$        \\ \cline{2-6}
        &3      &1.7    &9              &2.9            &5.1            &               \\ \cline{2-6}
        &4      &2.0    &16             &4              &8.0            &$\overline{\mathstrut x} = 5.5\qquad\overline{\mathstrut y}=3.0$\\\cline{2-6}
        &5      &2.5    &25             &6.2            &12.5           &               \\ \cline{2-6}
        &6      &3.3    &36             &10.9           &19.8           &$\overline{\mathstrut x \cdot y} = 19.5 $\\ \cline{2-6}
        &7      &3.3    &49             &10.9           &23.1           &               \\ \cline{2-6}
        &8      &5.0    &64             &25             &40.0           &$\overline{\mathstrut y^2} = 10.8$\\ \cline{2-6}
        &9      &5.0    &81             &25             &45.0           &               \\ \cline{1-6}
\hspace{-0.24cm}\vline
\,SUMA  &44     &23.9   &284            &86.1           &155.7          &$\overline{\mathstrut x^2} = 35.5$\\
\lasthline
\end{tabular}
\end{table}
Datos para el c\'alculo de la pendiente y el intercepto 
usando las f\'ormulas del m\'etodo de m\'{\i}nimos cuadrados.

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{}

Cuando se reemplazan los valores apropiados de esta tabla, se obtiene
{
\color{red}
$$
m=0.6\ (A^{-1}\cdot \Omega ^{-1})\qquad y \qquad b=-0.2\
(A^{-1}).
$$
}
\hskip-0.3em
Estos valores definen la recta \'optima $y=0.6\cdot x - 0.2$.

F\'{\i}sicamente se espera que el valor del par\'ametro $b$ sea cero 
(corriente infinita cuando la resistencia es cero), pero el c\'alculo da 
$b=-0.2$. No podemos imponer que la recta trazada pase por el punto 
$(0,0)$, el cual tampoco puede considerarse como punto experimental 
porque no es posible medir una corriente infinita. Respecto al hecho de 
no pasar la curva por el origen s\'olo nos quedar\'{\i}a evaluar el 
error en el c\'alculo de $b$ y verificar si se cumple o no que $$ 
b-s_b\le \ 0\ \le b+s_b. $$ Reemplazando en las f\'ormulas 
correspondientes los valores requeridos, que se obtienen de la tabla, 
obtenemos {\color{red}$s_m=0.1$, $s_b=0.3$}, y por lo tanto $-0.2-0.3\le 
0 \le -0.2+0.3$, con lo cual concluimos que el valor $b=-0.2$ 
efectivamente es atribuible a los errores experimentales, y no a una 
discrepancia respecto a la {\bf ley de Ohm}.

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{La L\'{\i}nea de Regresi\'on}

 \vfill

Si cada punto rojo representara una masa de igual magnitud, la 
l\'{\i}nea azul fuera una varilla r\'{\i}gida, cada masa estuviera unida 
a la varilla azul con una varillita perpendicular sin masa, y el campo 
de gravedad actuara perpendicular al plano de la gr\'afica, el sistema 
quedar\'{\i}a est\'atico si la l\'{\i}nea azul es de m\'{\i}nimos 
cuadrados, de lo contrario rotar\'{\i}a.

 \vfill
 \centerline{\psfig{figure=LineaDeRegresion.png,width=0.45\hsize}}
 \vfill

 \centerline{\tiny Imagen de Google}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{}

 \vfill
 \centerline{\psfig{figure=TemperaturaVsPiratas0.png,width=0.52\hsize}}
 \vfill
 \centerline{\psfig{figure=TemperaturaVsPiratas1.png,width=0.52\hsize}}
 \vfill
 \centerline{\tiny Imagen de Google}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{}

 \vfill
 \centerline{\psfig{figure=FrasePiratasTemperatura0.png,width=0.5\hsize}}
 \vfill
 \centerline{\psfig{figure=Pirata.png,width=0.5\hsize}}
 \vfill
 \centerline{\tiny Imagen de Google}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{}

 \vfill
 \centerline{\psfig{figure=Quiromancia.png,height=0.9\vsize}}
 \vfill
 \centerline{\tiny Imagen de Google}

 \vfill

\end{frame}

%-------------------------------------------------------------------

\begin{frame}{}
 \vfill

\url{https://en.wikipedia.org/wiki/Church-Turing_thesis}
 \vfill

{\bf La tesis de Church-Turing} dice que cualquier función para cuya 
evaluación se siguen reglas matemáticas definidas puede evaluarse 
mediante una máquina de Turing. Dado que existe equivalencia entre la 
máquina de Turing y el modelo de circuitos de la computación, se sigue 
de dicha tesis que cualquier función puede evaluarse con un computador. 
Y si las redes neuronales se pueden implementar con un modelo de 
circuitos, se seguiría una forma análoga de la tesis de Church-Turing 
con redes neuronales. Similarmente con el juego de la vida y otras 
equivalencias con la máquina de Turing.

 \vfill

\centerline{\bf Acerca de correlación y causalidad:}

\url{https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.95.244101}

\url{https://journals.aps.org/pre/abstract/10.1103/PhysRevE.92.022126}

\url{https://arxiv.org/pdf/1403.6496.pdf}

 \vfill

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{}

 \vfill
 \centerline{\psfig{figure=EscalarVectorMatriz-Tensor.png,width=\hsize}}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{Tensores en Machine Learning}

 \vfill

Son matrices multidimensionales que pueden almacenar cualquier 
tipo de datos, incluyendo números, textos, imágenes y videos. Los 
tensores tambi\'en se pueden utilizar para transformar datos de 
una forma a otra, como rotar una imagen o traducir un texto.

Los tensores de 2 índices se utilizan para representar texto. El 
primer índice del tensor representa la posición del carácter en la 
palabra, y el segundo índice representa el carácter en sí. O 
también, el primer índice del tensor se puede usar para 
representar la posición de la palabra en el texto, y el segundo 
índice para representar los caracteres de la palabra.

Un tensor puede representar una imagen como una matriz de píxeles. 
Una imagen se puede representar como un tensor de 3 índices, con 
un índice para cada fila, columna y canal de color.

Un ejemplo de tensor de 4 índices que se usa en inteligencia 
artificial es un tensor que representa una imagen 3D. Este tensor 
tendría un índice para cada fila, columna, profundidad y canal de 
color.

 \vfill

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{}

 \vfill

Por ejemplo, una imagen 3D de 200x200x100x3 píxeles tendría un 
tensor de 4 índices con la siguiente forma:

(filas, columnas, profundidad, canales) = (200, 200, 100, 3)

Cada píxel del tensor representaría la intensidad de un color en 
una ubicación específica de la escena.

Otro ejemplo de tensor de 4 índices que se usa en inteligencia 
artificial es un tensor que representa un video. Este tensor 
tendría un índice para cada fotograma, fila, columna y canal de 
color.

Por ejemplo, un video de 100 fotogramas de 200x200x3 píxeles 
tendría un tensor de 4 índices con la siguiente forma:

(fotogramas, filas, columnas, canales) = (100, 200, 200, 3)

 \vfill

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{}

 \vfill

Aprendizaje automático: Los tensores se utilizan en una 
variedad de algoritmos de aprendizaje automático, como las 
redes neuronales. Por ejemplo, una red neuronal se puede 
representar como un conjunto de tensores que se conectan entre 
sí.

Una red neuronal se puede representar como un tensor de 3 índices, 
con un índice para cada capa, neurona y entrada. Los tensores de 
2, 3 o más índices se utilizan para representar datos de entrada, 
pesos y salida de redes neuronales.

Los tensores de 2 índices son suficientes para representar datos 
unidimensionales y bidimensionales, como listas y matrices. Para 
representar datos tridimensionales o más, se necesitan tensores de 
3 índices o más.

Los tensores de 5 índices también se pueden utilizar para 
representar datos más complejos, como redes neuronales de varias 
capas. 

 \vfill

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{}

 \vfill

Otro ejemplo de tensor de 5 índices que se usa en inteligencia 
artificial es un tensor que representa un conjunto de datos de 
audio. Este tensor tendría un índice para cada muestra, canal, 
frecuencia, tiempo y dimensión.

Por ejemplo, un conjunto de datos de audio de 1000 muestras de 16 
bits, 44,1 kHz, estéreo tendría un tensor de 5 índices con la 
siguiente forma:

(muestras, canales, frecuencia, tiempo, dimensiones) = (1000, 2, 
44100, 1, 2)

 \vfill

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{}

 \vfill

Para convertir un NumPy array a TensorFlow tensor se usa

\centerline{\tt tensor = tf.convert\_to\_tensor(array)}

La conversión de tensores de Numpy en tensores de Pytorch se puede 
realizar utilizando la función

\centerline{\tt torch.from\_numpy()}.

 \vfill

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{Características y Etiquetas}

 \vfill

Puede decirse que una red neuronal es un procedimiento para evaluar una 
``función'' complicada, $f$, que tiene en su capa de entrada un conjunto 
de tensores $X$ llamados Features (características) y en la capa de 
salida otro conjunto $y$ con los Labels (etiquetas). La creencia básica 
consiste en la conexión entre la entrada y la salida.

{\color{red}{
\Huge
$$
y = f(X)
$$
}}

 \vfill

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{C\'alculos de la Pendiente y el Intercepto}

 \vfill

% \centerline{\textbf{Algunos Notebooks} \url{https://colab.research.google.com/drive/1Tq_M6jyTPUe7CxVe2zY1Os_o-srJwZlF#scrollTo=OvFJrEfvUraT}}

\vfill

\centerline{\textbf{Algunos Notebooks}}

\hfill

Ajuste de mínimos cuadrados con Numpy

\url{https://colab.research.google.com/drive/13lLbb2LS2gXe8VkPToYg0msQzm-NTU\_A}

 \vfill

Ajuste de mínimos cuadrados con Sklearn

\url{https://colab.research.google.com/drive/1SbDFJ3\_bGmcjBPjNROo1DYWckm5EpoPz}

 \vfill

Cálculo de la pendiente y el intercepto con Tensorflow

\url{https://colab.research.google.com/drive/1IDI8KB\_xo7qh-VWO\_qy\_6Qs-k7m4BkTi}

 \vfill

Cálculo de la pendiente y el intercepto con Tensorflow usando PGNN

\url{https://colab.research.google.com/drive/1DK1HI7HTuegTW36QYHJFmvnTb\_wvjPhx\#scrollTo=I44HQEv7tj0U}

 \vfill

Cálculo de la pendiente y el intercepto con Pytorch. También usando PGNN

\url{https://colab.research.google.com/drive/1lNlg6ye69Q7bzzBWbSrvmxRC\_SA43Ev3}

 \vfill

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{El Conjunto de Datos de la Flor Iris}

 Las tablas de Fisher contienen los datos morfol\'ogicos de la planta 
iris. Son 50 datos de cada una de los 3 tipos de la flor iris (setosa, 
virginica y versicolor). Cada registro contiene 5 entradas: {\bf 
longitud y ancho de los c\'epalos} y {\bf longitud y ancho de los 
p\'etalos}, en cm, y el {\bf nombre} del correspondiente tipo de flor.

Fisher calcul\'o un discriminante lineal para distinguir un tipo de 
otro. El correspondiente problema matem\'atico forma parte de la 
clasificaci\'on estad\'istica. Se puede implementar en aprendizaje 
autom\'atico, o ML, con diferentes algoritmos, uno de ellos llamado de 
M\'aquina de Soporte Vectorial (SVM).

\centerline{\texttt{\url{https://en.wikipedia.org/wiki/Iris\_flower\_data\_set}}}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 \vfill
 \centerline{\psfig{figure=IrisSetosaVersicolorVirginica.eps,width=\hsize}}

 \centerline{}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Espacio Tetradimensional}

\centerline{Algunos Datos de Ronald Fisher del Iris (1936)}

 $$
 \begin{array}{ccccc}
 \bf Largo\ de & \bf Ancho\ de & \bf Largo\ de & \bf Ancho\ de & \\
 \textbf{s\'epalo} & \textbf{s\'epalo} & \textbf{p\'etalo} & \textbf{p\'etalo} & \bf Especie \\
 5.0 & 2.0 & 3.5 & 1.0 & I. versicolor \\
 6.2 & 2.2 & 4.5 & 1.5 & I. versicolor \\
 6.0 & 2.2 & 5.0 & 1.5 & I. virginica  \\
 6.0 & 2.2 & 4.0 & 1.0 & I. versicolor \\
 6.3 & 2.3 & 4.4 & 1.3 & I. versicolor \\
 5.5 & 2.3 & 4.0 & 1.3 & I. versicolor \\
 5.0 & 2.3 & 3.3 & 1.0 & I. versicolor \\
 4.5 & 2.3 & 1.3 & 0.3 & I. setosa     \\
 5.5 & 2.4 & 3.8 & 1.1 & I. versicolor \\
 5.5 & 2.4 & 3.7 & 1.0 & I. versicolor \\
 4.9 & 2.4 & 3.3 & 1.0 & I. versicolor \\
 6.7 & 2.5 & 5.8 & 1.8 & I. virginica
 \end{array}
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 \vfill
 \centerline{\psfig{figure=Iris1D.eps,width=\hsize}}

 \centerline{}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 \vfill
 \centerline{\psfig{figure=IrisDiagramaDeDispersion.eps,width=0.78\hsize}}

 \centerline{}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 \vfill
 \centerline{\psfig{figure=IrisDatos3D.eps,width=\hsize}}

 \centerline{}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 El problema: Encontrar dos hiperplanos (superficies 3D inmersas en el 
espacio 4D) que produzcan una separaci\'on de los puntos de los 3 tipos 
de iris. Lo anterior marcar\'a fronteras de decisi\'on para futuras 
tareas de clasificaci\'on.

 Caso simple: Datos en 1D con s\'olo 2 clases. Se trata de hallar un 
punto $x$ que se sit\'ue exactamente entre los miembros de las clases 1 
y 2, tal que todos los puntos a la izquierda de $x$ pertenecen a una 
clase y los de la derecha a otra.

 Caso m\'as general en $D$ dimensiones con s\'olo 2 clases. Se trata de 
hallar un hiperplano $D-1$ dimensional que se sit\'ue exactamente entre 
los miembros de las clases 1 y 2, tal que todos los puntos a un lado 
pertenecen a una clase y los del otro lado a la otra clase. Se supone 
que las dos clases son disjuntas. El mejor hiperplano discriminador 
tiene la m\'axima distancia a los puntos de datos m\'as pr\'oximos de 
casa clase, los cuales se llaman ``vectores de soporte''.

 Se tiene el siguiente problema matem\'atico de optimizaci\'on: Hallar 
el hiperplano de ``m\'aximo margen'' o de ``separaci\'on \'optima'', el 
``m\'as alejado'' de los datos de entrenamiento.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Puntos $(x_1,x_2)$ De Dos Clases}

 \vfill
 \centerline{\psfig{figure=LineaSeparadora2Clases.eps,width=\hsize}}
 \centerline{}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Hiperplano de Separaci\'on}

 Obedece la ecuaci\'on
 $$
 \beta_0 + \beta_1x_1 + \beta_2x_2 + ... \beta_Dx_D = 0,
 $$
 donde $(x_1,x_2,...x_D)$ es un punto situado sobre el hiperplano.

 Las clases est\'an conformadas por puntos a cada uno de los 2 lados del 
hiperplano. Si $(x_1,x_2,...x_D)$, por fuera del hiperplano, es tal que
 $$
 \beta_0 + \beta_1x_1 + \beta_2x_2 + ... \beta_Dx_D > 0,
 $$
 decimos que ese punto pertenece a la clase $y=1$.
Si 
 $$
 \beta_0 + \beta_1x_1 + \beta_2x_2 + ... \beta_Dx_D < 0,
 $$
 decimos que el punto $(x_1,x_2,...x_D)$, por fuera del hiperplano, al 
``otro lado'' del anterior, pertenece a la clase $y=2$.

Por lo tanto la ecuaci\'on del hiperplano sirve de clasificador.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

Los puntos del ``soporte'' son tales que pertenecen a las dos clases y 
est\'an ubicados en hiperplanos paralelos al separador. Caracterizan la 
SVM.

Definamos dos vectores $D$ dimensionales $\bm{r}$ y $\bm{w}$ y un 
escalar $w_0$,
 $$
 \bm{r} = (x_1, x_2, ... x_D); \
 \bm{w} = (\beta_1, \beta_2, ... \beta_D);\
 w_0 = \beta_0.
 $$
 Los puntos ubicados sobre el separador satisfacen
 $$
 \bm{w}\cdot\bm{r} + w_0 = 0.
 $$
 Los puntos ubicados sobre uno de los dos planos de soporte satisfacen 
relaciones similares. $\bm{w}$ es com\'un a los tres planos, pero el 
$w_0$ obviamente es diferente, porque determina el sesgo de cada uno.

En el caso 2D, el ``hiperplano'' separador tiene una dimensi\'on menor, 
es una l\'{\i}nea recta.

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{Clasificaci\'on de los Tipos de Flor Iris}

 \vfill

\centerline{\textbf{Notebook} \url{http://localhost:8888/notebooks/Iris_flower_classification.ipynb}}

 \vfill

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{Reconocimiento de Im\'agenes}

 \vfill

\centerline{\textbf{Notebook} \url{https://colab.research.google.com/drive/1bexwbro5XFGsPpZncFc\_TdDv8E8-NmhO\#scrollTo=iLCu57TH8kQ4}}

 \vfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{RN Convolucionales}

Son similares a las RN en general, pero est\'an adaptadas a situaciones 
en las cuales la entrada contiene informaci\'on ``redundante'' o que 
contiene detales que pueden omitirse sin graves consecuencias.

Es el caso de las im\'agenes, las cuales admiten diferentes 
procedimientos de compresi\'on. Una imagen 2D se puede representar con 
un n\'umero de bits igual a largo$\times$ancho$\times$profundidad, donde 
largo y ancho son los pixeles y profundidad representa otros atributos 
como colores y tonos de gris. Im\'agenes de baja resoluci\'on como las 
de CIFAR-10 requieren 32$\times$32$\times$3 = 3072 bits. Una imagen de 
resoluci\'on moderada 200$\times$200$\times$3 = 120000 bits. Cuando se 
tengan muchas de estas \'ultimas ciertamente habr\'a dificultades 
computacionales.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

La ``correlaci\'on'' o correlaci\'on cruzada de dos funciones de una 
variable discreta y de dos variables discretas, se define por
 $$
 y(n) = (x*h)(n) = \sum\limits_{k=-\infty}^\infty x(k)h(n-k).
 $$
 $$
 (x*h)(m,n) =
 \sum\limits_{j=-\infty}^\infty\sum\limits_{k=-\infty}^\infty
 x(j,k)h(m-j,n-k).
 $$
 Es una suma de productos de valores de dos funciones punto a punto, 
sometidas a un desajuste.

\texttt{http://cs231n.stanford.edu/} es un curso sobre CNN. 
\texttt{https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/} 
contiene una explicaci\'on intuitiva acerca de las redes neuronales 
convolucionales. Tambi\'en es interesante 
\texttt{http://cs231n.github.io/convolutional-networks/}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Redes Neuronales Convolucionales}

 \vfill
 \centerline{\psfig{figure=Convolucion.png,width=\hsize}}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

La t\'ecnica de CNN opera sobre los mencionados ``vol\'umenes''. Utiliza 
un ``filtro'' de dimensi\'on menor que se mueve a lo largo de toda la 
imagen original. En el camino se realiza el producto entre la imagen y 
el filtro, lo cual da lugar a una serie de trozos m\'as peque\~nos. Por 
eso se supone que las CNN son apropiadas para extraer propiedades que no 
dependan dr\'asticamente de la posici\'on.

Por ejemplo, si la imagen original es 32$\times$32$\times$3 y el filtro 
es 5$\times$5$\times$3, la operaci\'on la convierte en 
28$\times$28$\times$1. En efecto, hay 28$\times$28 posiciones \'unicas 
donde el filtro puede colocarse sobre la imagen original. Otro ejemplo: 
con una imagen 4$\times$4$\times$3 y un filtro 2$\times$2$\times$3, el 
cual se puede deslizar de 3$\times$3=9 maneras distintas sobre la 
imagen, da lugar a 3$\times$3$\times$1. La palabra convoluci\'on 
representa la acci\'on de deslizar el filtro y sumar los productos de 
las respectivas unidades en coincidencia.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Entrenar un Clasificador}

\centerline{\texttt{\url{https://pytorch.org/tutorials/beginner/blitz/cifar10\_tutorial.html}}}
 
All\'{\i} se considera el problema de reconocimiento de im\'agenes 
mediante una red neuronal con muchas capas ocultas.

El problema empieza con el entrenamiento de un clasificador. Requiere: 
Disponer de los datos de entrenamiento, definir la red neuronal, 
calcular funciones de p\'erdida y actualizar los pesos de la red.

Considera el conjunto de im\'agenes dados en CIFAR10. All\'{\i} se 
tienen las clases `avi\'on', `autom\'obil', `p\'ajaro', `gato', `cabra', 
`perro', `rana', `caballo', `barco', `cami\'on'.

Del enlace

 \texttt{https://pytorch.org/tutorials/beginner/blitz/cifar10\_tutorial.html}

se extrae el notebook

 \centerline{\texttt{EnsayoPytorchVision.ipynb}}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Redes Neuronales Recurrentes}

Las redes neuronales recurrentes (RNN) son un tipo de RN que se usan 
para procesar datos que guarden una estructura secuencial, como series 
de tiempo y los textos. Permiten llevar un registro de las relaciones 
estructurales entre los datos, por ejemplo en una serie de tiempo 
capturar información del pasado y usarla para definir la salida actual.

Se usan en procesamiento del lenguaje natural (NLP), reconocimiento de 
voz, predicción de series temporales incluyendo la captura de patrones y 
dependencias a lo largo del tiempo, generación de música y artes 
plásticas, análisis de sentimients o juicios de valor.

Las RNN son adecuadas para problemas con datos secuenciales y 
dependencias a largo plazo, mientras que las CNN son más apropiadas para 
problemas que involucran datos con estructura espacial, como imágenes y 
videos. Las CNN sirven para captar patrones globales repetitivos, en 
tanto que las RNN se enfocan en las especificidades locales de los 
datos. Se pueden usar como una ``memoria interna'' o ``estado oculto''.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 \vfill
 \centerline{\psfig{figure=RedNeuronalRecurrente.png,width=\hsize}}
 \vfill
 \centerline{\tiny Imagen de Google}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Redes Neuronales con Atención}

Las redes neuronales con atención, los encoders-decoders y los 
transformadores son tipos de redes neuronales recurrentes que se 
utilizan para el procesamiento del lenguaje natural (NLP).

La {\bf atención} permite a las redes neuronales recurrentes centrarse
en las partes más relevantes de una secuencia de datos. Se usa en 
traducción automática, respuesta a preguntas y otras tareas de NLP.

Las redes neuronales con atención son redes neuronales recurrentes que 
utilizan una capa de atención para asignar diferentes pesos a diferentes 
partes de una secuencia de datos.  Una capa con atención es una capa 
adicional que se coloca en el medio de una red neuronal recurrente. Esta 
capa toma como entrada la salida de la capa anterior, que es una 
representación vectorial de la secuencia de datos. A continuación, la 
capa con atención calcula un vector de atención, que asigna diferentes 
pesos a diferentes partes de la secuencia. De esta manera le asigna un 
peso o importancia a la salida de la capa anterior. Las partes de la 
secuencia que tienen un peso alto se consideran más relevantes y, por lo 
tanto, tienen un mayor impacto en la salida de la red neuronal.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 \vfill
 \centerline{\psfig{figure=RedNeuronalConAtencion.png,width=\hsize}}
 \vfill
 \centerline{\tiny Imagen de Google}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

Con la atención, en lugar de procesar toda la secuencia de entrada de 
manera uniforme, la red aprende a enfocar y dar más peso a las partes 
relevantes o informativas de los datos.

Hay diferentes maneras de implementar una capa con atención. Una forma 
común es utilizar una función de atención que calcula el producto 
escalar entre el vector de estado de la capa anterior y un vector de 
consulta dado. El vector de consulta se puede inicializar con un vector 
de valores constantes, o se puede aprender durante el entrenamiento de 
la red neuronal.

Dicho vector de consulta puede representar un {\bf prompt}. Un prompt es una 
cadena de texto que se utiliza para proporcionar información adicional a 
una red neuronal. Por ejemplo, un prompt se podría utilizar para 
proporcionar el contexto de una oración o para indicar el tipo de 
respuesta que se espera.

Otra forma de implementar una capa con atención es utilizar una función 
de atención que calcula la probabilidad de que cada palabra de la 
secuencia sea importante. La probabilidad de cada palabra se puede 
calcular utilizando una función de activación, como la función sigmoide.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Codificadores y Decodificadores. Transformers}

Los {\bf encoders-decoders} son una arquitectura de red neuronal recurrente en 
la cual el encoder convierte una secuencia de entrada en una 
representación vectorial, y el decoder utiliza esta representación para 
generar una secuencia de salida. Esta arquitectura es especialmente 
adecuada para tareas de NLP que implican la traducción automática, la 
generación de texto y la respuesta a preguntas.

Los {\bf transformadores} son un tipo de red neuronal recurrente que utiliza 
una capa de atención para mapear una secuencia de entrada a una 
secuencia de salida. Los transformadores se han demostrado que son muy 
eficaces en una variedad de tareas de NLP, incluidas la traducción 
automática, la generación de texto y la respuesta a preguntas.

Las redes neuronales con atención son especialmente eficaces en tareas 
de NLP que requieren comprender el orden de las palabras en una oración. 
Se utilizan a menudo para la traducción automática, la respuesta a 
preguntas y la generación de texto creativo.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

La principal ventaja de las redes neuronales con atención es su 
capacidad para manejar secuencias de longitud variable y seleccionar 
automáticamente las partes más relevantes de la secuencia. Esto es 
particularmente útil en tareas donde se necesita una comprensión 
contextual de la secuencia, como el procesamiento del lenguaje natural 
(NLP). Al enfocarse en partes específicas, la red puede capturar 
dependencias a largo plazo y extraer características relevantes, lo que 
conduce a un mejor rendimiento en diversas aplicaciones.

Algunas aplicaciones de las redes neuronales con atención incluyen 
traducción automática, resumen de texto, preguntas y respuestas, 
reconocimiento de voz, análisis de sentimientos, patrones inusuales en 
los datos, deneración de música, etc.

La fortaleza principal de los transformers radica en su mecanismo de 
atención, que permite a la red enfocarse en diferentes partes de la 
secuencia de entrada mientras procesa la información. 

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Terminología}

En los transformers, los ``codificadores'' y ``decodificadores'' se 
refieren a los bloques de capas que realizan operaciones de atención y 
feed-forward. Estos bloques se repiten en la arquitectura para procesar 
y transformar las secuencias de datos.

El {\bf ``one-hot encoding''} es una técnica utilizada para representar datos 
categorizados o categóricos en forma de vectores binarios. Cada 
categoría se representa como un vector binario con una dimensión igual 
al número total de categorías. Todas las dimensiones del vector son 
cero, excepto la correspondiente a la categoría que se está 
representando, que se establece en uno.

En los transformers, las secuencias de entrada no se representan 
utilizando ``one-hot encoding''. En su lugar, se utilizan 
representaciones vectoriales densas que contienen información contextual 
y semántica sobre las palabras o elementos de la secuencia. Estas 
representaciones vectoriales se aprenden mediante el proceso de 
entrenamiento de la red neural, en el que se ajustan los pesos y se 
optimizan para capturar características y relaciones relevantes en los 
datos.

Los transformers están diseñados para procesar secuencias de datos, como 
palabras en un texto o elementos en una serie temporal, y no se centran 
en la codificación y decodificación de datos en términos de técnicas de 
representación como el ``one-hot encoding''.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

Los transformers tienen la propiedad de atención global, con la cual 
pueden acceder a todas las posiciones de la secuencia de entrada. Así 
capturan relaciones a largo plazo y comprenden el contexto global de la 
secuencia. Con la atención, el modelo puede asignar diferentes pesos las 
partes relevantes de la entrada, lo que mejora su capacidad para 
procesar información contextual.

Los transformers pueden procesar todas las posiciones de la secuencia en 
paralelo, lo cual los hace útiles cuando se usa hardware con GPUs o 
TPUs.

Los transformers son escalables, así pueden manejar secuencias de 
longitud variable. En NLP se tienen secuencias de diferentes longitudes, 
como la traducción automática o el resumen de texto.

Los transformers preentrenados en grandes cantidades de datos pueden 
usarse como modelos de transferencia de aprendizaje para tareas 
específicas. Así, se cuenta con buena aproximación inicial a los pesos 
de la red neuronal.

 \vfill

\end{frame}

%-------------------------------------------------------------------

\begin{frame}{}

 \vfill

\centerline{\url{https://gpt4all.io/index.html}}

 \vfill

\centerline{\url{https://github.com/amaiya/ktrain}}

 \vfill

\centerline{Enlace a los notebooks mencionados en la charla:}

\centerline{\url{https://github.com/JorgeEMahecha/Notebooks-Intro-ML}}

 \vfill

 \end{frame}

%-------------------------------------------------------------------

 \end{document}

%-------------------------------------------------------------------
%-------------------------------------------------------------------


%-------------------------------------------------------------------

 \section{El Problema de Clasificaci\'on}
 \begin{frame}{Puntos $(x_1,x_2)$ De Dos Clases}

 \vfill
 \centerline{\psfig{figure=LineaSeparadora2Clases.eps,width=\hsize}}
 \centerline{}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Puntos $(x_1,x_2,x_3)$ De Tres Clases}

 \vfill
 \centerline{\psfig{figure=IrisDatos3DOtro.eps,width=\hsize}}
 \centerline{}
 \vfill

 \end{frame}



%-------------------------------------------------------------------

 \section{Las Redes Neuronales}
 \begin{frame}{Perceptr\'on y Sigmoide}

 \vfill
 \centerline{\psfig{figure=Perceptron.eps,height=0.4\hsize,width=0.5\hsize}\psfig{figure=Sigmoide.eps,height=0.4\hsize,width=0.5\hsize}}

 \centerline{Perceptr\'on de una sola capa. \hfill Sigmoide\hfill}
 \vfill

 \end{frame}

%-------------------------------------------------------------------









%-------------------------------------------------------------------

 \section{}
 \begin{frame}{Regresi\'on Log\'{\i}stica}

Se define
 $$
 h_{\bm{w}}(\bm{x}) = f(\bm{w}\cdot\bm{x}),
 $$
 donde $f(z)$ es la funci\'on de activaci\'on log\'{\i}stica y $\bm{x}$ 
y $\bm{w}$ son vectores de dimensi\'on $D+1$, con $x_0=1$,
 $$
 \bm{w}\cdot\bm{x} = w_0 + \sum\limits_{i=1}^Dw_ix_i.
 $$

El problema de regresi\'on consiste en ajustar $\bm{w}$ conociendo $N$ 
series de datos $\bm{x} = \{1,x_1,...x_D\}$. Una manera simple es usar 
el ajuste de m\'{\i}nimos cuadrados. Otra es maximizar una funci\'on de 
\textbf{plausibilidad}. Llamamos $x_i$ a las componentes del vector 
$\bm{x}$ y $\bm{x}_\lambda$, con $\lambda=1,...N$ las N realizaciones 
del mismo.

Suponemos que a la entrada $\bm{x}_\lambda$ le corresponde una salida 
del perceptr\'on $y_\lambda$, la cual puede ser $y=0$ o $y=1$ 
(perceptr\'on binario).

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

El modelo probabil\'{\i}stico del perceptr\'on postula las 
probabilidades condicionales de $y=0$, $y=1$, as\'{\i},
 $$
 P(y=1\vert\bm{x};\bm{w}) = h_{\bm{w}}(\bm{x}),\quad 
 P(y=0\vert\bm{x};\bm{w}) = 1 - h_{\bm{w}}(\bm{x}),
 $$
 o, en general,
 $$
 P(y\vert\bm{x};\bm{w}) = h_{\bm{w}}(\bm{x})^y
 [1 - h_{\bm{w}}(\bm{x})]^{1-y}.
 $$

Dado el conjunto de observaciones $\{\bm{x}_\lambda,y_\lambda\}$, para 
$\lambda=1,...N$, el cual denotamos por $\{\bm{X},Y\}$, se define la 
\textbf{funci\'on de plausibilidad} $L$ por
 $$
 L(\bm{w}) = P(Y\vert\bm{X};\bm{w}) = \prod\limits_{\lambda=1}^N 
 P(y_\lambda\vert\bm{x}_\lambda;\bm{w}) = \prod\limits_{\lambda=1}^N 
 h_{\bm{w}}(\bm{x}_\lambda)^{y_\lambda} [1 - 
 h_{\bm{w}}(\bm{x}_\lambda)]^{1-y_\lambda}.
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Maximizaci\'on de la Funci\'on de Plausibilidad}

 $$
 \begin{array}{rcl}
 l(\bm{w}) = \log L(\bm{w}) &=& \log P(Y\vert\bm{X};\bm{w}) \\
 &=&\sum\limits_{\lambda=1}^N\{ y_\lambda \log h_{\bm{w}}(\bm{x}_\lambda) 
 + (1-y_\lambda) \log[1 - h_{\bm{w}}(\bm{x}_\lambda)]\}.
 \end{array}
 $$
 Se procede a la maximizaci\'on usando el m\'etodo del \textbf{ascenso 
del gradiente}. Se basa en que la funci\'on multidimensional, para 
cualquier $\bm{a}$ cercano al $\bm{w}$ en el cual es m\'axima tiene un 
gradiente con una componente orientada hacia el m\'aximo. Mientras m\'as 
cerca est\'e $\bm{a}$ del m\'aximo, m\'as peque\~na ser\'a la otra 
componente del gradiente. Eso permite establecer la siguiente regla para 
actualizar el punto $\bm{a}$ con el fin de acercarlo al m\'aximo,
 $$
 \bm{a}\to\bm{a}+\eta\frac{\partial l(\bm{w})}{\partial\bm{w}},
 $$
 donde $\eta$ es una constante positiva.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

Usando las propiedades de la funci\'on sigmoide se halla que
 $$
 \frac{\partial l(\bm{w})}{\partial\bm{w}} = [y -
 h_{\bm{w}}(\bm{x})]\bm{x} = \sum\limits_{\lambda=1}^N[y_\lambda -
 h_{\bm{w}}(\bm{x}_\lambda)]\bm{x}_\lambda.
 $$
 Por lo tanto,
 $$
 \bm{a}\to\bm{a}+\eta\sum\limits_{\lambda=1}^N[y_\lambda -
 h_{\bm{w}}(\bm{x}_\lambda)]\bm{x}_\lambda.
 $$
 Un criterio de parada del algoritmo puede formularse estableciendo 
cierto umbral $\epsilon$, tal que
 $$
 N\eta\frac{1}{N}\sum\limits_{\lambda=1}^N\vert y_\lambda -
 h_{\bm{w}}(\bm{x}_\lambda)\vert
 \frac{1}{N}\sum\limits_{\mu=1}^N\vert\bm{x}_\mu\vert<\epsilon.
 $$

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{Una ``Red'' que Produce la Puerta NOT}

La entrada es $x$ y la salida $y$, binarias. La salida deseable es el 
NOT de la entrada. Es decir, que si $x=0$ entonces $y=1$ y si $x=1$ 
entonces $y=0$.

Si se hace $w=1$, entonces $s=x$. Si se toma como funci\'on de 
activaci\'on la \texttt{identidad} entonces $f(s)=s$. Resulta as\'{\i} 
la puerta l\'ogica identidad. Sin embargo, si se suma cierta cantidad 
$\theta$, llamada en ingl\'es ``\textit{bias}'' (que se puede traducir 
como ``sesgo'', ``polarizaci\'on'' o ``desplazamiento''), puede lograrse 
la puerta l\'ogica NOT. $ s = w\cdot x + \theta,\ y= f(s). $ Tomando 
$f=Id$, $w=1$, $\theta=1$ se obtiene $f(s)=w\cdot x + \theta=1\cdot 
x+1=x+1$, lo cual, con suma en la base binaria, da $0+1=1$ y $1+1=0$.

\vspace{0.2cm}
\setlength{\unitlength}{1.5mm}
\thicklines
\hspace{3.5cm}
\begin{picture}(40,1)(0,0)
\put(2,0){\vector(1,0){36}}
\put(0,0){\circle{4}}
\put(40,0){\circle{4}}
\put(-0.7,-0.5){$\bm{x}$}
\put(39.3,-0.5){$\bm{y}$}
\put(20,1){$\bm{w}$}
\put(40,-5){\vector(0,1){3.4}}
\put(39.5,-7.5){$\bm{\theta}$}
\end{picture}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Puerta L\'ogica CNOT Con la Red Neuronal}

 La red de 3 unidades permite almacenar la funci\'on l\'ogica CNOT. Esta 
red tiene $2^3=8$ estados: $(-1,-1,-1)$, $(-1,-1,1)$, ... $(1,1,1)$. 
S\'olo tiene 4 m\'{\i}nimos locales, en los siguientes 4 puntos del 
espacio 3D, todos con energ\'{\i}a $-1$.
 $$
 \begin{array}{cccc}
 PUNTO & TARGET & CONTROL & CNOT \\
 1. & -1 & -1 & -1 \\
 2. & 1  & -1 & 1 \\
 3. & -1 & 1  & 1 \\
 4. & 1  & 1  & -1 
 \end{array}
 $$
 El control y el target forman 4 puntos de 2 bits: $(-1.-1)$, $(-1.1)$, 
$(1.-1)$, $(1.1)$. Por su parte, $CNOT$ es una funci\'on que toma uno de 
estos 4 puntos y los env\'{\i}a en $-1$ o $1$.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Separaci\'on en Dos Clases}

 Una recta puede separar siempre 3 puntos con una recta en las clases 
``$+$'' y ``$-$''. Las posibles tr\'{\i}adas de puntos son: $-,-,-$\quad 
$-,-,+$\quad $-,+,-$\quad $-,+,+$\quad $+,-,-$\quad $+,-,+$\quad 
$+,+,-$\quad $+,+,+$\quad.

 \vfill\hfill
 \setlength{\unitlength}{0.1cm}
 \begin{picture}(100,25)
 \linethickness{3pt}
 \thicklines
 \put(0,0){\line(1,1){24}}
 \put(23,0){\line(1,1){24}}
 \put(48,0){\line(1,1){24}}
 \put(73,0){\line(1,1){24}}
 \put(-7.,0.){\color{red}$\bm{+}$}
 \put(3.,10.){\color{red}$\bm{+}$}
 \put(13.,20.){\color{red}$\bm{+}$}
 \put(4.,0.){$\bm{}$}
 \put(14.,10.){$\bm{}$}
 \put(24.,20.){$\bm{}$}
 \put(17.,0.){\color{red}$\bm{+}$}
 \put(27.,10.){\color{red}$\bm{+}$}
 \put(37.,20.){$\bm{}$}
 \put(28.,0.){\color{blue}$\bm{-}$}
 \put(38.,10.){$\bm{}$}
 \put(48.,20.){$\bm{}$}
 \put(41.,0.){\color{red}$\bm{+}$}
 \put(51.,10.){$\bm{}$}
 \put(61.,20.){$\bm{}$}
 \put(52.,0.){\color{blue}$\bm{-}$}
 \put(62.,10.){\color{blue}$\bm{-}$}
 \put(72.,20.){$\bm{}$}
 \put(66.,0.){$\bm{}$}
 \put(77.,10.){$\bm{}$}
 \put(87.,20.){$\bm{}$}
 \put(76.,0.){\color{blue}$\bm{-}$}
 \put(87.,10.){\color{blue}$\bm{-}$}
 \put(98.,20.){\color{blue}$\bm{-}$}
 \end{picture}
 \hfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

Una recta del plano no puede separar 4 puntos tomados de las $2^4=16$ 
cuartetas $(-,-,-,-)$\ $(-,-,-,+)$\ $(-,-,+,-)$\ $(-,-,+,+)$\ 
$(-,+,-,-)$\ $(-,+,-,+)$\ $(-,+,+,-)$\ $(-,+,+,+)$\ $(+,-,-,-)$\ 
$(+,-,-,+)$\ $(+,-,+,-)$\ $(+,-,+,+)$\ $(+,+,-,-)$\ $(+,+,-,+)$\ 
$(+,+,+,-)$\ $(+,+,+,+)$\ con la clase ``$+$'' a un lado de la recta y 
la clase ``$-$'' al otro lado. Se requieren dos rectas, lo cual no da 
lugar a una separaci\'on en dos clases. Por ejemplo

 \vspace{1cm}
 \hfill
 \setlength{\unitlength}{0.2cm}
 \begin{picture}(45,10)
 \linethickness{3pt}
 \thicklines
 \put(0,0){\line(1,1){12}}
 \put(23,0){\line(1,1){12}}
 \put(-2.,5.){\color{red}$\bm{+}$}
 \put(3.,10.){\color{red}$\bm{}$}
 \put(13.,20.){\color{red}$\bm{}$}
 \put(10.,0.){\color{blue}$\bm{-}$}
 \put(20.,10.){\color{blue}$\bm{-}$}
 \put(24.,20.){$\bm{}$}
 \put(34.,5.){\color{red}$\bm{+}$}
 \put(37.,20.){$\bm{}$}
 \end{picture}
 \hfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 Los puntos de la $CNOT$ se pueden colocar en el plano $x_1-x_2$.

 \vspace{1cm}
 \hfill
 \setlength{\unitlength}{0.2cm}
 \begin{picture}(45,10)
 \linethickness{3pt}
 \thicklines
 \put(0,0){\vector(1,0){10}}
 \put(0,0){\vector(0,1){10}}
 \put(22,0){\line(1,0){10}}
 \put(22,0){\line(0,1){10}}
 \put(32,0){\line(0,1){10}}
 \put(32,10){\line(-1,0){10}}
 \put(32,-5){\line(-1,1){15}}
 \put(37,0){\line(-1,1){15}}
 \put(0.,11.){\color{red}$\bm{x_2}$}
 \put(11.,0.){\color{red}$\bm{x_1}$}
 \put(17.,11.){\color{blue}$\bm{(-1,1)}$}
 \put(32.,11.){\color{blue}$\bm{(1,1)}$}
 \put(17.,-3.){\color{blue}$\bm{(-1,-1)}$}
 \put(32.,-3.){\color{blue}$\bm{(1,-1)}$}
 \put(31.5,-0.5){\color{red}$\bm{\bullet}$}
 \put(31.5,9.5){\color{red}$\bm{\bullet}$}
 \put(21.5,-0.5){\color{red}$\bm{\bullet}$}
 \put(21.5,9.5){\color{red}$\bm{\bullet}$}
 \end{picture}
 \hfill

 \vspace{1cm}

 Los puntos $(-1,1)$ y $(1,-1)$ son estables. Los puntos $(-1,-1)$ y 
$(1,1)$ son inestables.

 Ninguna red de Hpfield de 3 unidades puede tener los 4 estados 
estables.

El problema de $CNOT$ se resuelve si la red se extiende a 4 unidades. La 
cuarta hace el papel de ancilla. Se tiene as\'{\i} la $CNOT$ 
\textbf{reversible}.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 La red de 4 unidades permite almacenar la funci\'on l\'ogica $CNOT$ 
reversible. Esta red tiene $2^4=16$ estados, de los cu\'ales 4 
corresponden a la $CNOT$:
 $$
 \begin{array}{cccc}
 CONTROL & TARGET & CNOT & ANCILLA \\
 -1 & -1 & -1 & 1 \\
 1  & -1 & 1  & 1\\
 -1 & 1  & 1  & 1 \\
 1  & 1  & -1 & -1 \\
 x_1 & x_2 & x_3 & x_4
 \end{array}
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{``Deep Learning''}

 \vfill
 \centerline{\psfig{figure=ImagenDeGoogle.eps,width=\hsize}}

 \centerline{\tiny Imagen de Google}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Red Neuronal de la Puerta CNOT}

 \DIVIDE{1.}{2.}{\coss}
 \DIVIDE{1.73205}{2.}{\sins}
 \MULTIPLY{50}{\sins}{\ymax}
 \MULTIPLY{3.5}{\coss}{\xu}
 \MULTIPLY{3.5}{\sins}{\yu}
 \DIVIDE{\ymax}{3.0}{\yc}
 \SUBTRACT{\ymax}{\yu}{\yv}
 \SUBTRACT{25}{\xu}{\xv}
 \SUBTRACT{50}{\xu}{\xd}
 \ADD{25}{\xu}{\xt}
 \setlength{\unitlength}{.09cm}
 \begin{picture}(50,\ymax)(-45,0)
 \setlength{\unitlength}{.09cm}
 \linethickness{3pt}
 \thicklines
 \put(0,0){\circle{7}}
 \put(25,\ymax){\circle{7}}
 \put(50,0){\circle{7}}
 \put(25,\yc){\circle{7}}
 \put(6,0){\vector(1,0){41}}
 \put(44,0){\vector(-1,0){41}}
 \put(\xu,\yu){\vector(0.5,0.866){21.5}}
 \put(\xv,\yv){\vector(-0.5,-0.866){21.5}}
 \put(\xt,\yv){\vector(0.5,-0.866){21.5}}
 \put(\xd,\yu){\vector(-0.5,0.866){21.5}}
 \put(2.9,1.5){\vector(11,7){19.3}}
 \put(4.5,2.5){\vector(-11,-7){1.9}}
 \put(25,40){\vector(0,-1){22.3}}
 \put(25,38.2){\vector(0,1){1.9}}
 \put(47.3,1.5){\vector(-11,7){19.3}}
 \put(45.7,2.5){\vector(11,-7){1.5}}
 \put(-1.5,0){$\bm{x_1}$}
 \put(48.5,0){$\bm{x_2}$}
 \put(23.5,\ymax){$\bm{x_3}$}
 \put(23.5,\yc){$\bm{x_4}$}
 \put(13,20){$\bm{w_{13}}$}
 \put(30,20){$\bm{w_{23}}$}
 \put(21.5,2){$\bm{w_{12}}$}
 \put(8.0,10){$\bm{w_{14}}$}
 \put(34.5,10){$\bm{w_{24}}$}
 \put(25.5,28){$\bm{w_{34}}$}
 \end{picture}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Actualizaci\'on de los Pesos}

 El aprendizaje con descenso del gradiente (gradient descent learning, 
GDL) utiliza la funci\'on de costo para determinar el cambio requerido 
en los pesos. Requiere evaluar el gradiente, $\partial 
E(\bm{w})/\partial\bm{w}$, el cual dice la direcci\'on en la cual debe 
moverse en el espacio $\bm{w}$ para reducir el error. Tambi\'en se 
requiere la tasa de aprendizaje $\eta$, que expresa el n\'umero de pasos 
en el espacio $\bm{w}$ requeridos para cada actualizaci\'on de los 
$\bm{w}$.

Entonces el cambio requerido del vector de pesos vale
 $$
 \Delta\bm{w} = -\eta\frac{\partial E(\bm{w})}{\partial\bm{w}},
 $$
 el cual debe repetirse hasta que la funci\'on de error alcance el 
m\'{\i}nimo valor.

No es posible con el anterior procedimiento tratar datos no separables 
linealmente, como sucede con la $CNOT$ de una capa (capa de entrada con 
los dos nodos $x_1$ y $x_2$ y capa de salida con un s\'olo nodo, 
$CNOT(x_1,x_2)$. Se requiere un perceptr\'on de varias capas, por 
ejemplo entrada $i$, oculta $j$ y salida $k$.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

En el algoritmo de entrenamiento m\'as simple, los pesos se actualizan 
con el siguiente procedimiento, al realizar las sucesivas iteraciones,
 $$
 w_{ij}(\textrm{nuevo}) = w_{ij}(\textrm{viejo}) + x_iy_i.
 $$
 Se modifica con la regla de aprendizaje de perceptr\'on (Perceptron 
Learning Rule PLR) o ``regla delta'',
 $$
 w_{ij}(\textrm{nuevo}) = w_{ij}(\textrm{viejo}) + 
\eta\cdot\delta_i\cdot
 x_j;\quad\delta_i = y_i(\textrm{target}) - y_i.
 $$
 Es conveniente usar en vez de la funci\'on umbral $SGN$ una funci\'on 
diferenciable como la sigmoide, la cual cumple,
 $$
 f'(x) = f(x)[1-f(x)].
 $$
 La regla delta generalizada (generalized delta rule GDR) utiliza la 
funci\'on de costo, as\'{\i},
 $$
 w_{ij}(\textrm{nuevo}) = w_{ij}(\textrm{viejo}) - \eta\frac{\partial
 E(\bm{w})}{\partial w_{ij}}.
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 La funci\'on de costo se expresa en funci\'on de la salida, la cual es 
funci\'on de la entrada,
 $$
 E(\bm{w}) = \frac{1}{2} \sum\limits_p\sum\limits_j 
 [y^p_j(\textrm{target}) - y^p_j],
 $$
 donde $y_j^p = \sum_iw_{ji}x_i^p$. Por lo tanto,
 $$
 \frac{\partial E}{\partial w_{ji}} = \frac{\partial
 E}{\partial y_j}\cdot \frac{\partial y_j}{\partial w_{ji}} = 
-[y_j\textrm{target} - y_j]x_i = -\delta_j\cdot x_i.
 $$
 Para reducir $E$ por el descenso del gradiente, los pesos se deben 
mover en direcci\'on opuesta a la del gradiente, $-(-\delta) = \delta$.

 \end{frame}

%-------------------------------------------------------------------

 \section{Propagaci\'on Hacia Atr\'as (Backpropagation)}
 \begin{frame}{Propagaci\'on Hacia Atr\'as}

 La funci\'on de error total, en un modelo de aprendizaje supervisado,
 $$
 E = \frac{1}{2}\sum\limits_k(y_k-\overline{y}_k)^2
 $$
 donde $y_k$ son los valores de salida predichos por la RN y 
$\overline{y}_k$ son las clases definidas en el entrenamiento, en 
\'ultima instancia es funci\'on de la entrada. El problema consiste en 
ajustar los pesos y los sesgos para minimizar $E$.

En una RN con una capa de entrada, una capa de salida y cierto n\'umero 
de capas ocultas, las unidades de la capa de salida son funciones de las 
de la \'ultima capa oculta, \'estas a su vez son funciones de las de la 
pen\'ultima capa oculta, y as\'{\i} sucesivamente hasta las de la capa 
de entrada. Por lo tanto se requiere propagar hacia atr\'as los errores 
en la capa de salida para ir determinando los ajustes de los 
par\'ametros de la RN.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

En el caso sin capas ocultas, el cambio en el peso que acopla la entrada 
$x_i$ con la salida $y_k$ es,
 $$
 \Delta w_{ki} = -\eta\frac{\partial E}{\partial y_k}\frac{\partial 
 y_k}{\partial x_i}\frac{\partial x_i}{\partial w_{ki}}.
 $$
 Si se usa la funci\'on de activaci\'on sigmoide, sin sesgo, $y_k = 
g(x_i) = [1+exp(-\sum_iw_{ki}x_i)]^{-1}$, y se usa la bidireccionalidad, 
$y_k = \sum_iw_{ki}x_i$,
 $$
 \frac{\partial E}{\partial y_k} = y_k-\overline{y}_k,\ 
 \frac{\partial y_k}{\partial x_i} = y_k(1-y_k),\ 
 \frac{\partial x_i}{\partial w_{ki}} = y_k.
 $$
 Por lo tanto,
 $$
 \Delta w_{ki} = -\eta(y_k-\overline{y}_k) y_k (1-y_k)y_i = \eta\delta_ky_i,
$$
 donde $\delta_k = (y_k-\overline{y}_k) y_k (1-y_k)$. Se parece a la 
regla de entrenamiento del perceptr\'on.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 En el caso con una capa oculta, el cambio en el acople entre la capa de 
entrada y la capa oculta es,
 $$
 \begin{array}{rcl}
 \Delta w_{ji} &=&\displaystyle -\eta\left(\sum_k\frac{\partial E}{\partial y_k}\frac{\partial 
 y_k}{\partial x_i}\frac{\partial x_i}{\partial y_j}\right) 
 \frac{\partial y_j}{\partial x_j} \frac{\partial x_j}{\partial w_{ji}} \\
 &=& -\eta\left[\sum_k(y_k-\overline{y}_k)y_k(1-y_k)w_{kj}\right]
 y_j(1-y_j)y_i \\
 &=& -\eta(\sum_k\delta_kw_{kj})y_j(1-y_j)y_i \\
 &=& -\eta\delta_jy_i. 
 \end{array}
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

El c\'alculo de la propagaci\'on de errores hacia atr\'as requiere un 
n\'umero exponencialmente grande de operaciones. Eso se puede ilustrar 
con el ``grafo computacional'', que reduce el c\'alculo de las derivadas 
parciales a una suma sobre todas las trayectorias que conectan entre si 
dos nodos y multiplicando las derivadas asociadas con cada borde, como 
lo ilustra la f\'ormula anterior.

En \texttt{colah.github.io/ports/2015-08-Backprop} se da el siguiente 
ejemplo, el grafo para evaluar $e=(a+b)*(b+1)$. Si se definen $c=a+b$, 
$d=b+1$, entonces $e=c*d$. Si los nodos de entrada del grafo son $a$ y 
$b$, que se conectan con los nodos $c$ y $d$, los cuales a su vez se 
conectan con $e$, los seis bordes contienen las derivadas $\partial 
c/\partial a$, $\partial c/\partial b$, $\partial d/\partial b$, 
$\partial e/\partial c$, $\partial e/\partial d$. Por lo tanto,
 $$
 \frac{\partial e}{\partial b} =
 \frac{\partial d}{\partial b}\cdot
 \frac{\partial e}{\partial d} +
 \frac{\partial c}{\partial b}\cdot
 \frac{\partial e}{\partial c},
 $$
 que es la regla de la cadena de las derivadas de funciones de muchas 
variables. Las derivadas de los grafos computacionales se hacen con 
propagaci\'on hacia atr\'as.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 \vspace{3cm}
 \DIVIDE{1.}{2.}{\sins}
 \DIVIDE{1.73205}{2.}{\coss}
 \MULTIPLY{9.}{\coss}{\yc}
 \MULTIPLY{9.}{\sins}{\xc}
 \ADD{20.}{\xc}{\xu}
 \ADD{10.}{\yc}{\yu}
 \SUBTRACT{60.}{\xc}{\xd}
 \ADD{10.}{\yc}{\yd}
 \ADD{60.}{\xc}{\xt}
 \ADD{10.}{\yc}{\yt}
 \ADD{40.}{\xc}{\xcu}
 \ADD{30.}{\yc}{\ycu}
 \SUBTRACT{80.}{\xc}{\xci}
 \ADD{30.}{\yc}{\yci}
 \setlength{\unitlength}{.1cm}
 \begin{picture}(100,40)
 \linethickness{3pt}
 \thicklines
 \put(20,10){\circle{18}}
 \put(60,10){\circle{18}}
 \put(40,30){\circle{18}}
 \put(80,30){\circle{18}}
 \put(60,50){\circle{18}}
 \put(\xu,\yu){\vector(1.,1.){8}}
 \put(\xd,\yd){\vector(-1.,1.){8}}
 \put(\xt,\yt){\vector(1.,1.){8}}
 \put(\xcu,\ycu){\vector(1.,1.){8}}
 \put(\xci,\yci){\vector(-1.,1.){8}}
 \put(15,20){\textbf{$\partial c/\partial a$}}
 \put(41,17){\textbf{$\partial c/\partial b$}}
 \put(69,17){\textbf{$\partial d/\partial b$}}
 \put(35,41){\textbf{$\partial e/\partial c$}}
 \put(75,41){\textbf{$\partial e/\partial d$}}
 \put(19,10){\textbf{$a$}}
 \put(59,10){\textbf{$b$}}
 \put(32,30){\textbf{$c=a+b$}}
 \put(72,30){\textbf{$d=b+1$}}
 \put(52,50){\textbf{$e=c\times d$}}
 \put(72,1){\framebox{\textbf{$\displaystyle
 \frac{\partial e}{\partial b} =
 \frac{\partial d}{\partial b}\cdot
 \frac{\partial e}{\partial d} +
 \frac{\partial c}{\partial b}\cdot
 \frac{\partial e}{\partial c}
 $}}}
 \end{picture}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Crecimiento Exponencial}

 \setlength{\unitlength}{.1cm}
 \begin{picture}(120,11)
 \linethickness{3pt}
 \thicklines
 \put(20,1){\framebox(10,10){$\Huge X$}}
 \put(60,1){\framebox(10,10){$\Huge Y$}}
 \put(100,1){\framebox(10,10){$\Huge Z$}}
 \put(31,1){\vector(1.,0.){28}}
 \put(71,1){\vector(1.,0.){28}}
 \put(31,6){\vector(1.,0.){28}}
 \put(71,6){\vector(1.,0.){28}}
 \put(31,11){\vector(1.,0.){28}}
 \put(71,11){\vector(1.,0.){28}}
 \put(42,2.3){\textbf{$\alpha$}}
 \put(42,7.3){\textbf{$\beta$}}
 \put(42,12.3){\textbf{$\gamma$}}
 \put(82,2.3){\textbf{$\zeta$}}
 \put(82,7.3){\textbf{$\epsilon$}}
 \put(82,12.3){\textbf{$\delta$}}
 \end{picture}

 La derivada de la salida respecto a la entrada, en modo hacia adelante,
 $$
 \frac{\partial Z}{\partial X} = (\alpha\delta + \alpha\epsilon + 
 \alpha\zeta) +
 (\beta\delta + \beta\epsilon + \beta\zeta) +
 (\gamma\delta + \gamma\epsilon + \gamma\zeta).
 $$
 $$
 \frac{\partial\phantom{.}.\phantom{.}}{\partial X} 
 \quad
 \bm{\Longrightarrow}
 $$
 \hspace{-1cm}
 \setlength{\unitlength}{.1cm}
 \begin{picture}(140,28)
 \linethickness{3pt}
 \thicklines
 \put(20,1){\framebox(15,27){$\displaystyle\frac{\partial 
 X}{\partial X} = 1$}}
 \put(60,1){\framebox(20,27){$
 \begin{array}{c}
 \displaystyle\frac{\partial Y}{\partial X} = \\\\
 \alpha + \beta + \gamma
 \end{array}$}}
 \put(100,1){\framebox(25,27){$
 \begin{array}{c}
 \displaystyle\frac{\partial Z}{\partial X} = \\\\
 (\alpha + \beta + \gamma)\times \\
 (\delta + \epsilon + \zeta)
 \end{array}$}}
 \put(36,1){\vector(1.,0.){23}}
 \put(36,14){\vector(1.,0.){23}}
 \put(36,28){\vector(1.,0.){23}}
 \put(81,1){\vector(1.,0.){18}}
 \put(81,14){\vector(1.,0.){18}}
 \put(81,28){\vector(1.,0.){18}}
 \put(46,2.7){\textbf{$\alpha$}}
 \put(46,14.7){\textbf{$\beta$}}
 \put(46,28.7){\textbf{$\gamma$}}
 \put(88,2.7){\textbf{$\zeta$}}
 \put(88,14.7){\textbf{$\epsilon$}}
 \put(88,28.7){\textbf{$\delta$}}
 \end{picture}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 La derivada de la salida respecto a la entrada, en modo hacia atr\'as,
 $$
 \frac{\partial Z}{\partial X} = (\alpha + \beta + \gamma)\times
 (\delta + \epsilon + \zeta).
 $$
 $$
 \frac{\partial Z}{\partial\phantom{.}.\phantom{.}}
 \quad
 \bm{\Longleftarrow}
 $$
 \hspace{-1cm}
 \setlength{\unitlength}{.1cm}
 \begin{picture}(140,28)
 \linethickness{3pt}
 \thicklines
 \put(20,1){\framebox(25,27){$
 \begin{array}{c}
 \displaystyle\frac{\partial Z}{\partial X} = \\\\
 (\alpha + \beta + \gamma)\times \\
 (\delta + \epsilon + \zeta)
 \end{array}
 $}}
 \put(60,1){\framebox(20,27){$
 \begin{array}{c}
 \displaystyle\frac{\partial Z}{\partial Y} = \\\\
 \delta + \epsilon + \zeta
 \end{array}$}}
 \put(100,1){\framebox(15,27){$
 \displaystyle\frac{\partial 
 Z}{\partial Z} = 1
 $}}
 \put(46,1){\vector(1.,0.){13}}
 \put(46,14){\vector(1.,0.){13}}
 \put(46,28){\vector(1.,0.){13}}
 \put(81,1){\vector(1.,0.){18}}
 \put(81,14){\vector(1.,0.){18}}
 \put(81,28){\vector(1.,0.){18}}
 \put(50,2.7){\textbf{$\alpha$}}
 \put(50,14.7){\textbf{$\beta$}}
 \put(50,28.7){\textbf{$\gamma$}}
 \put(88,2.7){\textbf{$\zeta$}}
 \put(88,14.7){\textbf{$\epsilon$}}
 \put(88,28.7){\textbf{$\delta$}}
 \end{picture}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Ventaja de la Diferenciaci\'on Hacia Atr\'as}

En la diferenciaci\'on hacia adelante respecto a una de las unidades de 
entrada, se requiere calcular la derivada en cada nodo respecto a dicha 
variable.

En la diferenciaci\'on hacia atr\'as, se requiere calcular la derivada 
de una de las variables de salida en cada nodo respecto la variable de 
cada nodo, no respecto cada variable de entrada. Esto implica un 
n\'umero de operaciones menor por un factor igual al n\'umero de 
variables de entrada. Eso representa un menor n\'umero de operaciones, 
lo cual es significativo cuando se tienen RN con millones de nodos.

La propagaci\'on hacia atr\'as ayuda a comprender c\'omo fluyen las 
derivadas a lo largo del modelo. Las derivadas son esenciales, deben 
evaluarse de manera sistem\'atica, lo cual requiere m\'etodos 
especiales, tales como linealizaci\'on y programaci\'on din\'amica.

 Esta idea es otro ejemplo de ``inteligencia artificial''.

 \end{frame}

%-------------------------------------------------------------------

 \section{Redes Neuronales Convolucionales (CNN)}
 \begin{frame}{RN Convolucionales}

Son similares a las RN en general, pero est\'an adaptadas a situaciones 
en las cuales la entrada contiene informaci\'on ``redundante'' o que 
contiene detalles que pueden omitirse sin graves consecuencias.

Es el caso de las im\'agenes, las cuales admiten diferentes 
procedimientos de compresi\'on. Una imagen 2D se puede representar con 
un n\'umero de bits igual a largo$\times$ancho$\times$profundidad, donde 
largo y ancho son los pixeles y profundidad representa otros atributos 
como colores y tonos de gris. Im\'agenes de baja resoluci\'on como las 
de CIFAR-10 requieren 32$\times$32$\times$3 = 3072 bits. Una imagen de 
resoluci\'on moderada 200$\times$200$\times$3 = 120000 bits. Cuando se 
tengan muchas de estas \'ultimas ciertamente habr\'a dificultades 
computacionales.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

La ``correlaci\'on'' o correlaci\'on cruzada de dos funciones de una 
variable discreta y de dos variables discretas, se define por
 $$
 y(n) = (x*h)(n) = \sum\limits_{k=-\infty}^\infty x(k)h(n-k).
 $$
 $$
 (x*h)(m,n) =
 \sum\limits_{j=-\infty}^\infty\sum\limits_{k=-\infty}^\infty
 x(j,k)h(m-j,n-k).
 $$
 Es una suma de productos de valores de dos funciones punto a punto, 
sometidas a un desajuste.

\texttt{http://cs231n.stanford.edu/} es un curso sobre CNN. 
\texttt{https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/} 
contiene una explicaci\'on intuitiva acerca de las redes neuronales 
convolucionales. Tambi\'en es interesante 
\texttt{http://cs231n.github.io/convolutional-networks/}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

La t\'ecnica de CNN opera sobre los mencionados ``vol\'umenes''. Utiliza 
un ``filtro'' de dimensi\'on menor que se mueve a lo largo de toda la 
imagen original. En el camino se realiza el producto entre la imagen y 
el filtro, lo cual da lugar a una serie de trozos m\'as peque\~nos. Por 
eso se supone que las CNN son apropiadas para extraer propiedades que no 
dependan dr\'asticamente de la posici\'on.

Por ejemplo, si la imagen original es 32$\times$32$\times$3 y el filtro 
es 5$\times$5$\times$3, la operaci\'on la convierte en 
28$\times$28$\times$1. En efecto, hay 28$\times$28 posiciones \'unicas 
donde el filtro puede colocarse sobre la imagen original. Otro ejemplo: 
con una imagen 4$\times$4$\times$3 y un filtro 2$\times$2$\times$3, el 
cual se puede deslizar de 3$\times$3=9 maneras distintas sobre la 
imagen, da lugar a 3$\times$3$\times$1. La palabra convoluci\'on 
representa la acci\'on de deslizar el filtro y sumar los productos de 
las respectivas unidades en coincidencia.

 \end{frame}

%-------------------------------------------------------------------
%-------------------------------------------------------------------
%-------------------------------------------------------------------


\begin{frame}{Resumen}

\vfill

Se presentan los conceptos b\'asicos del aprendizaje autom\'atico (AA). 
Se hace \'enfasis en los m\'etodos llamados redes neuronales, en 
especial en las redes neuronales de Hopfield, la m\'aquina de Boltzmann 
y las redes neuronales de muchas capas. Se ilustra lo anterior con 
algunos ejemplos. Se comentan algunos paquetes de redes neuronales como 
el Pytorch y se ilustra su uso con algunos ejemplos, entre ellos el 
reconocimiento de im\'agenes.

% Se discute la aplicaci\'on de dichos m\'etodos en ciertos problemas de 
% f\'{\i}sica at\'omica y molecular.

\vfill

\end{frame}

%-------------------------------------------------------------------

 \section{Introducci\'on}
 \begin{frame}{Introducci\'on}

La llamada inteligencia artificial busca m\'etodos para realizar 
inferencias a partir de ciertos datos. El programa debe ``aprender'' de 
los datos de entrada y luego ``tomar decisiones''. Se acostumbra 
clasificar los m\'etodos de aprendizaje autom\'atico en las siguientes 
categor\'{\i}as: (1) Aprendizaje supervisado, en el cual se ingresan 
datos de entrenamiento (en la forma de caracter\'{\i}sticas 
acompa\~nadas de la correspondiente clasificaci\'on), con la esperanza 
de que luego el programa le asigne el \'{\i}ndice de clasificaci\'on a 
un dato nuevo no usado en el entrenamiento. (2) En el no supervisado no 
se da un ``entrenamiento'' sino unos datos sin clasificaci\'on, de los 
cuales se espera que el programa los agrupe e identifique 
caracter\'{\i}sticas comunes en cada agrupamiento. (3) El aprendizaje de 
refuerzo posee un tipo de realimentaci\'on o ``recompensa'', dependiente 
de la cual el programa se alimenta con los datos que dan lugar a 
maximizaci\'on de la recompensa.

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{}

El aprendizaje autom\'atico busca entender e implementar los 
procedimientos que les permitir\'{\i}an a las computadoras ``aprender''. 
Involucra diferentes disciplinas de las ciencias de la computaci\'on, 
como la estad\'{\i}stica computacional y la complejidad computacional. 
Se relaciona con problemas matem\'aticos no resueltos como son la 
determinaci\'on del grado de dificultad de los algoritmos, el cual puede 
ser polinomial o exponencial.

Es un campo interdisciplinario que involucra la estad\'{\i}stica, 
problemas matem\'aticos de optimizaci\'on, las ciencias de la 
computaci\'on, algunas ramas de la ingenier\'{\i}a, ciencias de la 
cognici\'on y el lenguaje, y ramas de la filosof\'{\i}a tales como la 
l\'ogica y la epistemolog\'{\i}a.

Tiene aplicaciones m\'ultiples, tales como los sistemas de b\'usqueda, 
protocolos de diagn\'osticos m\'edicos, reconocimiento de patrones y 
rostros, traductores y sintetizadores de voz, secuenciaci\'on 
gen\'omica, sistemas expertos y rob\'otica. En f\'{\i}sica hay muchas 
aplicaciones, como los experimentos LIGO, BICEP, LHC, estudios de 
estructura y espectro de mol\'eculas, etc.

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{Modelos}

\textbf{Modelos geom\'etricos}. Los estados de un sistema se representan 
como vectores en un expacio multidimensional. Se pueden agrupar en 
clases, identificadas por cierta caracter\'{\i}stica com\'un. Por lo 
tanto las clases son subespacios de estados. La pregunta b\'asica es la 
determinaci\'on de la clase a la cual pertenece un estado (dato) dado. 
Dicha clasificaci\'on involucra conceptos geom\'etricos, tales como 
conexidad, distancia, perpendicularidad, paralelismo, etc.

\textbf{Modelos probabil\'{\i}sticos}. La pertenencia a determinada 
clase puede establecerse mediante una distribuci\'on de probabilidades. 
Se suele usar la estad\'{\i}stica bayesiana.

\textbf{Modelos l\'ogicos}. Ejemplos de tales modelos son los llamados 
\'arboles de decisi\'on.

 \end{frame}

%-------------------------------------------------------------------

 \section{Algoritmos}
 \begin{frame}{Algoritmos Supervisados}

El programa tiene como entrada pares de datos, $(\bm{x}_i,y_i)$, que se 
usan como ``entrenamiento de la m\'aquina''. $\bm{x}_i$ es un vector de 
$D$ componentes y, usualmente, $y_i$ es un escalar que toma dos valores. 
$i=1,2,...N$ es un \'{\i}ndice que recorre los $N$ datos.

La salida, por su parte, suele darse como los par\'ametros de una 
funci\'on de regresi\'on lineal o no lineal.

El objetivo del aprendizaje supervisado es crear una funci\'on que 
permita hacer predicciones, es decir responder cuestiones que no est\'an 
presentes en los datos de entrada.

Un ejemplo muy simple es la regresi\'on lineal. Dadas $N$ parejas de 
datos $(x_i,y_i)$, encontrar los par\'ametros $\beta_0$ y $\beta_1$ de 
una funci\'on lineal tal que
 $$
 y_i = \beta_0 + \beta_1 x_i;\quad i=1,2,...N.
 $$ El modelo permite predecir el valor de $\hat{y}$ correspondiente a 
un dato $\hat{x}$ no presente en los datos, $\{x_1,x_2,...x_N\}$, usados 
para definir los par\'ametros, $\beta_0$ y $\beta_1$, de la regresi\'on.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

La clasificaci\'on es un ejemplo simple de reconocimiento de patrones. 
Por ejemplo, dados los tipos de sangre A, B, AB, O, encontrar el tipo al 
cual pertenece una muestra dada.

La \textbf{clasificaci\'on} pretende determinar a cu\'al categor\'{\i}a 
pertenece una nueva observaci\'on, dentro de un conjunto de 
categor\'{\i}as predefinido. El algoritmo se llama clasificador.

Terminolog\'{\i}a: Casos son las observaciones. Variables explicativas 
son las caracter\'{\i}sticas. Clases son las posibles categor\'{\i}as 
que agrupan caracter\'{\i}sticas.

\textbf{Ejemplo}. Uso de una fuente de voltaje para establecer una 
clasificaci\'on binaria. A los voltajes $V\le0.5V$ se les asigna la 
clase del bit $0$. A los voltajes $V>0.5V$ se les asigna la clase del 
bit $1$.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 Distribuci\'on de probabilidades.

 \vfill
 \centerline{\psfig{figure=Prob0.eps,width=0.5\hsize}\psfig{figure=Prob1.eps,width=0.5\hsize}}

 \centerline{$Plot[c[x, \{"Probability", "0"\}], \{x, 0, 1\}].
 $Plot[c[x, \{"Probability", "1"\}], \{x, 0, 1\}].}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{El Perceptr\'on}

Modela una \textbf{neurona}. Recibe $D$ entradas, $x_1$, ... $x_D$, 
chequea el resultado y produce una salida. Realiza una \textbf{suma} 
ponderada de las entradas, chequea el resultado y dependiendo del mismo 
produce una salida. Se usa para clasificar datos que se agrupan en 
clases separables linealmente (la m\'as simple es la clasificaci\'on 
binaria).

En el perceptr\'on de una capa se tienen $D$ datos de entrada, $x_1$, 
... $x_D$. Cada entrada tiene asociado un peso $w_1$, ... $x_D$.
La suma es
 $$
 s = \sum\limits_{i=1}^Dw_ix_i.
 $$
 La salida est\'a determinada por cierta \textbf{funci\'on de 
activaci\'on}, $f(s)$.

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{Una ``Red'' que Produce la Puerta NOT}

Es trivial porque s\'olo hay una entrada, $x$, y una salida, $y$, ambas 
binarias. La salida deseable es el NOT de la entrada. Es decir, que si 
$x=0$ entonces $y=1$ y si $x=1$ entonces $y=0$.

N\'otese que si se hace $w=1$, entonces $s=x$. Si se toma como funci\'on 
de activaci\'on la \texttt{identidad} entonces $f(s)=s$. Resulta 
as\'{\i} la puerta l\'ogica identidad. Sin embargo, si se suma cierta 
cantidad $\theta$, llamada en ingl\'es ``\textit{bias}'' (que se puede 
traducir como ``sesgo'', ``polarizaci\'on'' o ``desplazamiento''), puede 
lograrse la puerta l\'ogica NOT,
 $$
 s = w\cdot x + \theta,\ y= f(s).
 $$
 As\'{\i}, tomando $w=1$, $\theta=1$ se obtiene $f(s)=w\cdot x + 
\theta=1\cdot x+1=x+1$, lo cual, con suma en la base binaria, da $0+1=1$ 
y $1+1=0$.

Puede verse que la funci\'on de activaci\'on se define por conveniencia, 
de acuerdo al problema que se tenga.

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{Conexi\'on Con el Mapa Log\'{\i}stico}

Una funci\'on de activaci\'on muy usada es la log\'{\i}stica o sigmoide,
 $$
 f(z) = \frac{1}{1+e^{-z}},
 $$
 cuya derivada tiene la propiedad $f'(z) = f(z)[1-f(z)]$.

Si llamamos $x_n = f(z)$ y $x_{n+1} = f(z+\Delta)$, la derivada de la 
funci\'on log\'{\i}stica se puede escribir como,
 $$
 \frac{x_{n+1} - x_n}{\Delta} = x_n (1-x_n) \to x_{n+1} = (1+\Delta)
 x_n - \Delta\cdot x_n^2.
 $$
 Con el cambio de escala
 $$
 x_n\to\frac{1+\Delta}{\Delta}x_n,
 $$
 se llega al mapa log\'{\i}stico $x_{n+1} = r x_n(1-x_n)$, donde 
$r=1+\Delta$.

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{Perceptr\'on y Sigmoide}

 \vfill
 \centerline{\psfig{figure=Perceptron.eps,height=0.4\hsize,width=0.5\hsize}\psfig{figure=Sigmoide.eps,height=0.4\hsize,width=0.5\hsize}}

 \centerline{Perceptr\'on de una sola capa. \hfill Sigmoide\hfill}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{Perceptr\'on de Muchas Capas (MLP)}

Un perceptr\'on de muchas capas (o red neuronal artificial) con una sola 
capa oculta se puede representar gr\'aficamente como sigue:

 \setlength{\unitlength}{.1cm}
 \begin{picture}(100,20)
 \linethickness{3pt}
 \thicklines
 \put(12,3){\circle*{3}}
 \put(32,3){\circle*{3}}
 \put(52,3){\circle*{3}}
 \put(2,10){\circle*{3}}
 \put(22,10){\circle*{3}}
 \put(42,10){\circle*{3}}
 \put(62,10){\circle*{3}}
 \put(22,17){\circle*{3}}
 \put(42,17){\circle*{3}}
 \put(12,3){\vector(-10,7){9.2}}
 \put(12,3){\vector(10,7){9.2}}
 \put(12,3){\vector(30,7){29}}
 \put(12,3){\vector(50,7){49}}
 \put(2,10){\vector(20,7){19}}
 \put(2,10){\vector(40,7){39}}
 \put(68,3){\textbf{Capa de entrada}}
 \put(68,10){\textbf{Capa oculta}}
 \put(68,17){\textbf{Capa de salida}}
 \end{picture}

Un MLP es una funci\'on $F:R^I\to R^O$, donde $I$ es el tama\~no del 
vector de entrada y $O$ del de salida, tal que,
 $$
 F(x) = f\{b^{(2)} + W^{(2)}[g(b^{(1)} + W^{(1)}x)]\},
 $$
 donde $b^{(1)}$ y $b^{(2)}$ son vectores de sesgo, $W^{(1)}$ y 
$W^{(2)}$ son matrices de pesos, y $f$ y $s$ son funciones de 
activaci\'on. El vector $h(x)=g(b^{(1)} + W^{(1)}x)$ constituye la capa 
oculta. $x$ es la entrada y $F(x)$ la salida. $W^{(1)}\in R^{(I\times 
H)}$, donde $H$ es el tama\~no del vector oculto, es la matriz de peso 
que conecta el vector de entrada $x$ a la capa oculta $h(x)$.

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{}

Son de inter\'es las funciones de activaci\'on $f$ llamadas 
``\textit{tanh}'', con $\tanh(z)=(e^z-e^{-z})/(e^z+e^{-z})$, y la 
``\textit{sigmoide}'' log\'{\i}stica, con $\textrm{sigmoide}(z) = 
1/(1+e^{-z})$. Tanto $tanh$ como $sigmoide$ son funciones $R\to R$ pero 
tienen extensi\'on natural a vectores, aplic\'andolas a cada componente 
por separado. El vector de salida se obtiene como $o(x) = f[b^{(2)} + 
W^{(2)} h(x)]$.
 
Para entrenar un MLP, se determinan todos los par\'ametros del modelo a 
partir de los datos de entrenamiento. Para ello se puede usar el 
algoritmo del descenso estoc\'astico del gradiente. El conjunto de 
par\'ametros resultantes es $\theta = 
\{W^{(2)},b^{(2)},W^{(1)},b^{(1)}\}$. La obtenci\'on de los gradientes 
$\partial{\ell}/\partial{\theta}$ se puede lograr mediante un algoritmo 
de propagaci\'on hacia atr\'as. $\ell$ es la llamada funci\'on de 
p\'erdida, en t\'erminos de la cual se define cierto problema de 
optimizaci\'on.

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{Regresi\'on Log\'{\i}stica}

Se define
 $$
 h_{\bm{w}}(\bm{x}) = f(\bm{w}\cdot\bm{x}),
 $$
 donde $f(z)$ es la funci\'on de activaci\'on log\'{\i}stica y $\bm{x}$ 
y $\bm{w}$ son vectores de dimensi\'on $D+1$, con $x_0=1$,
 $$
 \bm{w}\cdot\bm{x} = w_0 + \sum\limits_{i=1}^Dw_ix_i.
 $$

El problema de regresi\'on consiste en ajustar $\bm{w}$ conociendo $N$ 
series de datos $\bm{x} = \{1,x_1,...x_D\}$. Una manera simple es usar 
el ajuste de m\'{\i}nimos cuadrados. Otra es maximizar una funci\'on de 
\textbf{plausibilidad}. Llamamos $x_i$ a las componentes del vector 
$\bm{x}$ y $\bm{x}_\lambda$, con $\lambda=1,...N$ las N realizaciones 
del mismo.

Suponemos que a la entrada $\bm{x}_\lambda$ le corresponde una salida 
del perceptr\'on $y_\lambda$, la cual puede ser $y=0$ o $y=1$ 
(perceptr\'on binario).

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

El modelo probabil\'{\i}stico del perceptr\'on postula las 
probabilidades condicionales de $y=0$, $y=1$, as\'{\i},
 $$
 P(y=1\vert\bm{x};\bm{w}) = h_{\bm{w}}(\bm{x}),\quad 
 P(y=0\vert\bm{x};\bm{w}) = 1 - h_{\bm{w}}(\bm{x}),
 $$
 o, en general,
 $$
 P(y\vert\bm{x};\bm{w}) = h_{\bm{w}}(\bm{x})^y
 [1 - h_{\bm{w}}(\bm{x})]^{1-y}.
 $$

Dado el conjunto de observaciones $\{\bm{x}_\lambda,y_\lambda\}$, para 
$\lambda=1,...N$, el cual denotamos por $\{\bm{X},Y\}$, se define la 
\textbf{funci\'on de plausibilidad} $L$ por
 $$
 L(\bm{w}) = P(Y\vert\bm{X};\bm{w}) = \prod\limits_{\lambda=1}^N 
 P(y_\lambda\vert\bm{x}_\lambda;\bm{w}) = \prod\limits_{\lambda=1}^N 
 h_{\bm{w}}(\bm{x}_\lambda)^{y_\lambda} [1 - 
 h_{\bm{w}}(\bm{x}_\lambda)]^{1-y_\lambda}.
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Maximizaci\'on de la Funci\'on de Plausibilidad}

 $$
 \begin{array}{rcl}
 l(\bm{w}) = \log L(\bm{w}) &=& \log P(Y\vert\bm{X};\bm{w}) \\
 &=&\sum\limits_{\lambda=1}^N\{ y_\lambda \log h_{\bm{w}}(\bm{x}_\lambda) 
 + (1-y_\lambda) \log[1 - h_{\bm{w}}(\bm{x}_\lambda)]\}.
 \end{array}
 $$
 Se procede a la maximizaci\'on usando el m\'etodo del \textbf{ascenso 
del gradiente}. Se basa en que la funci\'on multidimensional, para 
cualquier $\bm{a}$ cercano al $\bm{w}$ en el cual es m\'axima tiene un 
gradiente con una componente orientada hacia el m\'aximo. Mientras m\'as 
cerca est\'e $\bm{a}$ del m\'aximo, m\'as peque\~na ser\'a la otra 
componente del gradiente. Eso permite establecer la siguiente regla para 
actualizar el punto $\bm{a}$ con el fin de acercarlo al m\'aximo,
 $$
 \bm{a}\to\bm{a}+\eta\frac{\partial l(\bm{w})}{\partial\bm{w}},
 $$
 donde $\eta$ es una constante positiva.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

Usando las propiedades de la funci\'on sigmoide se halla que
 $$
 \frac{\partial l(\bm{w})}{\partial\bm{w}} = [y -
 h_{\bm{w}}(\bm{x})]\bm{x} = \sum\limits_{\lambda=1}^N[y_\lambda -
 h_{\bm{w}}(\bm{x}_\lambda)]\bm{x}_\lambda.
 $$
 Por lo tanto,
 $$
 \bm{a}\to\bm{a}+\eta\sum\limits_{\lambda=1}^N[y_\lambda -
 h_{\bm{w}}(\bm{x}_\lambda)]\bm{x}_\lambda.
 $$
 Un criterio de parada del algoritmo puede formularse estableciendo 
cierto umbral $\epsilon$, tal que
 $$
 N\eta\frac{1}{N}\sum\limits_{\lambda=1}^N\vert y_\lambda -
 h_{\bm{w}}(\bm{x}_\lambda)\vert
 \frac{1}{N}\sum\limits_{\mu=1}^N\vert\bm{x}_\mu\vert<\epsilon.
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Inferencia Bayesiana}

Un ejemplo de inferencia bayesiana se encuentra en la clasificaci\'on 
supervisada de los clientes de un banco. Si $\bm{x}$ es un vector que 
describe el perfil de ingresos del cliente y $c$ indica la clase de 
riesgo a la cual pertenece el cliente, se pueden definir las siguientes 
probabilidades.

$p(c)$: probabilidad de pertenecer a la clase $c$.

$p(\bm{x})$: probabilidad de que el cliente tenga ingresos definidos por 
$\bm{x}$.

$p(c\vert\bm{x})$: probabilidad condicional de asignar la clase $c$ 
cuando los ingresos son $\bm{x}$.

$p(\bm{x}\vert c)$: probabilidad condicional de asignar ingresos 
$\bm{x}$ cuando se sabe que pertenece a la clase $c$.

La f\'ormula de Bayes dice que,
 $$
 p(c\vert\bm{x}) = p(\bm{x}\vert c) \frac{p(c)}{p(\bm{x})}.
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Enfoque Probabil\'{\i}stico del ANS}

Dada una secuencia de datos de entrada, $x_1$, ... $x_{t-1}$, se quiere 
deducir la distribuci\'on de probabilidades del dato que sigue, $x_t$. 
El aprendizaje debe modelar
 $$
 P(x_t\vert x_1,...x_{t-1}).
 $$
 Una simplificaci\'on consiste en considerar que el orden de los datos 
$x_1$, ... $x_{t-1}$ es irrelevante. Eso significa que los datos son 
independientes y todos est\'an descritos por la misma distribuci\'on de 
probabilidades
 $$
 P(x).
 $$
 Este modelo puede usarse para monitorear o detectar entradas 
``extra\~nas''.

Por ejemplo, se tiene un registro de los valores diarios de determinada 
divisa. A partir de los datos previos se deduce la probabilidad del 
valor siguiente. Si ese valor es anormalmente bajo (o alto), entonces 
bien ocurri\'o una intervenci\'on an\'omala en el mercado, o el modelo 
es incorrecto.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Regla de Bayes y Estad\'{\i}stica del AA}

\textbf{Problema}: Dise\~nar una m\'aquina que reciba hip\'otesis acerca 
de cierto fen\'omeno y que pueda modificar tales hip\'otesis a medida 
que reciba nuevos datos. La plausibilidad de tales hip\'otesis debe 
expresarse en forma num\'erica.

$P(X=x)$ se puede interpretar como la frecuencia con la cual la variable 
aleatoria $X$ toma el valor $x$ (estad\'{\i}stica frecuentista), o como 
el grado de creencia en que la variable aleatoria $X$ tome el valor $x$ 
(estad\'{\i}stica bayesiana).

Similarmente, $P(X=x\vert Y=y)$ se puede usar para representar el grado 
de creencia en que $X$ tome el valor $x$ dado que uno sabe que $Y$ vale 
$y$.

Sea $\Omega$ el conjunto de hip\'otesis posibles, $\Omega=\{1,...M\}$, 
cuyos elementos son $m\in\Omega$. Cada hip\'otesis tiene una 
probabilidad $P(m)$,
 $$
 \sum\limits_{m=1}^M P(m)=1.
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 Un modelo es la distribuci\'on de probabilidades de los datos 
correspondientes a las hip\'otesis, son las ``probabilidades previas'',
 $$
 P(x\vert m).
 $$
 Se supone que en cada modelo $m$ los datos $x$ son independientes y 
uniformemente distribuidos.

Luego de observar un conjunto de datos $\mathcal{D} = \{x_1,...x_N\}$, 
las creencias sobre el modelo $m$ cambian, son las ``probabilidades 
posteriores'',
 $$
 P(m\vert\mathcal{D}) = \frac{P(m)P(\mathcal{D}\vert m)}{P(\mathcal{D})}
 \propto P(m) \sum\limits_{i=1}^NP(x_i\vert m).
 $$
 La ``plausibilidad'' de un dato $x_i$, soportada en el modelo $m$, es 
$P(x_i\vert m)$. Es decir, el ``posterior'' del modelo $m$ es igual al 
``previo'' multiplicado por la plausibilidad normalizada.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

La hip\'otesis de que los datos son independientes e id\'enticamente 
distribuidos, ``datos no estructurados'', conduce a la distribuci\'on 
predictiva sobre nuevos datos, la cual puede usarse para codificar 
nuevos datos eficientemente,
 $$
 P(x\vert\mathcal{D}) = \sum\limits_{m=1}^M P(x\vert m) P(m
 \vert\mathcal{D}).
 $$

Los datos no independientes o no distribuidos id\'enticamente (datos 
estructurados) requieren otros modelos. Es el caso de ciertas 
``trayectorias'' o series de tiempo. Un modelo probabil\'{\i}stico debe 
dar cuenta de que la observaci\'on en el tiempo $t$ (presente) no es 
independiente de las observaciones previas, tiene la forma,
 $$
 P(y_t\vert y_{t-1},y_{t-2}, ...y_{-1}).
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 La historia de las observaciones puede crecer mucho, lo cual 
dificultar\'{\i}a la modelaci\'on. Se requieren aproximaciones. Por 
ejemplo, la de Markov de primer orden,
 $$
 P(y_t\vert y_{t-1}),
 $$
 o la de Markov de segundo orden,
 $$
 P(y_t\vert y_{t-1},y_{t-2}).
 $$
 Sin embargo, puede no ser realista establecer conexiones entre datos 
consecutivos, porque hay situaciones en las cuales los datos tienen 
comportamientos colectivos.

Otra aproximaci\'on es la de variables ocultas o latentes. En vez de 
suponer que $y_{t-1}$ determina a $y_t$ se supone que hay una variable 
oculta $x_t$ que captura una din\'amica determinista del sistema (por 
eso se llama variable de estado), y por lo tanto recoge todos los datos 
previos.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Algoritmos de Aprendizaje de Refuerzo}

La m\'aquina recibe datos $x_1,...$ del entorno y dependiendo de los 
mismos realiza acciones $a_1,...$ Esas acciones modifican el estado del 
entorno, lo cual a su vez implica que el entorno reacciona 
entreg\'andole a la m\'aquina recompensas (o castigos) $r_1,...$ La meta 
de la m\'aquina es aprender a actuar de modo que se maximicen las 
futuras recompensas que haya de recibir (o se minimicen los castigos) 
durante su tiempo de vida. El aprendizaje de refuerzo se relaciona con 
la \textbf{teor\'{\i}a de decisi\'on} (estad\'{\i}stica y 
administraci\'on) y la teor\'{\i}a del control autom\'atico 
(ingenier\'{\i}a).

Una variante es la \textbf{teor\'{\i}a de juegos}. La m\'aquina consigue 
entradas, produce acciones, recibe recompensas y aprende. Sin embargo, 
el entorno con el cual interact\'ua la m\'aquina no es est\'atico, sino 
que est\'a formado por otras m\'aquinas que hacen lo mismo que la 
primera: Consiguen datos de entrada, producen salidas, act\'uan sobre 
las otras m\'aquinas, reciben recompensas por las salidas, aprenden. La 
meta de la m\'aquina es aprender a actuar de modo que se maximicen las 
recompensas.

 \end{frame}

%-------------------------------------------------------------------

 \section{Modelos de Redes Neuronales}
 \begin{frame}{Modelos de RN}

Las RN pueden ejemplificarse con los modelos de Hopfield y la llamada 
M\'aquina de Boltzmann Restringida (Restricted Boltzmann Machine o RBM). 
Los mismos se usan, entre otros, en el problema de reconocimiento de 
im\'agenes. Una imagen se puede reducir a un conjunto de ``pixeles'', 
una tira de binarios.

El problema m\'as simple consiste en que si se da un conjunto de 
im\'agenes ``de entrenamiento'', hallar la imagen de este conjunto que 
se parece con mayor probabilidad a una imagen dada.

En la red neuronal de Hopfield se toma un conjunto de datos de 
``entrenamiento'', con los cuales se ajustan los par\'ametros de la red. 
Luego es posible determinar con cu\'al de los datos de entrenamiento 
concuerda con mayor probabilidad una nueva entrada que no necesariamente 
coincide con alguna de las del entrenamiento.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Memoria Asociativa Bidireccional (BAM)}

En una BAM cada patr\'on de entrenamiento se almacena en las conexiones 
entre las componentes de la red, $w_{ij}$. Esto constituye la llamada 
``memoria asociativa''. Cuando recibe un nuevo patr\'on la memoria 
asociativa activa (recuerda) el patr\'on almacenado que m\'as se parece 
a la entrada. Es el llamado perceptr\'on de una capa.

 \setlength{\unitlength}{.13cm}
 \begin{picture}(100,30)
 \linethickness{3pt}
 \thicklines
 \put(12,3){\circle*{4}}
 \put(32,3){\circle*{4}}
 \put(52,3){\circle*{4}}
 \put(12,17){\circle*{4}}
 \put(32,17){\circle*{4}}
 \put(52,17){\circle*{4}}
 \put(12,3){\vector(0,20){12}}
 \put(12,3){\vector(20,14){18}}
 \put(12,3){\vector(40,14){38}}
 \put(32,3){\vector(-20,14){18}}
 \put(32,3){\vector(20,14){18}}
 \put(32,3){\vector(0,7){12}}
 \put(52,3){\vector(0,20){12}}
 \put(52,3){\vector(-20,14){18}}
 \put(52,3){\vector(-40,14){38}}
 \put(12,-3){\vector(0,14){4}}
 \put(32,-3){\vector(0,14){4}}
 \put(52,-3){\vector(0,14){4}}
 \put(12,19){\vector(0,14){4}}
 \put(32,19){\vector(0,14){4}}
 \put(52,19){\vector(0,14){4}}
 \put(68,3){\textbf{Capa de entrada}}
 \put(68,17){\textbf{Capa de salida}}
 \put(10,-6){$\bm{x_1}$}
 \put(30,-6){$\bm{x_2}$}
 \put(50,-6){$\bm{x_3}$}
 \put(10,25){$\bm{y_1}$}
 \put(30,25){$\bm{y_2}$}
 \put(50,25){$\bm{y_3}$}
 \put(6,12){$\bm{w_{11}}$}
 \put(13,8){$\bm{w_{12}}$}
 \put(20,4){$\bm{w_{13}}$}
 \end{picture}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

En una ``memoria asociativa bidireccional'' (BAM), si $\bm{x}_0$ es un 
vector de entrada de $D$ dimensiones y $\bm{y}_0$ el correspondiente 
vector de salida de $F$ dimensiones, la matriz de pesos $W$ tendr\'a 
dimensi\'on $D\times F$. La relaci\'on entre la entrada y la salida es 
(usando SGN como funci\'on de activaci\'on),
 $$
 \bm{y}_0 = SGN(\bm{x}_0\cdot W).
 $$
 En un paso de ``feed-back'', $\bm{y}_0$ es la entrada y $\bm{x}_1$ es 
la salida,
 $$
 \bm{x}_1 = SGN(W\cdot\bm{y}_0^T).
 $$
 Una nueva iteraci\'on de izquierda a derecha produce
 $$
 \bm{y}_1 = SGN(\bm{x}_1\cdot W).
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 Despu\'es de $m$ iteraciones el sistema ha calculado $m+1$ pares de 
vectores $(\bm{x}_0,\bm{y}_0)$, $(\bm{x}_1,\bm{y}_1)$, ... 
$(\bm{x}_m,\bm{y}_m)$, los cuales cumplen las condiciones,
 $$
 \bm{y}_i = SGN(\bm{x}_i\cdot W),\quad
 \bm{x}_{i+1}^T = SGN(W\cdot\bm{y}_i^T).
 $$
 Surge el problema de encontrar un \textbf{punto fijo} 
$(\bm{x},\bm{y})$,
 $$
 \bm{y} = SGN(\bm{x}\cdot W),\quad
 \bm{x}^T = SGN(W\cdot\bm{y}^T).
 $$
 Los mismos bordes se pueden usar para transmitir informaci\'on en las 
dos direcciones. 

Se demuestra que el llamado \textbf{aprendizaje de Hebb} es condici\'on 
para la existencia del punto fijo de una BAM. Esto a su vez determina la 
matriz $W$ adecuada.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Aprendizaje de Hebb}

 Si $N$ es el n\'umero de patrones de entrenamiento (``datos''), donde 
$x_i^k$ es la $k$-\'esima entrada a la neurona $i$, y $y_j^k$ es la 
$k$-\'esima salida de la neurona $j$, el peso de la conexi\'on entre las 
neuronas $i$ y $j$ es
 $$
 w_{ij} = \frac{1}{N} \sum\limits_{k=1}^N x_i^ky_j^k.
 $$
 Es decir, $W = \bm{x}^T\bm{y}$. Entonces,
 $$
 \bm{y} = SGN(\bm{x}\cdot W) = SGN(\bm{x}\cdot\bm{x}^T\bm{y}) =
 SGN(\vert\bm{x}\vert^2\bm{y}) = \bm{y}.
 $$
 Tambi\'en,
 $$
 \bm{x}^T = SGN(W\cdot\bm{y}^T) = SGN(\bm{x}^T\bm{y}\cdot\bm{y}^T) =
 SGN(\bm{x}^T\vert\bm{y}\vert^2) = \bm{x}^T.
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 Para un conjunto de $m$ pares de vectores la matriz $W$ (sim\'etrica) 
es
 $$
 W = \bm{x}_1^T\bm{y}_1 + \bm{x}_2^T\bm{y}_2 + ... \bm{x}_m^T\bm{y}_m.
 $$
 Con las componentes de los vectores $\bm{x}_k$ se pueden formar las 
matrices $X$ y $X^T$. Se cumple
 $$
 X = X\cdot W,\quad X^T = W\cdot X^T,
 $$
 lo cual caracteriza a una BAM.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Funci\'on Energ\'{\i}a}

En una BAM con punto fijo $(X,Y)$, la red converge un vector inicial a 
la izquierda $X_0$ al punto fijo despu\'es de algunas iteraciones.

La excitaci\'on de las unidades en la capa izquierda puede entenderse 
como un vector de excitaci\'on obtenido como
 $$
 e^T = W\cdot Y_0^T.
 $$
 El punto $(X_0,Y_0)$ es estable si
 $$
 SGN(e) = X_0.
 $$
 Todos los $e$ cercanos a $X_0$ cumplen esta condici\'on. Esos vectores 
difieren de $X_0$ por un \'angulo peque\~no, por lo tanto el producto 
$X_0\cdot e^T$ ser\'a mayor para $X_0$ que para otros vectores de igual 
longitud pero alejados de $X_0$. El producto
 $$
 E = -X_0\cdot e^T.
 $$
 es m\'as peque\~no (por el signo menos) si el vector $W\cdot Y_0^T$ se 
sit\'ua m\'as cerca de $X_0$. El escalar $E$ puede usarse para medir 
convergencia hacia los estados estables de una BAM.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 $E$ se llama funci\'on energ\'{\i}a de la red. La energ\'{\i}a de una 
BAM con matriz de peso $W$, en la cual la salida $Y_i$ de la capa 
derecha es calculada en la $i$-\'esima iteraci\'on como
 $$
 Y_i = SGN(X_i\cdot W),
 $$
y la salida $X_i$ de la capa izquierda como
 $$
 X_{i+1}^T = SGN(W\cdot Y_i^T),
 $$
 est\'a dada por
 $$
 E(X_i,Y_i) = -\frac{1}{2}X_i\cdot W\cdot Y_i^T
 -\frac{1}{2}\sum\limits_{\mu,\nu}w_{\mu\nu}x_i^\mu x_j^\nu.
 $$
 La funci\'on energ\'{\i}a tiene m\'{\i}nimos en los estados estables, 
al considerar respuesta del tipo
 $$
 Y_i = SGN(X_i\cdot W),\quad X_{i+1}^T = SGN(W\cdot Y_i^T).
 $$
 Se est\'a tomando como funci\'on de activaci\'on $SGN(\cdot)$.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Funci\'on Energ\'{\i}a con Umbral}

Para introducir el umbral se considera una red con un nodo m\'as, el 
$n+1$,
 $$
 (x_1,x_2, ... x_n;1),\quad (y_1,y_2, ... y_n;1).
 $$
 La matriz de pesos en vez de ser de dimensi\'on $n\times k$ ser\'a 
$(n+1)\times(k+1)$, donde $W_{n+1,k+1} = 0$. Eso equivale a introducir 
un nuevo nodo con salida constante $1$ en cada capa.

Si consideramos los \textbf{datos} $\alpha = 1,2, ...N$ y los 
\textbf{nodos} $i=1,2,...n$, la funci\'on energ\'{\i}a ser\'a
 $$
 E(X,Y) = \frac{1}{2}\sum\limits_\alpha(\bm{x}^\alpha\cdot 
 W\cdot\bm{x}^{\alpha T} + \bm{\theta}_R\cdot\bm{y}^{\alpha T} + 
 \bm{x}^\alpha\cdot\bm{\theta}_L).
 $$
 $\bm{\theta}_R$ es vector de $n$ componentes en la capa derecha y 
$\bm{\theta}_L$ de $k$ componentes en la capa izquierda.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Red Neuronal Asincr\'onica}

Las BAM funcionan como unidades sincronizadas. Si se relaja la 
condici\'on de que los nodos se activen simult\'aneamente, la red 
adquiere nuevas propiedades. Surgen las \textbf{redes asincr\'onicas}.

$\cdot$ Cada nodo calcula su excitaci\'on en tiempos aleatorios.

$\cdot$ Cada nodo cambia su estado a $1$ o $-1$ independientemente de 
los dem\'as.

$\cdot$ Cada nodo cambia su estado de $1$ a $-1$ o de $-1$ a $1$ de 
acuerdo al signo de la excitaci\'on total.

$\cdot$ La probabilidad de que dos nodos se activen simult\'aneamente 
vale cero.

$\cdot$ La din\'amica de cualquier nodo seleccionado al azar es la misma 
(se calcula su excitaci\'on y se actualiza su estado en consecuencia).

$\cdot$ No habr\'a retardo entre el c\'alculo de la excitaci\'on y la 
actualizaci\'on del estado.

$\cdot$ El estado de un nodo no cambia si la excitaci\'on total vale 
cero. Es decir, $SGN(0)$ es indefinido.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

El estado estable
 $$
 Y = SGN(X\cdot W),\quad X^T = SGN(W\cdot Y^T),
 $$
 lo es tanto en la red BAM como en la asincr\'onica.

\textbf{Proposici\'on}. Una memoria asociativa con matriz de peso $W$ 
arbitraria llega a su estado estable (m\'{\i}nima energ\'{\i}a) en un 
n\'umero finito de iteraciones usando tanto actualizaciones 
sincr\'onicas como asincr\'onicas.

\textbf{Definiciones}. Dados $X = (\bf{x}_1, ... \bf{x}_n)$, $Y = 
(\bf{y}_1, ... \bf{y}_k)$ y $W = \{w_{ij}\}$, la funci\'on energ\'{\i}a 
es la forma bilineal
 $$
 E(X,Y) = -\frac{1}{2}
 (x_1, ... x_n)
 \left(
 \begin{array}{ccc}
 w_{11} & \ldots & w_{1k} \\
 \vdots & \vdots & \vdots \\
 w_{n1} & \ldots & w_{nk}
 \end{array}
 \right)
 \left(
 \begin{array}{c}
 y_1 \\
 \vdots \\
 y_k
 \end{array}
 \right).
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 Definimos
 $$
 \left(
 \begin{array}{c}
 g_1 \\
 \vdots \\
 g_n
 \end{array}
 \right) =
 \left(
 \begin{array}{ccc}
 w_{11} & \ldots & w_{1k} \\
 \vdots & \vdots & \vdots \\
 w_{n1} & \ldots & w_{nk}
 \end{array}
 \right)
 \left(
 \begin{array}{c}
 y_1 \\
 \vdots \\
 y_k
 \end{array}
 \right),
 $$
 $$
 (e_1, \ldots e_k) =
 (x_1, \ldots x_n)
 \left(
 \begin{array}{ccc}
 w_{11} & \ldots & w_{1k} \\
 \vdots & \vdots & \vdots \\
 w_{n1} & \ldots & w_{nk}
 \end{array}
 \right).
 $$
 Entonces
 $$
 E(X,Y) = -\frac{1}{2}
(x_1,\ldots x_n)
\left(
 \begin{array}{c}
 g_1 \\
 \vdots \\
 g_n
 \end{array}
 \right) =
 -\frac{1}{2} (e_1,\ldots e_k)
\left(
 \begin{array}{c}
 y_1 \\
 \vdots \\
 y_k
 \end{array}
 \right).
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 Es decir,
 $$
 E(X,Y) = -\frac{1}{2}\sum\limits_{i=1}^ke_iy_i = 
-\frac{1}{2}\sum\limits_{i=1}^ng_ix_i.
 $$
 Si ocurre un cambio en el estado de la celda ``i'' y las dem\'as quedan 
iguales, $x_i\to x_i'$, entonces la energ\'{\i}a tendr\'a un cambio
 $$
 E(X,Y) - E(X',Y) = -\frac{1}{2}(x_i - x_ i')g_i.
 $$
 Es los casos $x_i=1,x_i'=-1$ y $x_i=-1,x_i'=1$ se tiene $x_i - x_ i' = 
2x_i$, respectivamente.

 Dado que $g_i = \sum_jw_{ij}y_j$ y $x_i = SGN(g_i)$, vemos que $x_i$ 
cambia s\'olo si $g_i$ tiene signo diferente a $x_i$,
 $$
 -\frac{1}{2}(x_i - x_ i')g_i = -x_ig_i,\quad SGN(x_ig_i) = -1.
 $$
 Por lo tanto $ E(X,Y) - E(X',Y) > 0$. En el segundo caso, igualmente
 $E(X,Y) - E(X',Y) > 0$.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

Cualquier actualizaci\'on del estado de la red reduce su energ\'{\i}a 
total.

Si ocurren una serie de actualizaciones,
 $$
 (X,Y)\to(X,Y')\to(X,Y'')\to\ldots
 $$
 Eventualmente se llega a un estado $(a,b)$ cuya energ\'{\i}a no puede 
reducirse m\'as.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Red Neuronal de Hopfield (HNN)}

En el modelo HNN se supone que los nodos individuales mantienen sus 
estados hasta que sean seleccionados para una actualizaci\'on. La 
selecci\'on ocurre al azar. Una HNN consta de $n$ nodos totalmente 
acoplados entre si, cada uno est\'a conectado con todos los dem\'as 
excepto con \'el mismo. La red es sim\'etrica dado que $w_{ij}$ 
establece tanto la conexi\'on entre el nodo $i$ y el nodo $j$ como entre 
el $j$ y el $i$, hay una conexi\'on bidireccional entre ambos nodos de 
igual intensidad.

 \DIVIDE{1.}{2.}{\coss}
 \DIVIDE{1.73205}{2.}{\sins}
 \MULTIPLY{50}{\sins}{\ymax}
 \MULTIPLY{3.5}{\coss}{\xu}
 \MULTIPLY{3.5}{\sins}{\yu}
 \SUBTRACT{\ymax}{\yu}{\yv}
 \SUBTRACT{25}{\xu}{\xv}
 \SUBTRACT{50}{\xu}{\xd}
 \ADD{25}{\xu}{\xt}
 \setlength{\unitlength}{.09cm}
 \begin{picture}(50,\ymax)(-45,0)
 \linethickness{3pt}
 \thicklines
 \put(0,0){\circle{7}}
 \put(25,\ymax){\circle{7}}
 \put(50,0){\circle{7}}
 \put(6,0){\vector(1,0){41}}
 \put(44,0){\vector(-1,0){41}}
 \put(\xu,\yu){\vector(0.5,0.866){21.5}}
 \put(\xv,\yv){\vector(-0.5,-0.866){21.5}}
 \put(\xt,\yv){\vector(0.5,-0.866){21.5}}
 \put(\xd,\yu){\vector(-0.5,0.866){21.5}}
 \put(-1.5,0){$\bm{x_1}$}
 \put(48.5,0){$\bm{x_2}$}
 \put(23.5,\ymax){$\bm{x_3}$}
 \put(13,20){$\bm{w_{13}}$}
 \put(30,20){$\bm{w_{23}}$}
 \put(21.5,2){$\bm{w_{12}}$}
 \end{picture}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

Es decir, la HNN es una red BAM (asincr\'onica) en la cual las capas 
izquierda y derecha se funden en una \'unica capa.

$W$ es una matriz $n\times n$ en la cual $w_{ii} = 0$ para $i = 1,...n$ 
(cero en la diagonal). $W$ es sim\'etrica, $w_{ij} = w_{ji}$.

Si $W$ no fuera sim\'etrica o tuviera elementos no nulos en la diagonal, 
la red podr\'{\i}a oscila sin alcanzar un punto fijo. Por lo tanto 
$w_{ij} = w_{ji}$ y $w_{ii} = 0$ son condiciones necesarias para la 
convergencia de una red asincr\'onica totalmente conectada a un estado 
estable. Tambi\'en son suficientes.

Si la HNN tiene umbral $\theta\ne0$, se procede como con la BAM. En este 
caso $\theta_L = \theta_T = \theta$.

Al poner $Y$ coincidiendo con $X$ se obtiene,
 $$
 \begin{array}{rcl}
 E(X) &=& -\frac{1}{2} X\cdot W\cdot X^T + \theta\cdot X^T \\
 &=&\displaystyle-\frac{1}{2}\sum\limits_{i=1}^n\sum\limits_{j=1}^n 
 w_{ij}x_ix_j + \sum\limits_{i=1}^n\theta_ix_i.
 \end{array}
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

La energ\'{\i}a de Hopfield es una forma cuadr\'atica. La red de Hopfield 
siempre tiene un m\'{\i}nimo local de la funci\'on de energ\'{\i}a.

\textbf{Ejemplo}. La red de Hopfield flip-flop. Si $N=1$ y $n=2$,
 $$
 x_i = SGN(x_iW), i=1,2.\quad x_2 = SGN(Wx_1).
 $$
 Los puntos fijos cumplen,
 $$
 x = SGM(w_{12}x).
 $$
 Si $w_{12} = w_{21} = 1$ no hay cambio, pero si $w_{12} = w_{21} = -1$, 
los estados estables de los dos nodos son $(1,-1)$ y $(-1,1)$.

 Si el umbral se toma cero, la energ\'{\i}a vale
 $$
 E(x_1,x_2) =  x_1x_2.
 $$
 S\'olo los 4 estados (1,1), (1,-1), (-1,1), (-1,-1) son permitidos. 
Entonces la energ\'{\i}a tiene m\'{\i}nimo local en $(-1,1)$ y en 
$(1,-1)$.

Un flip-flop es una red capaz de almacenar uno de los estados $(-1,1)$ o 
$(1,-1)$.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

\vfill

\centerline{\psfig{figure=cubo.eps, height=0.6\vsize}}

Funci\'on de energ\'{\i}a de un flip-flop. En los m\'{\i}nimos locales 
$(-1,1)$ y $(1,-1)$ la energ\'{\i}a vale $-1$. En los m\'aximos locales 
$(1,1)$ y $(-1,-1)$ la energ\'{\i}a vale $1$. Un flip-flop es una red 
capaz de alamacenar uno de los estados $(-1,1)$ o $(1,-1)$.

\vfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Puerta L\'ogica CNOT Con la Red de Hopfield}

 La red de 3 unidades permite almacenar la funci\'on l\'ogica CNOT. Esta 
red tiene $2^3=8$ estados: $(-1,-1,-1)$, $(-1,-1,1)$, ... $(1,1,1)$. 
S\'olo tiene 4 m\'{\i}nimos locales, en los siguientes 4 puntos del 
espacio 3D, todos con energ\'{\i}a $-1$.
 $$
 \begin{array}{cccc}
 PUNTO & TARGET & CONTROL & CNOT \\
 1. & -1 & -1 & -1 \\
 2. & 1  & -1 & 1 \\
 3. & -1 & 1  & 1 \\
 4. & 1  & 1  & -1 
 \end{array}
 $$
 El control y el target forman 4 puntos de 2 bits: $(-1.-1)$, $(-1.1)$, 
$(1.-1)$, $(1.1)$. Por su parte, $CNOT$ es una funci\'on que toma uno de 
estos 4 puntos y los env\'{\i}a en $-1$ o $1$.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Separaci\'on en Dos Clases}

 Una recta puede separar siempre 3 puntos con una recta en las clases 
``$+$'' y ``$-$''. Las posibles tr\'{\i}adas de puntos son: $-,-,-$\quad 
$-,-,+$\quad $-,+,-$\quad $-,+,+$\quad $+,-,-$\quad $+,-,+$\quad 
$+,+,-$\quad $+,+,+$\quad.

 \vfill\hfill
 \setlength{\unitlength}{0.1cm}
 \begin{picture}(100,25)
 \linethickness{3pt}
 \thicklines
 \put(0,0){\line(1,1){24}}
 \put(23,0){\line(1,1){24}}
 \put(48,0){\line(1,1){24}}
 \put(73,0){\line(1,1){24}}
 \put(-7.,0.){\color{red}$\bm{+}$}
 \put(3.,10.){\color{red}$\bm{+}$}
 \put(13.,20.){\color{red}$\bm{+}$}
 \put(4.,0.){$\bm{}$}
 \put(14.,10.){$\bm{}$}
 \put(24.,20.){$\bm{}$}
 \put(17.,0.){\color{red}$\bm{+}$}
 \put(27.,10.){\color{red}$\bm{+}$}
 \put(37.,20.){$\bm{}$}
 \put(28.,0.){\color{blue}$\bm{-}$}
 \put(38.,10.){$\bm{}$}
 \put(48.,20.){$\bm{}$}
 \put(41.,0.){\color{red}$\bm{+}$}
 \put(51.,10.){$\bm{}$}
 \put(61.,20.){$\bm{}$}
 \put(52.,0.){\color{blue}$\bm{-}$}
 \put(62.,10.){\color{blue}$\bm{-}$}
 \put(72.,20.){$\bm{}$}
 \put(66.,0.){$\bm{}$}
 \put(77.,10.){$\bm{}$}
 \put(87.,20.){$\bm{}$}
 \put(76.,0.){\color{blue}$\bm{-}$}
 \put(87.,10.){\color{blue}$\bm{-}$}
 \put(98.,20.){\color{blue}$\bm{-}$}
 \end{picture}
 \hfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

Una recta del plano no puede separar 4 puntos tomados de las $2^4=16$ 
cuartetas $(-,-,-,-)$\ $(-,-,-,+)$\ $(-,-,+,-)$\ $(-,-,+,+)$\ 
$(-,+,-,-)$\ $(-,+,-,+)$\ $(-,+,+,-)$\ $(-,+,+,+)$\ $(+,-,-,-)$\ 
$(+,-,-,+)$\ $(+,-,+,-)$\ $(+,-,+,+)$\ $(+,+,-,-)$\ $(+,+,-,+)$\ 
$(+,+,+,-)$\ $(+,+,+,+)$\ con la clase ``$+$'' a un lado de la recta y 
la clase ``$-$'' al otro lado. Se requieren dos rectas, lo cual no da 
lugar a una separaci\'on en dos clases. Por ejemplo

 \vspace{1cm}
 \hfill
 \setlength{\unitlength}{0.2cm}
 \begin{picture}(45,10)
 \linethickness{3pt}
 \thicklines
 \put(0,0){\line(1,1){12}}
 \put(23,0){\line(1,1){12}}
 \put(-2.,5.){\color{red}$\bm{+}$}
 \put(3.,10.){\color{red}$\bm{}$}
 \put(13.,20.){\color{red}$\bm{}$}
 \put(10.,0.){\color{blue}$\bm{-}$}
 \put(20.,10.){\color{blue}$\bm{-}$}
 \put(24.,20.){$\bm{}$}
 \put(34.,5.){\color{red}$\bm{+}$}
 \put(37.,20.){$\bm{}$}
 \end{picture}
 \hfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 Los puntos de la $CNOT$ se pueden colocar en el plano $x_1-x_2$.

 \vspace{1cm}
 \hfill
 \setlength{\unitlength}{0.2cm}
 \begin{picture}(45,10)
 \linethickness{3pt}
 \thicklines
 \put(0,0){\vector(1,0){10}}
 \put(0,0){\vector(0,1){10}}
 \put(22,0){\line(1,0){10}}
 \put(22,0){\line(0,1){10}}
 \put(32,0){\line(0,1){10}}
 \put(32,10){\line(-1,0){10}}
 \put(32,-5){\line(-1,1){15}}
 \put(37,0){\line(-1,1){15}}
 \put(0.,11.){\color{red}$\bm{x_2}$}
 \put(11.,0.){\color{red}$\bm{x_1}$}
 \put(17.,11.){\color{blue}$\bm{(-1,1)}$}
 \put(32.,11.){\color{blue}$\bm{(1,1)}$}
 \put(17.,-3.){\color{blue}$\bm{(-1,-1)}$}
 \put(32.,-3.){\color{blue}$\bm{(1,-1)}$}
 \put(31.5,-0.5){\color{red}$\bm{\bullet}$}
 \put(31.5,9.5){\color{red}$\bm{\bullet}$}
 \put(21.5,-0.5){\color{red}$\bm{\bullet}$}
 \put(21.5,9.5){\color{red}$\bm{\bullet}$}
 \end{picture}
 \hfill

 \vspace{1cm}

 Los puntos $(-1,1)$ y $(1,-1)$ son estables. Los puntos $(-1,-1)$ y 
$(1,1)$ son inestables.

 Ninguna red de Hpfield de 3 unidades puede tener los 4 estados 
estables.

El problema de $CNOT$ se resuelve si la red se extiende a 4 unidades. La 
cuarta hace el papel de ancilla. Se tiene as\'{\i} la $CNOT$ 
\textbf{reversible}.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 La red de 4 unidades permite almacenar la funci\'on l\'ogica $CNOT$ 
reversible. Esta red tiene $2^4=16$ estados, de los cu\'ales 4 
corresponden a la $CNOT$:
 $$
 \begin{array}{cccc}
 CONTROL & TARGET & CNOT & ANCILLA \\
 -1 & -1 & -1 & 1 \\
 1  & -1 & 1  & 1\\
 -1 & 1  & 1  & 1 \\
 1  & 1  & -1 & -1 \\
 x_1 & x_2 & x_3 & x_4
 \end{array}
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

La red neuronal para la puerta $CNOT$ consta de tres neuronas que 
corresponden a dos entradas y una salida. Tambi\'en es posible 
representarla por cuatro neuronas, donde tres neuronas corresponden a 
dos entradas y una salida, y la cuarta es adicional. La red neuronal 
para un circuito l\'ogico cualquiera se caracteriza por una funci\'on de 
energ\'{\i}a $E$ que tiene un m\'{\i}nimo global (que se puede escoger 
como $0$) s\'olo en los estados compatibles con la definici\'on de la 
operaci\'on l\'ogica. Los dem\'as estados tienen energ\'{\i}a m\'as 
alta. Dicha funci\'on se puede escribir como sigue,
 $$
 E = -\frac{1}{2}\sum\limits_{i,j=1,i\ne j}^n w_{ij}x_ix_j-
 \sum\limits_{i=1}^n b_ix_i + K,
 $$ donde $n$ es el n\'umero de neuronas en la red neuronal, $w_{ij}$ es 
el peso asociado con el enlace entre las neuronas $i$ y $j$, $x_i$ es el 
valor de activaci\'on de la neurona $i$, $b_i$ es el umbral asociado con 
la neurona $i$ y $K$ es una constante.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Red Neuronal de la Puerta CNOT}

 \DIVIDE{1.}{2.}{\coss}
 \DIVIDE{1.73205}{2.}{\sins}
 \MULTIPLY{50}{\sins}{\ymax}
 \MULTIPLY{3.5}{\coss}{\xu}
 \MULTIPLY{3.5}{\sins}{\yu}
 \DIVIDE{\ymax}{3.0}{\yc}
 \SUBTRACT{\ymax}{\yu}{\yv}
 \SUBTRACT{25}{\xu}{\xv}
 \SUBTRACT{50}{\xu}{\xd}
 \ADD{25}{\xu}{\xt}
 \setlength{\unitlength}{.09cm}
 \begin{picture}(50,\ymax)(-45,0)
 \setlength{\unitlength}{.09cm}
 \linethickness{3pt}
 \thicklines
 \put(0,0){\circle{7}}
 \put(25,\ymax){\circle{7}}
 \put(50,0){\circle{7}}
 \put(25,\yc){\circle{7}}
 \put(6,0){\vector(1,0){41}}
 \put(44,0){\vector(-1,0){41}}
 \put(\xu,\yu){\vector(0.5,0.866){21.5}}
 \put(\xv,\yv){\vector(-0.5,-0.866){21.5}}
 \put(\xt,\yv){\vector(0.5,-0.866){21.5}}
 \put(\xd,\yu){\vector(-0.5,0.866){21.5}}
 \put(2.9,1.5){\vector(11,7){19.3}}
 \put(4.5,2.5){\vector(-11,-7){1.9}}
 \put(25,40){\vector(0,-1){22.3}}
 \put(25,38.2){\vector(0,1){1.9}}
 \put(47.3,1.5){\vector(-11,7){19.3}}
 \put(45.7,2.5){\vector(11,-7){1.5}}
 \put(-1.5,0){$\bm{x_1}$}
 \put(48.5,0){$\bm{x_2}$}
 \put(23.5,\ymax){$\bm{x_3}$}
 \put(23.5,\yc){$\bm{x_4}$}
 \put(13,20){$\bm{w_{13}}$}
 \put(30,20){$\bm{w_{23}}$}
 \put(21.5,2){$\bm{w_{12}}$}
 \put(8.0,10){$\bm{w_{14}}$}
 \put(34.5,10){$\bm{w_{24}}$}
 \put(25.5,28){$\bm{w_{34}}$}
 \end{picture}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Isomorfismo Entre los Modelos de Ising y Hopfield}

 Si $w_{ij}$ es la magnitud del acople entre los espines de los \'atomos 
$i$ y $j$ de una red cristalina y $h_i$ es el campo magn\'etico efectivo 
sobre el esp\'{\i}n del \'atomo $i$, la energ\'{\i}a vale
 $$
 E = -\sum\limits_{i=1}^N h_ix_i = -\frac{1}{2}
 \sum\limits_{i,j}^Nw_{ij}x_ix_j -\sum\limits_{i=1}^N h^*x_i,\quad
 h_i = \sum\limits_{i=1}^Nw_{ij}x_j + h^*.
 $$
 $(x_1,...x_N)$ es la configuraci\'on de los espines, donde cada $x_i$ 
vale $\pm$. El campo magn\'etico externo (si est\'a presente) es $h^*$ y 
se considera que la temperatura del sistema vale $T=0$. Se supone que 
$w_{ji} = w_{ij}$, de ah\'{\i} el factor de $1/2$,
 $$
 \frac{1}{2}\sum\limits_{i,j}^N \longrightarrow \sum\limits_{i<j}.
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 En materiales paramagn\'eticos las constantes de acople $w_{ij}$ valen 
cero. En ferromagn\'eticos todas las $w_{ij}$ son positivas y en 
anti-ferromagn\'eticos todas las $w_{ij}$ son negativas. En vidrios de 
esp\'{\i}n las $w_{ij}$ son aleatorias.

 En el modelo de Hopfield, por su parte, la energ\'{\i}a es,
 $$
 E(\bm{x}) = -\frac{1}{2}\bm{x}\cdot W\cdot\bm{x} + 
 \bm{\theta}\cdot\bm{x} = -\frac{1}{2}\sum\limits_{ij} w_{ij}x_ix_j + 
 \sum\limits_{i=1}^N\theta_ix_i.
 $$
 Los pesos son $w_{ij}$ y forman una matriz $W$. Adem\'as $\bm{x} = 
(x_1,...x_N)$ y $\bm{\beta} = (\beta_1,...\beta_N)$.

Otra analog\'{\i}a entre una red neuronal y un sistema f\'{\i}sico es 
entre la llamada ``m\'aquina de Boltzmann'' y el modelo de Ising a 
temperatura $T>0$.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Algunos Teoremas Acerca del Modelo de Hopfield}

\textbf{Regla de Hebb}. Si
 $$
 w_{ij} = \frac{1}{N}\sum\limits_{\mu=1}^p \xi_i^\mu \xi_j^\mu,
 $$
 donde los $\xi_i^\mu$ son $p$ tiras de longitud $D$ formadas por $-1$ 
y $1$, para las neuronas $i=1,...N$ y las $p$ muestras o palabras $\mu = 
1,...p$, la relaci\'on de recurrencia
 $$
 x_i(t+1) = SGN[\sum\limits_jw_{ij}x_j(t)]
 $$
 constituye una \'orbita atractiva de cierto sistema din\'amico, con 
puntos fijos $\xi_i^\mu$.

La atracci\'on es local.

Las condiciones $N,p\to\infty$ con $p = N^{1/2-\epsilon}$, con 
$\epsilon>0$ una constante peque\~na.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

La localidad ha de entenderse as\'{\i}: Cada muestra $\xi_i^\mu$ es 
perturbaci\'on de alg\'un conjunto de se\~nales,
 $$
 x_i(0) = \xi_i^\mu\epsilon_i,
 $$
 donde $\epsilon_i$ es una variable aleatoria que toma valores $\pm1$ 
con probabilidad
 $$
 p(\epsilon_i = 1) = 1-q,\quad p(\epsilon_i = -1) = q.
 $$
 Cuando $N$ es grande, el porcentaje de neuronas con bit errado es $q$ 
(salvo fluctuaciones que decrece, con el aumento de $N$).

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Actualizaci\'on de los Pesos}

 El aprendizaje con descenso del gradiente (gradient descent learning, 
GDL) utiliza la funci\'on de costo para determinar el cambio requerido 
en los pesos. Requiere evaluar el gradiente, $\partial 
E(\bm{w})/\partial\bm{w}$, el cual dice la direcci\'on en la cual debe 
moverse en el espacio $\bm{w}$ para reducir el error. Tambi\'en se 
requiere la tasa de aprendizaje $\eta$, que expresa el n\'umero de pasos 
en el espacio $\bm{w}$ requeridos para cada actualizaci\'on de los 
$\bm{w}$.

Entonces el cambio requerido del vector de pesos vale
 $$
 \Delta\bm{w} = -\eta\frac{\partial E(\bm{w})}{\partial\bm{w}},
 $$
 el cual debe repetirse hasta que la funci\'on de error alcance el 
m\'{\i}nimo valor.

No es posible con el anterior procedimiento tratar datos no separables 
linealmente, como sucede con la $CNOT$ de una capa (capa de entrada con 
los dos nodos $x_1$ y $x_2$ y capa de salida con un s\'olo nodo, 
$CNOT(x_1,x_2)$. Se requiere un perceptr\'on de varias capas, por 
ejemplo entrada $i$, oculta $j$ y salida $k$.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

En el algoritmo de entrenamiento m\'as simple, los pesos se actualizan 
con el siguiente procedimiento, al realizar las sucesivas iteraciones,
 $$
 w_{ij}(\textrm{nuevo}) = w_{ij}(\textrm{viejo}) + x_iy_i.
 $$
 Se modifica con la regla de aprendizaje de perceptr\'on (Perceptron 
Learning Rule PLR) o ``regla delta'',
 $$
 w_{ij}(\textrm{nuevo}) = w_{ij}(\textrm{viejo}) + 
\eta\cdot\delta_i\cdot
 x_j;\quad\delta_i = y_i(\textrm{target}) - y_i.
 $$
 Es conveniente usar en vez de la funci\'on umbral $SGN$ una funci\'on 
diferenciable como la sigmoide, la cual cumple,
 $$
 f'(x) = f(x)[1-f(x)].
 $$
 La regla delta generalizada (generalized delta rule GDR) utiliza la 
funci\'on de costo, as\'{\i},
 $$
 w_{ij}(\textrm{nuevo}) = w_{ij}(\textrm{viejo}) - \eta\frac{\partial
 E(\bm{w})}{\partial w_{ij}}.
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 La funci\'on de costo se expresa en funci\'on de la salida, la cual es 
funci\'on de la entrada,
 $$
 E(\bm{w}) = \frac{1}{2} \sum\limits_p\sum\limits_j 
 [y^p_j(\textrm{target}) - y^p_j],
 $$
 donde $y_j^p = \sum_iw_{ji}x_i^p$. Por lo tanto,
 $$
 \frac{\partial E}{\partial w_{ji}} = \frac{\partial
 E}{\partial y_j}\cdot \frac{\partial y_j}{\partial w_{ji}} = 
-[y_j\textrm{target} - y_j]x_i = -\delta_j\cdot x_i.
 $$
 Para reducir $E$ por el descenso del gradiente, los pesos se deben 
mover en direcci\'on opuesta a la del gradiente, $-(-\delta) = \delta$.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{M\'aquina de Boltzmann Restringida (RBM)}

 La M\'aquina de Boltzmann es una familia de modelos de redes neuronales 
bidireccionalmente conectadas dise\~nadas para aprender distribuciones 
de probabilidad desconocidas. Modelos particulares son: Red de creencias 
profundas (DBN) y m\'aquina de Boltzmann profunda (DBM).

Una RBM es una red neuronal estoc\'astica de dos capas (las activaciones 
de las neuronas tienen un elemento probabil\'{\i}stico). La primera capa 
de la RBM se llama ``visible'', o capa de entrada, y la segunda es la 
capa ``oculta''. Cada nodo visible est\'a conectado con cada uno de los 
nodos ocultos, pero no hay conexiones de los nodos visibles entre si, ni 
entre los ocultos. Una RBM tiene dos tipos de par\'ametros: los pesos o 
acoples entre una capa visible y una oculta, y unos par\'ametros de 
sesgo de las capas visible y ocultas.

En el modelo RBM las im\'agenes de entrenamiento se llaman ``visibles'' 
El proceso de entrenamiento consiste en determinar los pesos y sesgos de 
la capa de entrada, $W^{(1)}_{ij}$ y $b^{(1)}$, y los pesos y acoples 
entre las capas oculta y de salida, $W^{(2)}_{ij}$ y $b^{(2)}$.

Una RBM con $V$ unidades visibles y $H$ unidades ocultas se puede 
describir con la siguiente funci\'on de energ\'{\i}a,
 $$
 E(\bm{v},\bm{h}) = -\sum_{i=1}^V\sum_{j=1}^Hv_ih_jw_{ij} - 
\sum_{i=1}^Vv_ib^v_i -\sum_{i=1}^Hh_ib^h_i.
 $$
 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Arquitectura de la M\'aquina de Boltzmann Restringida}

 \setlength{\unitlength}{.1cm}
 \begin{picture}(100,45)
 \linethickness{3pt}
 \thicklines
 \put(20,20){\circle{10}}
 \put(50,20){\circle{10}}
 \put(80,20){\circle{10}}
 \put(35,40){\circle*{10}}
 \put(65,40){\circle*{10}}
 \put(35,40){\line(-4,-5){12.5}}
 \put(35,40){\line(4,-5){12.5}}
 \put(35,40){\line(2,-0.9){40.3}}
 \put(65,40){\line(-4,-5){12.5}}
 \put(65,40){\line(4,-5){12.5}}
 \put(65,40){\line(-2,-0.9){40.3}}
 \put(90,40){\textbf{Unidades visibles}}
 \put(90,20){\textbf{Unidades ocultas}}
 \end{picture}

 \vspace{-1cm}

 $\bm{v}$ es un vector de dimensi\'on $V$ con componentes binarias $v_i$ 
(el estado de la unidad visible $i$). Similarmente el vector $\bm{h}$. 
La intensidad del acople entre la unidad visible $i$ y la oculta $j$ 
est\'a dado por el real $w_{ij}$. El real $b^v_i$ describe la intensidad 
de un ``sesgo'' en la unidad visible $i$. Similarmente el real $b^h_i$ 
respecto a las ocultas.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Probabilidades}

 A la configuraci\'on de la RBM ($\bm{v},\bm{h}$), cuya energ\'{\i}a vale
$E(\bm{v},\bm{h})$, se le asocia la probabilidad
 $$
 p(\bm{v},\bm{h}) = 
 \frac{e^{-E(\bm{v},\bm{h})}}{\sum_{\bm{f}}\sum_{\bm{g}}e^{-E(\bm{f},\bm{g})}}.
 $$
 La probabilidad de una configuraci\'on particular de estado visible es,
 $$
 p(\bm{v}) = \sum_{\bm{h}}p(\bm{v},\bm{h}) =
 \frac{\sum_{\bm{h}}e^{-E(\bm{v},\bm{h})}} 
 {\sum_{\bm{f}}\sum_{\bm{g}}e^{-E(\bm{f},\bm{g})}}.
 $$
 La probabilidad de una configuraci\'on particular de estado oculto es,
 $$
 p(\bm{h}) = \sum_{\bm{v}}p(\bm{v},\bm{h}) =
 \frac{\sum_{\bm{v}}e^{-E(\bm{v},\bm{h})}} 
 {\sum_{\bm{f}}\sum_{\bm{g}}e^{-E(\bm{f},\bm{g})}}.
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Probabilidades Condicionales}

 El entrenamiento de la RBM consiste en fijar los estados de las 
unidades visibles $\bm{v}$ en una configuraci\'on deseable y luego 
encontrar los valores de los par\'ametros (pesos $w_{ij}$ y sesgos 
$b_i^v$ y $b_i^h$) tales que $p(\bm{v})$ sea grande. Esto se hace para 
definir una ``generalizaci\'on'' con las unidades visibles, con la cual 
luego se pueda extraer un patr\'on dentro del conjunto de datos. Con 
ello $p(\bm{\tilde{v}})$ ser\'a tambi\'en grande si $\bm{\tilde{v}}$ es 
``cercano'' a alguno de los estados $\bm{v}$, es decir pertenece a la 
misma distribuci\'on de los $\bm{v}$.

Probabilidades condicionales.
 $$
 p(\bm{v}\vert\bm{h}) = \frac{p(\bm{v},\bm{h})}{p(\bm{h})} = 
 \frac{e^{-E(\bm{v},\bm{h})}} {\sum_{\bm{f}}e^{-E(\bm{f},\bm{h})}}.
 $$
 $$
 p(\bm{h}\vert\bm{v}) = \frac{p(\bm{v},\bm{h})}{p(\bm{v})} = 
 \frac{e^{-E(\bm{v},\bm{h})}} {\sum_{\bm{f}}e^{-E(\bm{v},\bm{f})}}.
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

La probabilidad de que una unidad visible $k$ tenga cierto valor para 
una configuraci\'on oculta $\bm{h}$ dada est\'a definida por,
 $$
 \begin{array}{rcl}
 p(v_k=1\vert\bm{h}) &=& 
 \frac{\sum_{v_1}...\sum_{v_{k-1}}\sum_{v_{k+1}}...\sum_{v_V}p(v_1,...v_{k-1},v_k=1,v_{k+1},...v_V,\bm{h})}{p(\bm{h})} \\
 &=&
 \displaystyle\frac{1}{1+e^{\sum_{j=1}^Hh_jw_{kj}+b_k^v}}.
 \end{array}
 $$
 Similarmente
 $$
 \begin{array}{rcl}
 p(h_k=1\vert\bm{v}) = 
 \displaystyle\frac{1}{1+e^{\sum_{i=1}^Vv_iw_{ik}+b_k^h}}.
 \end{array}
 $$
 Los resultados son consistentes con la ausencia de interacciones entre 
las unidades visibles y entre las ocultas. N\'otese que estas 
probabilidades condicionales tienen la forma de una sigmoide.

 Esta propiedad de las RBM permite manipular todas las unidades visibles 
simult\'aneamente y luego todas las unidades ocultas simult\'aneamente.

 \end{frame}

%-------------------------------------------------------------------

 \section{Propagaci\'on Hacia Atr\'as (Backpropagation)}
 \begin{frame}{Propagaci\'on Hacia Atr\'as}

 La funci\'on de error total, en un modelo de aprendizaje supervisado,
 $$
 E = \frac{1}{2}\sum\limits_k(y_k-\overline{y}_k)^2
 $$
 donde $y_k$ son los valores de salida predichos por la RN y 
$\overline{y}_k$ son las clases definidas en el entrenamiento, en 
\'ultima instancia es funci\'on de la entrada. El problema consiste en 
ajustar los pesos y los sesgos para minimizar $E$.

En una RN con una capa de entrada, una capa de salida y cierto n\'umero 
de capas ocultas, las unidades de la capa de salida son funciones de las 
de la \'ultima capa oculta, \'estas a su vez son funciones de las de la 
pen\'ultima capa oculta, y as\'{\i} sucesivamente hasta las de la capa 
de entrada. Por lo tanto se requiere propagar hacia atr\'as los errores 
en la capa de salida para ir determinando los ajustes de los 
par\'ametros de la RN.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

En el caso sin capas ocultas, el cambio en el peso que acopla la entrada 
$x_i$ con la salida $y_k$ es,
 $$
 \Delta w_{ki} = -\eta\frac{\partial E}{\partial y_k}\frac{\partial 
 y_k}{\partial x_i}\frac{\partial x_i}{\partial w_{ki}}.
 $$
 Si se usa la funci\'on de activaci\'on sigmoide, sin sesgo, $y_k = 
g(x_i) = [1+exp(-\sum_iw_{ki}x_i)]^{-1}$, y se usa la bidireccionalidad, 
$y_k = \sum_iw_{ki}x_i$,
 $$
 \frac{\partial E}{\partial y_k} = y_k-\overline{y}_k,\ 
 \frac{\partial y_k}{\partial x_i} = y_k(1-y_k),\ 
 \frac{\partial x_i}{\partial w_{ki}} = y_k.
 $$
 Por lo tanto,
 $$
 \Delta w_{ki} = -\eta(y_k-\overline{y}_k) y_k (1-y_k)y_i = \eta\delta_ky_i,
$$
 donde $\delta_k = (y_k-\overline{y}_k) y_k (1-y_k)$. Se parece a la 
regla de entrenamiento del perceptr\'on.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 En el caso con una capa oculta, el cambio en el acople entre la capa de 
entrada y la capa oculta es,
 $$
 \begin{array}{rcl}
 \Delta w_{ji} &=&\displaystyle -\eta\left(\sum_k\frac{\partial E}{\partial y_k}\frac{\partial 
 y_k}{\partial x_i}\frac{\partial x_i}{\partial y_j}\right) 
 \frac{\partial y_j}{\partial x_j} \frac{\partial x_j}{\partial w_{ji}} \\
 &=& -\eta\left[\sum_k(y_k-\overline{y}_k)y_k(1-y_k)w_{kj}\right]
 y_j(1-y_j)y_i \\
 &=& -\eta(\sum_k\delta_kw_{kj})y_j(1-y_j)y_i \\
 &=& -\eta\delta_jy_i. 
 \end{array}
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

El c\'alculo de la propagaci\'on de errores hacia atr\'as requiere un 
n\'umero exponencialmente grande de operaciones. Eso se puede ilustrar 
con el ``grafo computacional'', que reduce el c\'alculo de las derivadas 
parciales a una suma sobre todas las trayectorias que conectan entre si 
dos nodos y multiplicando las derivadas asociadas con cada borde, como 
lo ilustra la f\'ormula anterior.

En \texttt{colah.github.io/ports/2015-08-Backprop} se da el siguiente 
ejemplo, el grafo para evaluar $e=(a+b)*(b+1)$. Si se definen $c=a+b$, 
$d=b+1$, entonces $e=c*d$. Si los nodos de entrada del grafo son $a$ y 
$b$, que se conectan con los nodos $c$ y $d$, los cuales a su vez se 
conectan con $e$, los seis bordes contienen las derivadas $\partial 
c/\partial a$, $\partial c/\partial b$, $\partial d/\partial b$, 
$\partial e/\partial c$, $\partial e/\partial d$. Por lo tanto,
 $$
 \frac{\partial e}{\partial b} =
 \frac{\partial d}{\partial b}\cdot
 \frac{\partial e}{\partial d} +
 \frac{\partial c}{\partial b}\cdot
 \frac{\partial e}{\partial c},
 $$
 que es la regla de la cadena de las derivadas de funciones de muchas 
variables. Las derivadas de los grafos computacionales se hacen con 
propagaci\'on hacia atr\'as.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 \vspace{3cm}
 \DIVIDE{1.}{2.}{\sins}
 \DIVIDE{1.73205}{2.}{\coss}
 \MULTIPLY{9.}{\coss}{\yc}
 \MULTIPLY{9.}{\sins}{\xc}
 \ADD{20.}{\xc}{\xu}
 \ADD{10.}{\yc}{\yu}
 \SUBTRACT{60.}{\xc}{\xd}
 \ADD{10.}{\yc}{\yd}
 \ADD{60.}{\xc}{\xt}
 \ADD{10.}{\yc}{\yt}
 \ADD{40.}{\xc}{\xcu}
 \ADD{30.}{\yc}{\ycu}
 \SUBTRACT{80.}{\xc}{\xci}
 \ADD{30.}{\yc}{\yci}
 \setlength{\unitlength}{.1cm}
 \begin{picture}(100,40)
 \linethickness{3pt}
 \thicklines
 \put(20,10){\circle{18}}
 \put(60,10){\circle{18}}
 \put(40,30){\circle{18}}
 \put(80,30){\circle{18}}
 \put(60,50){\circle{18}}
 \put(\xu,\yu){\vector(1.,1.){8}}
 \put(\xd,\yd){\vector(-1.,1.){8}}
 \put(\xt,\yt){\vector(1.,1.){8}}
 \put(\xcu,\ycu){\vector(1.,1.){8}}
 \put(\xci,\yci){\vector(-1.,1.){8}}
 \put(15,20){\textbf{$\partial c/\partial a$}}
 \put(41,17){\textbf{$\partial c/\partial b$}}
 \put(69,17){\textbf{$\partial d/\partial b$}}
 \put(35,41){\textbf{$\partial e/\partial c$}}
 \put(75,41){\textbf{$\partial e/\partial d$}}
 \put(19,10){\textbf{$a$}}
 \put(59,10){\textbf{$b$}}
 \put(32,30){\textbf{$c=a+b$}}
 \put(72,30){\textbf{$d=b+1$}}
 \put(52,50){\textbf{$e=c\times d$}}
 \put(72,1){\framebox{\textbf{$\displaystyle
 \frac{\partial e}{\partial b} =
 \frac{\partial d}{\partial b}\cdot
 \frac{\partial e}{\partial d} +
 \frac{\partial c}{\partial b}\cdot
 \frac{\partial e}{\partial c}
 $}}}
 \end{picture}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Crecimiento Exponencial}

 \setlength{\unitlength}{.1cm}
 \begin{picture}(120,11)
 \linethickness{3pt}
 \thicklines
 \put(20,1){\framebox(10,10){$\Huge X$}}
 \put(60,1){\framebox(10,10){$\Huge Y$}}
 \put(100,1){\framebox(10,10){$\Huge Z$}}
 \put(31,1){\vector(1.,0.){28}}
 \put(71,1){\vector(1.,0.){28}}
 \put(31,6){\vector(1.,0.){28}}
 \put(71,6){\vector(1.,0.){28}}
 \put(31,11){\vector(1.,0.){28}}
 \put(71,11){\vector(1.,0.){28}}
 \put(42,2.3){\textbf{$\alpha$}}
 \put(42,7.3){\textbf{$\beta$}}
 \put(42,12.3){\textbf{$\gamma$}}
 \put(82,2.3){\textbf{$\zeta$}}
 \put(82,7.3){\textbf{$\epsilon$}}
 \put(82,12.3){\textbf{$\delta$}}
 \end{picture}

 La derivada de la salida respecto a la entrada, en modo hacia adelante,
 $$
 \frac{\partial Z}{\partial X} = (\alpha\delta + \alpha\epsilon + 
 \alpha\zeta) +
 (\beta\delta + \beta\epsilon + \beta\zeta) +
 (\gamma\delta + \gamma\epsilon + \gamma\zeta).
 $$
 $$
 \frac{\partial\phantom{.}.\phantom{.}}{\partial X} 
 \quad
 \bm{\Longrightarrow}
 $$
 \hspace{-1cm}
 \setlength{\unitlength}{.1cm}
 \begin{picture}(140,28)
 \linethickness{3pt}
 \thicklines
 \put(20,1){\framebox(15,27){$\displaystyle\frac{\partial 
 X}{\partial X} = 1$}}
 \put(60,1){\framebox(20,27){$
 \begin{array}{c}
 \displaystyle\frac{\partial Y}{\partial X} = \\\\
 \alpha + \beta + \gamma
 \end{array}$}}
 \put(100,1){\framebox(25,27){$
 \begin{array}{c}
 \displaystyle\frac{\partial Z}{\partial X} = \\\\
 (\alpha + \beta + \gamma)\times \\
 (\delta + \epsilon + \zeta)
 \end{array}$}}
 \put(36,1){\vector(1.,0.){23}}
 \put(36,14){\vector(1.,0.){23}}
 \put(36,28){\vector(1.,0.){23}}
 \put(81,1){\vector(1.,0.){18}}
 \put(81,14){\vector(1.,0.){18}}
 \put(81,28){\vector(1.,0.){18}}
 \put(46,2.7){\textbf{$\alpha$}}
 \put(46,14.7){\textbf{$\beta$}}
 \put(46,28.7){\textbf{$\gamma$}}
 \put(88,2.7){\textbf{$\zeta$}}
 \put(88,14.7){\textbf{$\epsilon$}}
 \put(88,28.7){\textbf{$\delta$}}
 \end{picture}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 La derivada de la salida respecto a la entrada, en modo hacia atr\'as,
 $$
 \frac{\partial Z}{\partial X} = (\alpha + \beta + \gamma)\times
 (\delta + \epsilon + \zeta).
 $$
 $$
 \frac{\partial Z}{\partial\phantom{.}.\phantom{.}}
 \quad
 \bm{\Longleftarrow}
 $$
 \hspace{-1cm}
 \setlength{\unitlength}{.1cm}
 \begin{picture}(140,28)
 \linethickness{3pt}
 \thicklines
 \put(20,1){\framebox(25,27){$
 \begin{array}{c}
 \displaystyle\frac{\partial Z}{\partial X} = \\\\
 (\alpha + \beta + \gamma)\times \\
 (\delta + \epsilon + \zeta)
 \end{array}
 $}}
 \put(60,1){\framebox(20,27){$
 \begin{array}{c}
 \displaystyle\frac{\partial Z}{\partial Y} = \\\\
 \delta + \epsilon + \zeta
 \end{array}$}}
 \put(100,1){\framebox(15,27){$
 \displaystyle\frac{\partial 
 Z}{\partial Z} = 1
 $}}
 \put(46,1){\vector(1.,0.){13}}
 \put(46,14){\vector(1.,0.){13}}
 \put(46,28){\vector(1.,0.){13}}
 \put(81,1){\vector(1.,0.){18}}
 \put(81,14){\vector(1.,0.){18}}
 \put(81,28){\vector(1.,0.){18}}
 \put(50,2.7){\textbf{$\alpha$}}
 \put(50,14.7){\textbf{$\beta$}}
 \put(50,28.7){\textbf{$\gamma$}}
 \put(88,2.7){\textbf{$\zeta$}}
 \put(88,14.7){\textbf{$\epsilon$}}
 \put(88,28.7){\textbf{$\delta$}}
 \end{picture}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Ventaja de la Diferenciaci\'on Hacia Atr\'as}

En la diferenciaci\'on hacia adelante respecto a una de las unidades de 
entrada, se requiere calcular la derivada en cada nodo respecto a dicha 
variable.

En la diferenciaci\'on hacia atr\'as, se requiere calcular la derivada 
de una de las variables de salida en cada nodo respecto la variable de 
cada nodo, no respecto cada variable de entrada. Esto implica un 
n\'umero de operaciones menor por un factor igual al n\'umero de 
variables de entrada. Eso representa un menor n\'umero de operaciones, 
lo cual es significativo cuando se tienen RN con millones de nodos.

La propagaci\'on hacia atr\'as ayuda a comprender c\'omo fluyen las 
derivadas a lo largo del modelo. Las derivadas son esenciales, deben 
evaluarse de manera sistem\'atica, lo cual requiere m\'etodos 
especiales, tales como linealizaci\'on y programaci\'on din\'amica.

 \end{frame}

%-------------------------------------------------------------------

 \section{Redes Neuronales Convolucionales (CNN)}
 \begin{frame}{RN Convolucionales}

Son similares a las RN en general, pero est\'an adaptadas a situaciones 
en las cuales la entrada contiene informaci\'on ``redundante'' o que 
contiene detales que pueden omitirse sin graves consecuencias.

Es el caso de las im\'agenes, las cuales admiten diferentes 
procedimientos de compresi\'on. Una imagen 2D se puede representar con 
un n\'umero de bits igual a largo$\times$ancho$\times$profundidad, donde 
largo y ancho son los pixeles y profundidad representa otros atributos 
como colores y tonos de gris. Im\'agenes de baja resoluci\'on como las 
de CIFAR-10 requieren 32$\times$32$\times$3 = 3072 bits. Una imagen de 
resoluci\'on moderada 200$\times$200$\times$3 = 120000 bits. Cuando se 
tengan muchas de estas \'ultimas ciertamente habr\'a dificultades 
computacionales.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

La ``correlaci\'on'' o correlaci\'on cruzada de dos funciones de una 
variable discreta y de dos variables discretas, se define por
 $$
 y(n) = (x*h)(n) = \sum\limits_{k=-\infty}^\infty x(k)h(n-k).
 $$
 $$
 (x*h)(m,n) =
 \sum\limits_{j=-\infty}^\infty\sum\limits_{k=-\infty}^\infty
 x(j,k)h(m-j,n-k).
 $$
 Es una suma de productos de valores de dos funciones punto a punto, 
sometidas a un desajuste.

\texttt{http://cs231n.stanford.edu/} es un curso sobre CNN. 
\texttt{https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/} 
contiene una explicaci\'on intuitiva acerca de las redes neuronales 
convolucionales. Tembi\'en es interesante 
\texttt{http://cs231n.github.io/convolutional-networks/}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

La t\'ecnica de CNN opera sobre los mencionados ``vol\'umenes''. Utiliza 
un ``filtro'' de dimensi\'on menor que se mueve a lo largo de toda la 
imagen original. En el camino se realiza el producto entre la imagen y 
el filtro, lo cual da lugar a una serie de trozos m\'as peque\~nos. Por 
eso se supone que las CNN son apropiadas para extraer propiedades que no 
dependan dr\'asticamente de la posici\'on.

Por ejemplo, si la imagen original es 32$\times$32$\times$3 y el filtro 
es 5$\times$5$\times$3, la operaci\'on la convierte en 
28$\times$28$\times$1. En efecto, hay 28$\times$28 posiciones \'unicas 
donde el filtro puede colocarse sobre la imagen original. Otro ejemplo: 
con una imagen 4$\times$4$\times$3 y un filtro 2$\times$2$\times$3, el 
cual se puede deslizar de 3$\times$3=9 maneras distintas sobre la 
imagen, da lugar a 3$\times$3$\times$1. La palabra convoluci\'on 
representa la acci\'on de deslizar el filtro y sumar los productos de 
las respectivas unidades en coincidencia.

 \end{frame}

%-------------------------------------------------------------------

 \section{Algunos Ejemplos y Aplicaciones}
 \begin{frame}{Algunos Ejemplos y Aplicaciones}

 \centerline{\bf La puerta CNOT}

 \texttt{https://www.machinelearningpython.org/single-post/}\endgraf
  \hspace{1cm}\texttt{Neural-Network-Implementation}
 \texttt{https://github.com/snlpatel001213/algorithmia/blob/}\endgraf
\hspace{1cm}\texttt{ad97168585fa53bf06b4d51048ebf79baec47d03/}\endgraf
\hspace{1cm}\texttt{neuralNetwork/ANN/xor.py}

 Considera una RN con una capa de entrada y una capa oculta, ambas con 
dos unidades, y una de salida con una unidad.

\texttt{FirstMLprogram.ipynb}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 \centerline{\bf Datos de ICS en UCI}

 \texttt{http://archive.ics.uci.edu/ml/datasets.html}

Breast Cancer. Iris. SUSY. Higgs.\\

Implementing a Neural Network from Scratch in Python - An Introduction:

 \texttt{http://www.wildml.com/2015/09/implementing-a-neural}\endgraf 
\hspace{1cm}\texttt{-network-from-scratch/}

 \texttt{https://github.com/dennybritz/nn-from-scratch}\\

A Beginner's Guide to Neural Networks with Python and SciKit Learn 
0.18!\endgraf
 \texttt{https://www.kdnuggets.com/2016/10/}\endgraf
 \texttt{beginners-guide-neural-networks-python-scikit-learn.html/2}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 \centerline{\bf El paquete PYTORCH}

Es un paquete en python que permite c\'alculos tensoriales como numpy 
(ndarray), uso de GPU y la inclusi\'on de c\'odigo en C usando el 
cython. Tambi\'en el scipy. Es usado por Facebook y otras 
compa\~n\'{\i}as. Tiene una librer\'{\i}a completa de rutinas de ML que 
usan tanto la CPU como la GPU. Una de sus fortalezas son las 
librer\'{\i}as espec\'{\i}ficas para tarjetas gr\'aficas como NVIDIA.

Algunos otros paquetes de ML son TensorFlow (Google), Theano, Caffe 
(Facebook) y CNTK (Microsoft).

 \texttt{http://pytorch.org/tutorials/beginner/blitz/autograd\_tutorial.html}

 \texttt{http://pytorch.org/tutorials/}

 \texttt{http://pytorch.org/tutorials/beginner/pytorch\_with\_examples.html}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Introducci\'on al Pytorch}

 \texttt{https://towardsdatascience.com/getting-started-with-pytorch}\endgraf
 \hspace{1cm}\texttt{-part-1-understanding-how-automatic-differentiation}\endgraf
 \hspace{1cm}\texttt{-works-5008282073ec}

All\'{\i} se empieza haciendo una distinci\'on entre los arreglos de 
\textit{numpy} y los tensores de \textit{pytorch}:

import torch 

import numpy as np

arr = np.random.randn((3,5))

tens = torch.from\_numpy(arr)

Otros objetos de pytorch son las ``Variables'':

from torch.autograd import Variable

var\_ex = Variable(torch.randn((4,3))   \#creating a Variable

Un objeto de la clase Variable encierra un tensor. El tensor se puede 
recuperar invocando el atributo ``.data'' de una Variable.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

Una Variable sirve para almacenar el gradiente de un escalar (por 
ejemplo la funci\'on de p\'erdida). Se accede al gradiente por medio del 
atributo ``.grad''.

Un tercer atributo que almacena una Variable es ``grad\_fn'', un objeto 
funci\'on que crea la variable.

Ver

\texttt{tensor\_tutorial.ipynb}

el cual se basa en

 \texttt{http://pytorch.org/tutorials/beginner/blitz/tensor\_tutorial.html}

Tambi\'en el notebook

\texttt{PytorchTests.ipynb}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

Algunos paquetes del pytorch son:

\begin{tabular}{ll}
torch & a Tensor library like NumPy, with strong GPU support\\
torch.autograd & a tape based automatic differentiation library\\
 & that supports all differentiable Tensor operations in torch\\
torch.nn & a neural networks library deeply integrated with\\
 & autograd designed for maximum flexibility\\
torch.optim & an optimization package to be used with torch.nn \\
 & with standard optimization methods such as SGD, RMSProp, LBFGS, Adam etc.\\
torch.multiprocessing & python multiprocessing,\\
 & for data loading and hogwild training.\\
torch.utils & DataLoader, Trainer and other utility functions for \\
 & convenience\\
torch.legacy(.nn/.optim) & legacy code that has been ported over\\
 & from torch for backward compatibility reasons
\end{tabular}
los cuales se discuten en,
 \texttt{https://pytorch.org/about/}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Ejemplo Para Entrenar un Clasificador}

 \texttt{https://pytorch.org/tutorials/beginner/blitz/cifar10\_tutorial.html}
 
All\'{\i} se considera el problema de reconocimiento de im\'agenes 
mediante una red neuronal con muchas capas ocultas.

El problema empieza con el entrenamiento de un clasificador. Requiere: 
Disponer de los datos de entrenamiento, definir la red neuronal, 
calcular funciones de p\'erdida y actualizar los pesos de la red.

Considera el conjunto de im\'agenes dados en CIFAR10. All\'{\i} se 
tienen las clases `avi\'on', `automobil', `p\'ajaro', `gato', `cabra', 
`perro', `rana', `caballo', `barco', `cami\'on'.

Del enlace

 \texttt{https://pytorch.org/tutorials/beginner/blitz/cifar10\_tutorial.html}

se extrae el notebook

 \texttt{EnsayoPytorchVision.ipynb}

 \end{frame}

%-------------------------------------------------------------------

 \section{Conclusiones}
 \begin{frame}{Algunas Conclusiones}

Se han estudiado algunos conceptos importantes de la teor\'{\i}a del 
aprendizaje automatizado.

Los m\'etodos llamados de ``m\'aquinas con soporte vectorial'' (SVM) 
permiten realizar la clasificaci\'on de diferentes datos.

Las llamadas ``redes neuronales'' presentan gran versatilidad, lo cual 
determina su uso en muchas aplicaciones.

Entre las aplicaciones de las redes neuronales se distinguen el 
reconocimiento de im\'agenes y el reconocimiento de voz.

Cada vez son m\'as comunes las aplicaciones en f\'{\i}sica, entre las 
cuales se destaca la determinaci\'on de propiedades de materiales basada 
en datos experimentales o en modelos te\'oricos. De una imagen de 
microscop\'{\i}a de barrido de efecto tunel, por ejemplo, es posible 
determinar ciertas propiedades del material.

 \end{frame}

%-------------------------------------------------------------------

 \section{Referencias}
 \begin{frame}{Referencias}

\begin{thebibliography}{99}

\bibitem{rojas} R. Rojas. \textit{Neural Networks\/}. Springer, Berlin, 
1996.

\bibitem{nielsen} M. Nielsen. \textit{Neural Networks and Deep 
Learning\/}. 2017, 
\texttt{http://neuralnetworksanddeeplearning.com/index.html}

 \end{thebibliography}

 \end{frame}

%-------------------------------------------------------------------





%-------------------------------------------------------------------
%-------------------------------------------------------------------

\begin{frame}{Resumen}

\vfill

El aprendizaje autom\'atico, aprendizaje de m\'aquina, o inteligencia 
artificial, IA (o machine learning ML), es un campo interdisciplinario 
que involucra la estad\'{\i}stica, problemas matem\'aticos de 
optimizaci\'on, las ciencias de la computaci\'on, algunas ramas de la 
ingenier\'{\i}a, ciencias de la cognici\'on y el lenguaje, y ramas de la 
filosof\'{\i}a tales como la l\'ogica y la epistemolog\'{\i}a. Consta de 
diferentes m\'etodos para realizar inferencias a partir de ciertos 
datos, la m\'aquina debe ``aprender'' de los datos de entrada y luego 
``tomar decisiones''. La IA tiene aplicaciones m\'ultiples, tales como 
los sistemas de b\'usqueda, protocolos de diagn\'osticos m\'edicos, 
reconocimiento de patrones y rostros, traductores y sintetizadores de 
voz, secuenciaci\'on gen\'omica, sistemas expertos y rob\'otica, etc. En 
las charlas se presentar\'an los conceptos b\'asicos de la IA. Se har\'a 
\'enfasis en los m\'etodos llamados redes neuronales artificiales, en 
especial las redes neuronales de muchas capas, se ilustrar\'a lo 
anterior con algunos ejemplos. Se comentar\'an algunos paquetes que 
permiten implementar redes neuronales artificiales, como el Pytorch, y 
se ilustrar\'a su uso con algunos ejemplos, entre ellos el 
reconocimiento de im\'agenes.

\vfill

\end{frame}

%-------------------------------------------------------------------

 \section{Introducci\'on}
 \begin{frame}{Introducci\'on}

La llamada inteligencia artificial busca m\'etodos para realizar 
inferencias a partir de ciertos datos. El programa debe ``aprender'' de 
los datos de entrada y luego ``tomar decisiones''. Se acostumbra 
clasificar los m\'etodos de aprendizaje autom\'atico en las siguientes 
categor\'{\i}as: (1) Aprendizaje supervisado, en el cual se ingresan 
datos de entrenamiento (en la forma de caracter\'{\i}sticas 
acompa\~nadas de la correspondiente clasificaci\'on), con la esperanza 
de que luego el programa le asigne el \'{\i}ndice de clasificaci\'on a 
un dato nuevo no usado en el entrenamiento. (2) En el no supervisado no 
se da un ``entrenamiento'' sino unos datos sin clasificaci\'on, de los 
cuales se espera que el programa los agrupe e identifique 
caracter\'{\i}sticas comunes en cada agrupamiento. (3) El aprendizaje de 
refuerzo posee un tipo de realimentaci\'on o ``recompensa'', dependiente 
de la cual el programa se alimenta con los datos que dan lugar a 
maximizaci\'on de la recompensa.

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{}

El aprendizaje autom\'atico busca entender e implementar los 
procedimientos que les permitir\'{\i}an a las computadoras ``aprender''. 
Involucra diferentes disciplinas de las ciencias de la computaci\'on, 
como la estad\'{\i}stica computacional y la complejidad computacional. 
Se relaciona con problemas matem\'aticos no resueltos como son la 
determinaci\'on del grado de dificultad de los algoritmos, el cual puede 
ser polinomial o exponencial.

Es un campo interdisciplinario que involucra la estad\'{\i}stica, 
problemas matem\'aticos de optimizaci\'on, las ciencias de la 
computaci\'on, algunas ramas de la ingenier\'{\i}a, ciencias de la 
cognici\'on y el lenguaje, y ramas de la filosof\'{\i}a tales como la 
l\'ogica y la epistemolog\'{\i}a.

Tiene aplicaciones m\'ultiples, tales como los sistemas de b\'usqueda, 
protocolos de diagn\'osticos m\'edicos, reconocimiento de patrones y 
rostros, traductores y sintetizadores de voz, secuenciaci\'on 
gen\'omica, sistemas expertos y rob\'otica. En f\'{\i}sica hay muchas 
aplicaciones, como los experimentos LIGO, BICEP, LHC, estudios de 
estructura y espectro de mol\'eculas, etc.

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{}

 \vfill
 \centerline{\psfig{figure=InteligenciaArtificial-Top30Technologies.eps, 
 width=\hsize}}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{Modelos}

\textbf{Modelos geom\'etricos}. Los estados de un sistema se representan 
como vectores en un expacio multidimensional. Se pueden agrupar en 
clases, identificadas por cierta caracter\'{\i}stica com\'un. Por lo 
tanto las clases son subespacios de estados. La pregunta b\'asica es la 
determinaci\'on de la clase a la cual pertenece un estado (dato) dado. 
Dicha clasificaci\'on involucra conceptos geom\'etricos, tales como 
conexidad, distancia, perpendicularidad, paralelismo, etc.

\textbf{Modelos probabil\'{\i}sticos}. La pertenencia a determinada 
clase puede establecerse mediante una distribuci\'on de probabilidades. 
Se suele usar la estad\'{\i}stica bayesiana.

\textbf{Modelos l\'ogicos}. Ejemplos de tales modelos son los llamados 
\'arboles de decisi\'on.

 \end{frame}

%-------------------------------------------------------------------

 \section{Algoritmos}
 \begin{frame}{Algoritmos Supervisados}

El programa tiene como entrada pares de datos, $(\bm{x}_i,y_i)$, que se 
usan como ``entrenamiento de la m\'aquina''. $\bm{x}_i$ es un vector de 
$D$ componentes y, usualmente, $y_i$ es un escalar que toma dos valores. 
$i=1,2,...N$ es un \'{\i}ndice que recorre los $N$ datos.

La salida, por su parte, suele darse como los par\'ametros de una 
funci\'on de regresi\'on lineal o no lineal.

El objetivo del aprendizaje supervisado es crear una funci\'on que 
permita hacer predicciones, es decir responder cuestiones que no est\'an 
presentes en los datos de entrada.

Un ejemplo muy simple es la regresi\'on lineal. Dadas $N$ parejas de 
datos $(x_i,y_i)$, encontrar los par\'ametros $\beta_0$ y $\beta_1$ de 
una funci\'on lineal tal que
 $$
 y_i = \beta_0 + \beta_1 x_i;\quad i=1,2,...N.
 $$ El modelo permite predecir el valor de $\hat{y}$ correspondiente a 
un dato $\hat{x}$ no presente en los datos, $\{x_1,x_2,...x_N\}$, usados 
para definir los par\'ametros, $\beta_0$ y $\beta_1$, de la regresi\'on.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

La clasificaci\'on es un ejemplo simple de reconocimiento de patrones. 
Por ejemplo, dados los tipos de sangre A, B, AB, O, encontrar el tipo al 
cual pertenece una muestra dada.

La \textbf{clasificaci\'on} pretende determinar a cu\'al categor\'{\i}a 
pertenece una nueva observaci\'on, dentro de un conjunto de 
categor\'{\i}as predefinido. El algoritmo se llama clasificador.

Terminolog\'{\i}a: Casos son las observaciones. Variables explicativas 
son las caracter\'{\i}sticas. Clases son las posibles categor\'{\i}as 
que agrupan caracter\'{\i}sticas.

\textbf{Ejemplo}. Uso de una fuente de voltaje para establecer una 
clasificaci\'on binaria. A los voltajes $V\le0.5V$ se les asigna la 
clase del bit $0$. A los voltajes $V>0.5V$ se les asigna la clase del 
bit $1$.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Mathematica}

Conjunto de entrenamiento:

 $$
 \begin{array}{l}
 
trs=\{0{.}1\to"0",0{.}2\to"0",0{.}3\to"0",0{.}4\to"0",0{.}5\to"0",0{.}6\to"1", 
 \\ 0{.}7\to"1", 0{.}8\to"1", 0{.}9\to"1"\}\\
 c=Classify[trs]\\
 c[0{.}53] \\
  0 \\
  c[0{.}53, "Probabilities"] \\
  \{0\to0{.}805, 1\to0{.}195\} 
 \end{array}
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 Distribuci\'on de probabilidades.

 \vfill
 \centerline{\psfig{figure=Prob0.eps,width=0.5\hsize}\psfig{figure=Prob1.eps,width=0.5\hsize}}

 \centerline{$Plot[c[x, \{"Probability", "0"\}], \{x, 0, 1\}].
 $Plot[c[x, \{"Probability", "1"\}], \{x, 0, 1\}].}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{El Perceptr\'on}

Modela una \textbf{neurona}. Recibe $D$ entradas, $x_1$, ... $x_D$, 
chequea el resultado y produce una salida. Realiza una \textbf{suma} 
ponderada de las entradas, chequea el resultado y dependiendo del mismo 
produce una salida. Se usa para clasificar datos que se agrupan en 
clases separables linealmente (la m\'as simple es la clasificaci\'on 
binaria).

En el perceptr\'on de una capa se tienen $D$ datos de entrada, $x_1$, 
... $x_D$. Cada entrada tiene asociado un peso $w_1$, ... $x_D$.
La suma es
 $$
 s = \sum\limits_{i=1}^Dw_ix_i.
 $$
 La salida, $y$, est\'a determinada por cierta \textbf{funci\'on de 
activaci\'on}, $f(s)$,
 $$
 y = f(s).
 $$

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{Una ``Red'' que Produce la Puerta NOT}

Es trivial porque s\'olo hay una entrada, $x$, y una salida, $y$, ambas 
binarias. La salida deseable es el NOT de la entrada. Es decir, que si 
$x=0$ entonces $y=1$ y si $x=1$ entonces $y=0$.

N\'otese que si se hace $w=1$, entonces $s=x$. Si se toma como funci\'on 
de activaci\'on la \texttt{identidad} entonces $f(s)=s$. Resulta 
as\'{\i} la puerta l\'ogica identidad. Sin embargo, si se suma cierta 
cantidad $\theta$, llamada en ingl\'es ``\textit{bias}'' (que se puede 
traducir como ``sesgo'', ``polarizaci\'on'' o ``desplazamiento''), puede 
lograrse la puerta l\'ogica NOT,
 $$
 s = w\cdot x + \theta,\ y= f(s).
 $$
 As\'{\i}, tomando $w=1$, $\theta=1$ se obtiene $f(s)=w\cdot x + 
\theta=1\cdot x+1=x+1$, lo cual, con suma en la base binaria, da $0+1=1$ 
y $1+1=0$.

Puede verse que la funci\'on de activaci\'on se define por conveniencia, 
de acuerdo al problema que se tenga.

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{Conexi\'on Con el Mapa Log\'{\i}stico}

Una funci\'on de activaci\'on muy usada es la log\'{\i}stica o sigmoide,
 $$
 f(z) = \frac{1}{1+e^{-z}},
 $$
 cuya derivada tiene la propiedad $f'(z) = f(z)[1-f(z)]$.

Si llamamos $x_n = f(z)$ y $x_{n+1} = f(z+\Delta)$, la derivada de la 
funci\'on log\'{\i}stica se puede escribir como,
 $$
 \frac{x_{n+1} - x_n}{\Delta} = x_n (1-x_n) \to x_{n+1} = (1+\Delta)
 x_n - \Delta\cdot x_n^2.
 $$
 Con el cambio de escala
 $$
 x_n\to\frac{1+\Delta}{\Delta}x_n,
 $$
 se llega al mapa log\'{\i}stico $x_{n+1} = r x_n(1-x_n)$, donde 
$r=1+\Delta$.

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{Perceptr\'on y Sigmoide}

 \vfill
 \centerline{\psfig{figure=Perceptron.eps,height=0.4\hsize,width=0.5\hsize}\psfig{figure=Sigmoide.eps,height=0.4\hsize,width=0.5\hsize}}

 \centerline{Perceptr\'on de una sola capa. \hfill Sigmoide\hfill}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{Perceptr\'on de Muchas Capas (MLP)}

Un perceptr\'on de muchas capas (o red neuronal artificial) con una sola 
capa oculta se puede representar gr\'aficamente como sigue:

 \setlength{\unitlength}{.1cm}
 \begin{picture}(100,20)
 \linethickness{3pt}
 \thicklines
 \put(12,3){\circle*{3}}
 \put(32,3){\circle*{3}}
 \put(52,3){\circle*{3}}
 \put(2,10){\circle*{3}}
 \put(22,10){\circle*{3}}
 \put(42,10){\circle*{3}}
 \put(62,10){\circle*{3}}
 \put(22,17){\circle*{3}}
 \put(42,17){\circle*{3}}
 \put(12,3){\vector(-10,7){9.2}}
 \put(12,3){\vector(10,7){9.2}}
 \put(12,3){\vector(30,7){29}}
 \put(12,3){\vector(50,7){49}}
 \put(2,10){\vector(20,7){19}}
 \put(2,10){\vector(40,7){39}}
 \put(68,3){\textbf{Capa de entrada}}
 \put(68,10){\textbf{Capa oculta}}
 \put(68,17){\textbf{Capa de salida}}
 \end{picture}

Un MLP es una funci\'on $F:R^I\to R^O$, donde $I$ es el tama\~no del 
vector de entrada y $O$ del de salida, tal que,
 $$
 F(x) = f\{b^{(2)} + W^{(2)}[g(b^{(1)} + W^{(1)}x)]\},
 $$
 donde $b^{(1)}$ y $b^{(2)}$ son vectores de sesgo, $W^{(1)}$ y 
$W^{(2)}$ son matrices de pesos, y $f$ y $s$ son funciones de 
activaci\'on. El vector $h(x)=g(b^{(1)} + W^{(1)}x)$ constituye la capa 
oculta. $x$ es la entrada y $F(x)$ la salida. $W^{(1)}\in R^{(I\times 
H)}$, donde $H$ es el tama\~no del vector oculto, es la matriz de peso 
que conecta el vector de entrada $x$ a la capa oculta $h(x)$.

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{}

Son de inter\'es las funciones de activaci\'on $f$ llamadas 
``\textit{tanh}'', con $\tanh(z)=(e^z-e^{-z})/(e^z+e^{-z})$, y la 
``\textit{sigmoide}'' log\'{\i}stica, con $\textrm{sigmoide}(z) = 
1/(1+e^{-z})$. Tanto $tanh$ como $sigmoide$ son funciones $R\to R$ pero 
tienen extensi\'on natural a vectores, aplic\'andolas a cada componente 
por separado. El vector de salida se obtiene como $o(x) = f[b^{(2)} + 
W^{(2)} h(x)]$.
 
Para entrenar un MLP, se determinan todos los par\'ametros del modelo a 
partir de los datos de entrenamiento. Para ello se puede usar el 
algoritmo del descenso estoc\'astico del gradiente. El conjunto de 
par\'ametros resultantes es $\theta = 
\{W^{(2)},b^{(2)},W^{(1)},b^{(1)}\}$. La obtenci\'on de los gradientes 
$\partial{\ell}/\partial{\theta}$ se puede lograr mediante un algoritmo 
de propagaci\'on hacia atr\'as. $\ell$ es la llamada funci\'on de 
p\'erdida, en t\'erminos de la cual se define cierto problema de 
optimizaci\'on.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Algoritmos de Aprendizaje de Refuerzo}

La m\'aquina recibe datos $x_1,...$ del entorno y dependiendo de los 
mismos realiza acciones $a_1,...$ Esas acciones modifican el estado del 
entorno, lo cual a su vez implica que el entorno reacciona 
entreg\'andole a la m\'aquina recompensas (o castigos) $r_1,...$ La meta 
de la m\'aquina es aprender a actuar de modo que se maximicen las 
futuras recompensas que haya de recibir (o se minimicen los castigos) 
durante su tiempo de vida. El aprendizaje de refuerzo se relaciona con 
la \textbf{teor\'{\i}a de decisi\'on} (estad\'{\i}stica y 
administraci\'on) y la teor\'{\i}a del control autom\'atico 
(ingenier\'{\i}a).

Una variante es la \textbf{teor\'{\i}a de juegos}. La m\'aquina consigue 
entradas, produce acciones, recibe recompensas y aprende. Sin embargo, 
el entorno con el cual interact\'ua la m\'aquina no es est\'atico, sino 
que est\'a formado por otras m\'aquinas que hacen lo mismo que la 
primera: Consiguen datos de entrada, producen salidas, act\'uan sobre 
las otras m\'aquinas, reciben recompensas por las salidas, aprenden. La 
meta de la m\'aquina es aprender a actuar de modo que se maximicen las 
recompensas.

 \end{frame}

%-------------------------------------------------------------------

 \section{Modelos de Redes Neuronales}
 \begin{frame}{Modelos de RN}

Hay muchos modelos de RN, por ejemplo los modelos de Hopfield y la 
llamada M\'aquina de Boltzmann Restringida (Restricted Boltzmann Machine 
o RBM). Los mismos se usan, entre otros, en el problema de 
reconocimiento de im\'agenes. Una imagen se puede reducir a un conjunto 
de ``pixeles'', una tira de binarios.

El problema m\'as simple consiste en que si se da un conjunto de 
im\'agenes ``de entrenamiento'', hallar la imagen de este conjunto que 
se parece con mayor probabilidad a una imagen dada.

En la red neuronal de Hopfield se toma un conjunto de datos de 
``entrenamiento'', con los cuales se ajustan los par\'ametros de la red. 
Luego es posible determinar con cu\'al de los datos de entrenamiento 
concuerda con mayor probabilidad una nueva entrada que no necesariamente 
coincide con alguna de las del entrenamiento.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Memoria Asociativa Bidireccional (BAM)}

En una BAM cada patr\'on de entrenamiento se almacena en las conexiones 
entre las componentes de la red, $w_{ij}$. Esto constituye la llamada 
``memoria asociativa''. Cuando recibe un nuevo patr\'on la memoria 
asociativa activa (recuerda) el patr\'on almacenado que m\'as se parece 
a la entrada. Es el llamado perceptr\'on de una capa.

 \setlength{\unitlength}{.13cm}
 \begin{picture}(100,30)
 \linethickness{3pt}
 \thicklines
 \put(12,3){\circle*{4}}
 \put(32,3){\circle*{4}}
 \put(52,3){\circle*{4}}
 \put(12,17){\circle*{4}}
 \put(32,17){\circle*{4}}
 \put(52,17){\circle*{4}}
 \put(12,3){\vector(0,20){12}}
 \put(12,3){\vector(20,14){18}}
 \put(12,3){\vector(40,14){38}}
 \put(32,3){\vector(-20,14){18}}
 \put(32,3){\vector(20,14){18}}
 \put(32,3){\vector(0,7){12}}
 \put(52,3){\vector(0,20){12}}
 \put(52,3){\vector(-20,14){18}}
 \put(52,3){\vector(-40,14){38}}
 \put(12,-3){\vector(0,14){4}}
 \put(32,-3){\vector(0,14){4}}
 \put(52,-3){\vector(0,14){4}}
 \put(12,19){\vector(0,14){4}}
 \put(32,19){\vector(0,14){4}}
 \put(52,19){\vector(0,14){4}}
 \put(68,3){\textbf{Capa de entrada}}
 \put(68,17){\textbf{Capa de salida}}
 \put(10,-6){$\bm{x_1}$}
 \put(30,-6){$\bm{x_2}$}
 \put(50,-6){$\bm{x_3}$}
 \put(10,25){$\bm{y_1}$}
 \put(30,25){$\bm{y_2}$}
 \put(50,25){$\bm{y_3}$}
 \put(6,12){$\bm{w_{11}}$}
 \put(13,8){$\bm{w_{12}}$}
 \put(20,4){$\bm{w_{13}}$}
 \end{picture}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

En una ``memoria asociativa bidireccional'' (BAM), si $\bm{x}_0$ es un 
vector de entrada de $D$ dimensiones y $\bm{y}_0$ el correspondiente 
vector de salida de $F$ dimensiones, la matriz de pesos $W$ tendr\'a 
dimensi\'on $D\times F$. La relaci\'on entre la entrada y la salida es 
(usando SGN como funci\'on de activaci\'on),
 $$
 \bm{y}_0 = SGN(\bm{x}_0\cdot W).
 $$
 En un paso de ``feed-back'', $\bm{y}_0$ es la entrada y $\bm{x}_1$ es 
la salida,
 $$
 \bm{x}_1 = SGN(W\cdot\bm{y}_0^T).
 $$
 Una nueva iteraci\'on de izquierda a derecha produce
 $$
 \bm{y}_1 = SGN(\bm{x}_1\cdot W).
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 Despu\'es de $m$ iteraciones el sistema ha calculado $m+1$ pares de 
vectores $(\bm{x}_0,\bm{y}_0)$, $(\bm{x}_1,\bm{y}_1)$, ... 
$(\bm{x}_m,\bm{y}_m)$, los cuales cumplen las condiciones,
 $$
 \bm{y}_i = SGN(\bm{x}_i\cdot W),\quad
 \bm{x}_{i+1}^T = SGN(W\cdot\bm{y}_i^T).
 $$
 Surge el problema de encontrar un \textbf{punto fijo} 
$(\bm{x},\bm{y})$,
 $$
 \bm{y} = SGN(\bm{x}\cdot W),\quad
 \bm{x}^T = SGN(W\cdot\bm{y}^T).
 $$
 Los mismos bordes se pueden usar para transmitir informaci\'on en las 
dos direcciones. 

Se demuestra que el llamado \textbf{aprendizaje de Hebb} es condici\'on 
para la existencia del punto fijo de una BAM. Esto a su vez determina la 
matriz $W$ adecuada.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Aprendizaje de Hebb}

 Si $N$ es el n\'umero de patrones de entrenamiento (``datos''), donde 
$x_i^k$ es la $k$-\'esima entrada a la neurona $i$, y $y_j^k$ es la 
$k$-\'esima salida de la neurona $j$, el peso de la conexi\'on entre las 
neuronas $i$ y $j$ es
 $$
 w_{ij} = \frac{1}{N} \sum\limits_{k=1}^N x_i^ky_j^k.
 $$
 Es decir, $W = \bm{x}^T\bm{y}$. Entonces,
 $$
 \bm{y} = SGN(\bm{x}\cdot W) = SGN(\bm{x}\cdot\bm{x}^T\bm{y}) =
 SGN(\vert\bm{x}\vert^2\bm{y}) = \bm{y}.
 $$
 Tambi\'en,
 $$
 \bm{x}^T = SGN(W\cdot\bm{y}^T) = SGN(\bm{x}^T\bm{y}\cdot\bm{y}^T) =
 SGN(\bm{x}^T\vert\bm{y}\vert^2) = \bm{x}^T.
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 Para un conjunto de $m$ pares de vectores la matriz $W$ (sim\'etrica) 
es
 $$
 W = \bm{x}_1^T\bm{y}_1 + \bm{x}_2^T\bm{y}_2 + ... \bm{x}_m^T\bm{y}_m.
 $$
 Con las componentes de los vectores $\bm{x}_k$ se pueden formar las 
matrices $X$ y $X^T$. Se cumple
 $$
 X = X\cdot W,\quad X^T = W\cdot X^T,
 $$
 lo cual caracteriza a una BAM.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Red Neuronal de Hopfield (HNN)}

En el modelo HNN se supone que los nodos individuales mantienen sus 
estados hasta que sean seleccionados para una actualizaci\'on. La 
selecci\'on ocurre al azar. Una HNN consta de $n$ nodos totalmente 
acoplados entre si, cada uno est\'a conectado con todos los dem\'as 
excepto con \'el mismo. La red es sim\'etrica dado que $w_{ij}$ 
establece tanto la conexi\'on entre el nodo $i$ y el nodo $j$ como entre 
el $j$ y el $i$, hay una conexi\'on bidireccional entre ambos nodos de 
igual intensidad.

 \DIVIDE{1.}{2.}{\coss}
 \DIVIDE{1.73205}{2.}{\sins}
 \MULTIPLY{50}{\sins}{\ymax}
 \MULTIPLY{3.5}{\coss}{\xu}
 \MULTIPLY{3.5}{\sins}{\yu}
 \SUBTRACT{\ymax}{\yu}{\yv}
 \SUBTRACT{25}{\xu}{\xv}
 \SUBTRACT{50}{\xu}{\xd}
 \ADD{25}{\xu}{\xt}
 \setlength{\unitlength}{.09cm}
 \begin{picture}(50,\ymax)(-45,0)
 \linethickness{3pt}
 \thicklines
 \put(0,0){\circle{7}}
 \put(25,\ymax){\circle{7}}
 \put(50,0){\circle{7}}
 \put(6,0){\vector(1,0){41}}
 \put(44,0){\vector(-1,0){41}}
 \put(\xu,\yu){\vector(0.5,0.866){21.5}}
 \put(\xv,\yv){\vector(-0.5,-0.866){21.5}}
 \put(\xt,\yv){\vector(0.5,-0.866){21.5}}
 \put(\xd,\yu){\vector(-0.5,0.866){21.5}}
 \put(-1.5,0){$\bm{x_1}$}
 \put(48.5,0){$\bm{x_2}$}
 \put(23.5,\ymax){$\bm{x_3}$}
 \put(13,20){$\bm{w_{13}}$}
 \put(30,20){$\bm{w_{23}}$}
 \put(21.5,2){$\bm{w_{12}}$}
 \end{picture}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

Es decir, la HNN es una red BAM (asincr\'onica) en la cual las capas 
izquierda y derecha se funden en una \'unica capa.

$W$ es una matriz $n\times n$ en la cual $w_{ii} = 0$ para $i = 1,...n$ 
(cero en la diagonal). $W$ es sim\'etrica, $w_{ij} = w_{ji}$.

Si $W$ no fuera sim\'etrica o tuviera elementos no nulos en la diagonal, 
la red podr\'{\i}a oscila sin alcanzar un punto fijo. Por lo tanto 
$w_{ij} = w_{ji}$ y $w_{ii} = 0$ son condiciones necesarias para la 
convergencia de una red asincr\'onica totalmente conectada a un estado 
estable. Tambi\'en son suficientes.

Si la HNN tiene umbral $\theta\ne0$, se procede como con la BAM. En este 
caso $\theta_L = \theta_T = \theta$.

Al poner $Y$ coincidiendo con $X$ se obtiene,
 $$
 \begin{array}{rcl}
 E(X) &=& -\frac{1}{2} X\cdot W\cdot X^T + \theta\cdot X^T \\
 &=&\displaystyle-\frac{1}{2}\sum\limits_{i=1}^n\sum\limits_{j=1}^n 
 w_{ij}x_ix_j + \sum\limits_{i=1}^n\theta_ix_i.
 \end{array}
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

La energ\'{\i}a de Hopfield es una forma cuadr\'atica. La red de Hopfield 
siempre tiene un m\'{\i}nimo local de la funci\'on de energ\'{\i}a.

\textbf{Ejemplo}. La red de Hopfield flip-flop. Si $N=1$ y $n=2$,
 $$
 x_i = SGN(x_iW), i=1,2.\quad x_2 = SGN(Wx_1).
 $$
 Los puntos fijos cumplen,
 $$
 x = SGM(w_{12}x).
 $$
 Si $w_{12} = w_{21} = 1$ no hay cambio, pero si $w_{12} = w_{21} = -1$, 
los estados estables de los dos nodos son $(1,-1)$ y $(-1,1)$.

 Si el umbral se toma cero, la energ\'{\i}a vale
 $$
 E(x_1,x_2) =  x_1x_2.
 $$
 S\'olo los 4 estados (1,1), (1,-1), (-1,1), (-1,-1) son permitidos. 
Entonces la energ\'{\i}a tiene m\'{\i}nimo local en $(-1,1)$ y en 
$(1,-1)$.

Un flip-flop es una red capaz de almacenar uno de los estados $(-1,1)$ o 
$(1,-1)$.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

\vfill

\centerline{\psfig{figure=cubo.eps, height=0.6\vsize}}

Funci\'on de energ\'{\i}a de un flip-flop. En los m\'{\i}nimos locales 
$(-1,1)$ y $(1,-1)$ la energ\'{\i}a vale $-1$. En los m\'aximos locales 
$(1,1)$ y $(-1,-1)$ la energ\'{\i}a vale $1$. Un flip-flop es una red 
capaz de almacenar uno de los estados $(-1,1)$ o $(1,-1)$.

\vfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Puerta L\'ogica CNOT Con la Red de Hopfield}

 La red de 3 unidades permite almacenar la funci\'on l\'ogica CNOT. Esta 
red tiene $2^3=8$ estados: $(-1,-1,-1)$, $(-1,-1,1)$, ... $(1,1,1)$. 
S\'olo tiene 4 m\'{\i}nimos locales, en los siguientes 4 puntos del 
espacio 3D, todos con energ\'{\i}a $-1$.
 $$
 \begin{array}{cccc}
 PUNTO & TARGET & CONTROL & CNOT \\
 1. & -1 & -1 & -1 \\
 2. & 1  & -1 & 1 \\
 3. & -1 & 1  & 1 \\
 4. & 1  & 1  & -1 
 \end{array}
 $$
 El control y el target forman 4 puntos de 2 bits: $(-1.-1)$, $(-1.1)$, 
$(1.-1)$, $(1.1)$. Por su parte, $CNOT$ es una funci\'on que toma uno de 
estos 4 puntos y los env\'{\i}a en $-1$ o $1$.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Separaci\'on en Dos Clases}

 Una recta puede separar siempre 3 puntos con una recta en las clases 
``$+$'' y ``$-$''. Las posibles tr\'{\i}adas de puntos son: $-,-,-$\quad 
$-,-,+$\quad $-,+,-$\quad $-,+,+$\quad $+,-,-$\quad $+,-,+$\quad 
$+,+,-$\quad $+,+,+$\quad.

 \vfill\hfill
 \setlength{\unitlength}{0.1cm}
 \begin{picture}(100,25)
 \linethickness{3pt}
 \thicklines
 \put(0,0){\line(1,1){24}}
 \put(23,0){\line(1,1){24}}
 \put(48,0){\line(1,1){24}}
 \put(73,0){\line(1,1){24}}
 \put(-7.,0.){\color{red}$\bm{+}$}
 \put(3.,10.){\color{red}$\bm{+}$}
 \put(13.,20.){\color{red}$\bm{+}$}
 \put(4.,0.){$\bm{}$}
 \put(14.,10.){$\bm{}$}
 \put(24.,20.){$\bm{}$}
 \put(17.,0.){\color{red}$\bm{+}$}
 \put(27.,10.){\color{red}$\bm{+}$}
 \put(37.,20.){$\bm{}$}
 \put(28.,0.){\color{blue}$\bm{-}$}
 \put(38.,10.){$\bm{}$}
 \put(48.,20.){$\bm{}$}
 \put(41.,0.){\color{red}$\bm{+}$}
 \put(51.,10.){$\bm{}$}
 \put(61.,20.){$\bm{}$}
 \put(52.,0.){\color{blue}$\bm{-}$}
 \put(62.,10.){\color{blue}$\bm{-}$}
 \put(72.,20.){$\bm{}$}
 \put(66.,0.){$\bm{}$}
 \put(77.,10.){$\bm{}$}
 \put(87.,20.){$\bm{}$}
 \put(76.,0.){\color{blue}$\bm{-}$}
 \put(87.,10.){\color{blue}$\bm{-}$}
 \put(98.,20.){\color{blue}$\bm{-}$}
 \end{picture}
 \hfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

Una recta del plano no puede separar 4 puntos tomados de las $2^4=16$ 
cuartetas $(-,-,-,-)$\ $(-,-,-,+)$\ $(-,-,+,-)$\ $(-,-,+,+)$\ 
$(-,+,-,-)$\ $(-,+,-,+)$\ $(-,+,+,-)$\ $(-,+,+,+)$\ $(+,-,-,-)$\ 
$(+,-,-,+)$\ $(+,-,+,-)$\ $(+,-,+,+)$\ $(+,+,-,-)$\ $(+,+,-,+)$\ 
$(+,+,+,-)$\ $(+,+,+,+)$\ con la clase ``$+$'' a un lado de la recta y 
la clase ``$-$'' al otro lado. Se requieren dos rectas, lo cual no da 
lugar a una separaci\'on en dos clases. Por ejemplo

 \vspace{1cm}
 \hfill
 \setlength{\unitlength}{0.2cm}
 \begin{picture}(45,10)
 \linethickness{3pt}
 \thicklines
 \put(0,0){\line(1,1){12}}
 \put(23,0){\line(1,1){12}}
 \put(-2.,5.){\color{red}$\bm{+}$}
 \put(3.,10.){\color{red}$\bm{}$}
 \put(13.,20.){\color{red}$\bm{}$}
 \put(10.,0.){\color{blue}$\bm{-}$}
 \put(20.,10.){\color{blue}$\bm{-}$}
 \put(24.,20.){$\bm{}$}
 \put(34.,5.){\color{red}$\bm{+}$}
 \put(37.,20.){$\bm{}$}
 \end{picture}
 \hfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 Los puntos de la $CNOT$ se pueden colocar en el plano $x_1-x_2$.

 \vspace{1cm}
 \hfill
 \setlength{\unitlength}{0.2cm}
 \begin{picture}(45,10)
 \linethickness{3pt}
 \thicklines
 \put(0,0){\vector(1,0){10}}
 \put(0,0){\vector(0,1){10}}
 \put(22,0){\line(1,0){10}}
 \put(22,0){\line(0,1){10}}
 \put(32,0){\line(0,1){10}}
 \put(32,10){\line(-1,0){10}}
 \put(32,-5){\line(-1,1){15}}
 \put(37,0){\line(-1,1){15}}
 \put(0.,11.){\color{red}$\bm{x_2}$}
 \put(11.,0.){\color{red}$\bm{x_1}$}
 \put(17.,11.){\color{blue}$\bm{(-1,1)}$}
 \put(32.,11.){\color{blue}$\bm{(1,1)}$}
 \put(17.,-3.){\color{blue}$\bm{(-1,-1)}$}
 \put(32.,-3.){\color{blue}$\bm{(1,-1)}$}
 \put(31.5,-0.5){\color{red}$\bm{\bullet}$}
 \put(31.5,9.5){\color{red}$\bm{\bullet}$}
 \put(21.5,-0.5){\color{red}$\bm{\bullet}$}
 \put(21.5,9.5){\color{red}$\bm{\bullet}$}
 \end{picture}
 \hfill

 \vspace{1cm}

 Los puntos $(-1,1)$ y $(1,-1)$ son estables. Los puntos $(-1,-1)$ y 
$(1,1)$ son inestables.

 Ninguna red de Hpfield de 3 unidades puede tener los 4 estados 
estables.

El problema de $CNOT$ se resuelve si la red se extiende a 4 unidades. La 
cuarta hace el papel de ancilla. Se tiene as\'{\i} la $CNOT$ 
\textbf{reversible}.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 La red de 4 unidades permite almacenar la funci\'on l\'ogica $CNOT$ 
reversible. Esta red tiene $2^4=16$ estados, de los cu\'ales 4 
corresponden a la $CNOT$:
 $$
 \begin{array}{cccc}
 CONTROL & TARGET & CNOT & ANCILLA \\
 -1 & -1 & -1 & 1 \\
 1  & -1 & 1  & 1\\
 -1 & 1  & 1  & 1 \\
 1  & 1  & -1 & -1 \\
 x_1 & x_2 & x_3 & x_4
 \end{array}
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

La red neuronal para la puerta $CNOT$ consta de tres neuronas que 
corresponden a dos entradas y una salida. Tambi\'en es posible 
representarla por cuatro neuronas, donde tres neuronas corresponden a 
dos entradas y una salida, y la cuarta es adicional. La red neuronal 
para un circuito l\'ogico cualquiera se caracteriza por una funci\'on de 
energ\'{\i}a $E$ que tiene un m\'{\i}nimo global (que se puede escoger 
como $0$) s\'olo en los estados compatibles con la definici\'on de la 
operaci\'on l\'ogica. Los dem\'as estados tienen energ\'{\i}a m\'as 
alta. Dicha funci\'on se puede escribir como sigue,
 $$
 E = -\frac{1}{2}\sum\limits_{i,j=1,i\ne j}^n w_{ij}x_ix_j-
 \sum\limits_{i=1}^n b_ix_i + K,
 $$ donde $n$ es el n\'umero de neuronas en la red neuronal, $w_{ij}$ es 
el peso asociado con el enlace entre las neuronas $i$ y $j$, $x_i$ es el 
valor de activaci\'on de la neurona $i$, $b_i$ es el umbral asociado con 
la neurona $i$ y $K$ es una constante.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Red Neuronal de la Puerta CNOT}

 \DIVIDE{1.}{2.}{\coss}
 \DIVIDE{1.73205}{2.}{\sins}
 \MULTIPLY{50}{\sins}{\ymax}
 \MULTIPLY{3.5}{\coss}{\xu}
 \MULTIPLY{3.5}{\sins}{\yu}
 \DIVIDE{\ymax}{3.0}{\yc}
 \SUBTRACT{\ymax}{\yu}{\yv}
 \SUBTRACT{25}{\xu}{\xv}
 \SUBTRACT{50}{\xu}{\xd}
 \ADD{25}{\xu}{\xt}
 \setlength{\unitlength}{.09cm}
 \begin{picture}(50,\ymax)(-45,0)
 \setlength{\unitlength}{.09cm}
 \linethickness{3pt}
 \thicklines
 \put(0,0){\circle{7}}
 \put(25,\ymax){\circle{7}}
 \put(50,0){\circle{7}}
 \put(25,\yc){\circle{7}}
 \put(6,0){\vector(1,0){41}}
 \put(44,0){\vector(-1,0){41}}
 \put(\xu,\yu){\vector(0.5,0.866){21.5}}
 \put(\xv,\yv){\vector(-0.5,-0.866){21.5}}
 \put(\xt,\yv){\vector(0.5,-0.866){21.5}}
 \put(\xd,\yu){\vector(-0.5,0.866){21.5}}
 \put(2.9,1.5){\vector(11,7){19.3}}
 \put(4.5,2.5){\vector(-11,-7){1.9}}
 \put(25,40){\vector(0,-1){22.3}}
 \put(25,38.2){\vector(0,1){1.9}}
 \put(47.3,1.5){\vector(-11,7){19.3}}
 \put(45.7,2.5){\vector(11,-7){1.5}}
 \put(-1.5,0){$\bm{x_1}$}
 \put(48.5,0){$\bm{x_2}$}
 \put(23.5,\ymax){$\bm{x_3}$}
 \put(23.5,\yc){$\bm{x_4}$}
 \put(13,20){$\bm{w_{13}}$}
 \put(30,20){$\bm{w_{23}}$}
 \put(21.5,2){$\bm{w_{12}}$}
 \put(8.0,10){$\bm{w_{14}}$}
 \put(34.5,10){$\bm{w_{24}}$}
 \put(25.5,28){$\bm{w_{34}}$}
 \end{picture}

 \vspace{0.5cm}
 En la pr\'oxima clase se detallar\'a este ejemplo, el cual permite 
ilustrar conceptos centrales de las RN de muchas capas.

Continuaremos con el problema de la determinaci\'on de las clases 
presentes en un conjunto de datos, el cual es central para la 
clasificaci\'on.

 \end{frame}









%-------------------------------------------------------------------

 \section{M\'aquina de Soporte Vectorial (SVM)}
 \begin{frame}{El Conjunto de Datos de la Flor Iris}

 Las tablas de Fisher contienen los datos morfol\'ogicos de la planta 
iris. Son 50 datos de cada una de las 3 tipos de la flor iris (setosa, 
virginica y versicolor). Cada registro contiene 5 entradas: longitud y 
ancho de los c\'epalos y longitud y ancho de los p\'etalos, en cm, y la 
correspondiente especie de flor.

Fisher calcul\'o un discriminante lineal para distinguir una especie de 
otra. El correspondiente problema matem\'atico forma parte de la 
clasificaci\'on estad\'istica. Se puede implementar en aprendizaje 
autom\'atico, o ML, con diferentes algoritmos, uno de ellos llamado de 
M\'aquina de Soporte Vectorial (SVM).

\centerline{\texttt{https://en.wikipedia.org/wiki/Iris\_flower\_data\_set}}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Espacio Tetra Dimensional}

\centerline{Algunos Datos de Ronald Fisher del Iris (1936)}

 $$
 \begin{array}{ccccc}
 \bf Largo\ de & \bf Ancho\ de & \bf Largo\ de & \bf Ancho\ de & \\
 \bf s\'epalo & \bf s\'epalo & \bf p\'etalo & \bf p\'etalo & \bf Especie \\
 5.0 & 2.0 & 3.5 & 1.0 & I. versicolor \\
 6.2 & 2.2 & 4.5 & 1.5 & I. versicolor \\
 6.0 & 2.2 & 5.0 & 1.5 & I. virginica  \\
 6.0 & 2.2 & 4.0 & 1.0 & I. versicolor \\
 6.3 & 2.3 & 4.4 & 1.3 & I. versicolor \\
 5.5 & 2.3 & 4.0 & 1.3 & I. versicolor \\
 5.0 & 2.3 & 3.3 & 1.0 & I. versicolor \\
 4.5 & 2.3 & 1.3 & 0.3 & I. setosa     \\
 5.5 & 2.4 & 3.8 & 1.1 & I. versicolor \\
 5.5 & 2.4 & 3.7 & 1.0 & I. versicolor \\
 4.9 & 2.4 & 3.3 & 1.0 & I. versicolor \\
 6.7 & 2.5 & 5.8 & 1.8 & I. virginica
 \end{array}
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 \vfill
 \centerline{\psfig{figure=Iris1D.eps,width=\hsize}}

 \centerline{}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 \vfill
 \centerline{\psfig{figure=IrisDiagramaDeDispersion.eps,width=0.78\hsize}}

 \centerline{}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 \vfill
 \centerline{\psfig{figure=IrisDatos3D.eps,width=\hsize}}

 \centerline{}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 \vfill
 \centerline{\psfig{figure=IrisSetosaVersicolorVirginica.eps,width=\hsize}}

 \centerline{}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 El problema: Encontrar dos hiperplanos (superficies 3D inmersas en el 
espacio 4D) que produzcan una separaci\'on de los puntos de los 3 tipos 
de iris. Lo anterior marcar\'a fronteras de decisi\'on para futuras 
tareas de clasificaci\'on.

 Caso simple: Datos en 1D con s\'olo 2 clases. Se trata de hallar un 
punto $x$ que se sit\'ue exactamente entre los miembros de las clases 1 
y 2, tal que todos los puntos a la izquierda de $x$ pertenecen a una 
clase y los de la derecha a otra.

 Caso m\'as general en $D$ dimensiones con s\'olo 2 clases. Se trata de 
hallar un hiperplano $D-1$ dimensional que se sit\'ue exactamente entre 
los miembros de las clases 1 y 2, tal que todos los puntos a un lado 
pertenecen a una clase y los del otro lado a la otra clase. Se supone 
que las dos clases son disjuntas. El mejor hiperplano discriminador 
tiene la m\'axima distancia a los puntos de datos m\'as pr\'oximos de 
casa clase, los cuales se llaman ``vectores de soporte''.

 Se tiene el siguiente problema matem\'atico de optimizaci\'on: Hallar 
el hiperplano de ``m\'aximo margen'' o de ``separaci\'on \'optima'', el 
``m\'as alejado'' de los datos de entrenamiento.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Puntos $(x_1,x_2)$ De Dos Clases}

 \vfill
 \centerline{\psfig{figure=LineaSeparadora2Clases.eps,width=\hsize}}
 \centerline{}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Hiperplano de Separaci\'on}

 Obedece la ecuaci\'on
 $$
 \beta_0 + \beta_1x_1 + \beta_2x_2 + ... \beta_Dx_D = 0,
 $$
 donde $(x_1,x_2,...x_D)$ es un punto situado sobre el hiperplano.

 Las clases est\'an conformadas por puntos a cada uno de los 2 lados del 
hiperplano. Si $(x_1,x_2,...x_D)$, por fuera del hiperplano, es tal que
 $$
 \beta_0 + \beta_1x_1 + \beta_2x_2 + ... \beta_Dx_D > 0,
 $$
 decimos que ese punto pertenece a la clase $y=1$.
Si 
 $$
 \beta_0 + \beta_1x_1 + \beta_2x_2 + ... \beta_Dx_D < 0,
 $$
 decimos que el punto $(x_1,x_2,...x_D)$, por fuera del hiperplano, al 
``otro lado'' del anterior, pertenece a la clase $y=2$.

Por lo tanto la ecuaci\'on del hiperplano sirve de clasificador.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

Los puntos del ``soporte'' son tales que pertenecen a las dos clases y 
est\'an ubicados en hiperplanos paralelos al separador. Caracterizan la 
SVM.

Definamos dos vectores $D$ dimensionales $\bm{r}$ y $\bm{w}$ y un 
escalar $w_0$,
 $$
 \bm{r} = (x_1, x_2, ... x_D); \
 \bm{w} = (\beta_1, \beta_2, ... \beta_D);\
 w_0 = \beta_0.
 $$
 Los puntos ubicados sobre el separador satisfacen
 $$
 \bm{w}\cdot\bm{r} + w_0 = 0.
 $$
 Los puntos ubicados sobre uno de los dos planos de soporte satisfacen 
relaciones similares. $\bm{w}$ es com\'un a los tres planos, pero el 
$w_0$ obviamente es diferente, porque determina el sesgo de cada uno.

En el caso 2D, el ``hiperplano'' separador tiene una dimensi\'on menor, 
es una l\'{\i}nea recta.

 \end{frame}

%-------------------------------------------------------------------

\begin{frame}{Rectas de la Forma $mx-y+b=0$}

\vspace{1.0cm}
\setlength{\unitlength}{1.5mm}
\thicklines
\hspace{3.5cm}
\begin{picture}(40,40)(0,0)
\put(0,0){\vector(0,1){40}}
\put(0,0){\vector(1,0){40}}
\put(-10,0){\line(1,1){30}}
\put(-10,15){\line(1,1){30}}
\put(-10,35){\line(1,-1){30}}
\put(42,0){$x$}
\put(0,42){$y$}
\put(-3,24){$b$}
\put(-3,10){$b'$}
\put(4,22){$d$}
\put(-0.5,24.3){\color{red}$\bullet$}
\put(-0.5,9.5){\color{red}$\bullet$}
\put(15,38){$y=mx+b$}
\put(15,22){$y=mx+b'$}
\put(15,3){$y=\displaystyle-\frac{1}{m}x+b$}
\put(31,40){La distancia vale}
\put(31,35){$\displaystyle d = \frac{\vert b-b'\vert}{\sqrt{1+m^2}}$,}
\put(31,30){es m\'axima si $m=0$,}
\put(31,25){rectas paralelas.}
\put(31,20){Generalizaci\'on:}
\put(31,15){$\displaystyle d = \frac{\vert w_0-w_0'\vert}{\vert\bm{w}\vert}$.}
\put(31,10){$\bm{w}=m\bm{\hat{x}}-1\bm{\hat{y}}$, $w_0=b$.}
\end{picture}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{El Problema de Optimizaci\'on}

 Si $\bm{r}$ pertenece al conjunto de puntos de un lado del hiperplano 
separador en el cual se cumple
 $$
 \bm{w}\cdot\bm{r} + w_0 \ge 0,
 $$
 decimos que $\bm{r}$ pertenece a la clase $c=1$. Si $\bm{w}\cdot\bm{r} 
+ w_0 \le 0$ decimos que $\bm{r}$ pertenece a la clase $c=-1$. Por lo 
tanto, en general, se cumple que
 $$
 (\bm{w}\cdot\bm{r} + w_0)c \ge 0.
 $$
 Esto impone una ``ligadura'' a los $\bm{w}$ y $w_0$ buscados, para el 
conjunto total de datos de entrenamiento $\{\bm{r}_i\}$, $i=1,...N$.

El problema de optimizaci\'on consiste en maximizar $\bm{w}$ sujeto a 
dicha ligadura, la cual se impone mediante $N$ ``multiplicadores de 
Lagrange'' $\alpha_i$.
 $$
 L_P = 
\frac{1}{2}\bm{w}^2-\sum\limits_{i=1}^N\alpha_i[(\bm{r}_i\cdot\bm{w}+w_0)c_i-1].
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 Se debe maximizar $L_P$ respecto a los multiplicadores $\alpha_i$ y 
minimizar respecto a $\bm{w}$ y $w_0$. Eso requiere evaluar derivadas 
parciales respecto a dichas variables.
 $$
 \frac{\partial L_P}{\partial\bm{w}} = 
 0\longrightarrow\bm{w}=\sum\limits_{i=1}^N\alpha_ic_i\bm{r}_i,
 $$
 $$
 \frac{\partial L_P}{\partial w_0} = 
 0\longrightarrow\sum\limits_{i=1}^N\alpha_ic_i = 0.
 $$
 Esta \'ultima ecuaci\'on puede escribirse como $\bm{\alpha}\cdot\bm{c} 
=0$, con $\alpha_i\ge0$.

 Al reemplazar los anteriores resultados en $L_P$ se obtiene el llamado
 ``lagrangiano dual'',
 $$
 L_d = -\frac{1}{2}\sum\limits_i\sum\limits_j\alpha_i\alpha_jc_ic_j 
(\bm{r}_i\cdot\bm{r}_j) + \sum\limits_i\alpha_i.
 $$

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 Ahora debe maximizarse $L_d$ respecto a las $\alpha_i$ sujeto a las 
ligaduras $\sum_i\alpha_i\bm{r}_i = 0$ con $\alpha_i\ge0$ para todo $i$,
 $$
 \frac{\partial L_d}{\partial\alpha_k} =
 1 - \sum\limits_{i=1}^N\alpha_ic_ic_k(\bm{r}_i\cdot\bm{r}_k) = 0.
 $$
 Esta ecuaci\'on debe resolverse para las $\alpha_i$, con lo cual se 
obtendr\'an finalmente los valores buscados de los par\'ametros 
$\bm{w}$, $w_0$ y los $\alpha_i$.

 La mayor\'{\i}a de los $\alpha_i$ ser\'an cero. Est\'an asociados a los 
puntos $\bm{r}_i$ para los cuales se cumple
 $$
 (\bm{w}\cdot\bm{r}_i + w_0)c_i > 1,
 $$
 estos $\bm{r}_i$ corresponden a los datos situados m\'as lejos del 
hiperplano separador y fuera de los hiperplanos de SVM. Los datos que no 
pertenecen al conjunto de los vectores de soporte no llevan 
informaci\'on decisoria para definir el hiperplano separador.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Otras Funciones}

\texttt{trainingset = 
  Table[Delete[iris[[i]], 5] -> iris[[i]][[5]], \
  \{i, 1, Length[iris] - 1\}];}
\\
\texttt{cl = FindClusters[trainingset];
Length[cl]}
\\
\texttt{c = Classify[trainingset, Method ->  ``SupportVectorMachine'']}
\\
\texttt{ClassifierInformation[c]}
\vspace{0.5cm}
\texttt{dat3 = trainingset = 
   Table[Delete[Delete[iris[[i]], 5], 4], \{i, 1, Length[iris] - 1\}];}
\\
\texttt{cl3 = FindClusters[dat3];}
\\
\texttt{Length[cl3]}
\\
\texttt{g1 = ListPointPlot3D[cl3[[1]], PlotStyle -> \{Red\}];
g2 = ListPointPlot3D[cl3[[2]], PlotStyle -> \{Blue\}];
g3 = ListPointPlot3D[cl3[[3]], PlotStyle -> \{Green\}];
Show[g1, g2, g3, PlotRange -> All]}

 \end{frame}

%-------------------------------------------------------------------












 \section{Referencias}
 \begin{frame}{Referencias}

\begin{thebibliography}{99}

\bibitem{rojas} R. Rojas. \textit{Neural Networks\/}. Springer, Berlin, 
1996.

\bibitem{nielsen} M. Nielsen. \textit{Neural Networks and Deep 
Learning\/}. 2017, 
\texttt{http://neuralnetworksanddeeplearning.com/index.html}

 \end{thebibliography}

 \end{frame}









%-------------------------------------------------------------------
%-------------------------------------------------------------------








%-------------------------------------------------------------------
%-------------------------------------------------------------------

 \section{Algunos Ejemplos y Aplicaciones}
 \begin{frame}{Algunos Ejemplos y Aplicaciones}

 \centerline{\bf La puerta CNOT}

 \texttt{https://www.machinelearningpython.org/single-post/}\endgraf
  \hspace{1cm}\texttt{Neural-Network-Implementation}
 \texttt{https://github.com/snlpatel001213/algorithmia/blob/}\endgraf
\hspace{1cm}\texttt{ad97168585fa53bf06b4d51048ebf79baec47d03/}\endgraf
\hspace{1cm}\texttt{neuralNetwork/ANN/xor.py}

 Considera una RN con una capa de entrada y una capa oculta, ambas con 
dos unidades, y una de salida con una unidad.

\texttt{FirstMLprogram.ipynb}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{El Raspberry Pi}

 \vfill
 \centerline{\psfig{figure=PropagandaRaspberryPi.eps,width=\hsize}}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 \centerline{\bf Datos de ICS en UCI}

 \texttt{http://archive.ics.uci.edu/ml/datasets.html}

Breast Cancer. Iris. SUSY. Higgs.\\

Implementing a Neural Network from Scratch in Python - An Introduction:

 \texttt{http://www.wildml.com/2015/09/implementing-a-neural}\endgraf 
\hspace{1cm}\texttt{-network-from-scratch/}

 \texttt{https://github.com/dennybritz/nn-from-scratch}\\

A Beginner's Guide to Neural Networks with Python and SciKit Learn 
0.18!\endgraf
 \texttt{https://www.kdnuggets.com/2016/10/}\endgraf
 \texttt{beginners-guide-neural-networks-python-scikit-learn.html/2}

\centerline{\bf A visual proof that neural nets can compute any function}
\centerline{\texttt{http://neuralnetworksanddeeplearning.com/chap3.html}}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Ejemplo de ICS en UCI: Calidad del Aire}

\centerline{\bf\texttt{http://archive.ics.uci.edu/ml/datasets/Air+quality}}

 \vfill
 \centerline{\psfig{figure=SemiSupervisado-CalidadDelAire.eps,width=\hsize}}
 \centerline{}
 \vfill

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Ejemplo de ICS en UCI: La Flor Iris}

\centerline{\bf\texttt{http://archive.ics.uci.edu/ml/datasets/Iris}}

 \vfill
 \centerline{\psfig{figure=Supervisado-Iris-UCI.eps,width=\hsize}}
 \centerline{}
 \vfill
 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

 \centerline{\bf El paquete PYTORCH}

Es un paquete en python que permite c\'alculos tensoriales como numpy 
(ndarray), uso de GPU y la inclusi\'on de c\'odigo en C usando el 
cython. Tambi\'en el scipy. Es usado por Facebook y otras 
compa\~n\'{\i}as. Tiene una librer\'{\i}a completa de rutinas de ML que 
usan tanto la CPU como la GPU. Una de sus fortalezas son las 
librer\'{\i}as espec\'{\i}ficas para tarjetas gr\'aficas como NVIDIA.

Algunos otros paquetes de ML son TensorFlow (Google), Theano, Caffe 
(Facebook) y CNTK (Microsoft).

 \texttt{http://pytorch.org/tutorials/beginner/blitz/autograd\_tutorial.html}

 \texttt{http://pytorch.org/tutorials/}

 \texttt{http://pytorch.org/tutorials/beginner/pytorch\_with\_examples.html}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Introducci\'on al Pytorch}

 \texttt{https://towardsdatascience.com/getting-started-with-pytorch}\endgraf
 \hspace{1cm}\texttt{-part-1-understanding-how-automatic-differentiation}\endgraf
 \hspace{1cm}\texttt{-works-5008282073ec}

All\'{\i} se empieza haciendo una distinci\'on entre los arreglos de 
\textit{numpy} y los tensores de \textit{pytorch}:

import torch 

import numpy as np

arr = np.random.randn((3,5))

tens = torch.from\_numpy(arr)

Otros objetos de pytorch son las ``Variables'':

from torch.autograd import Variable

var\_ex = Variable(torch.randn((4,3))   \#creating a Variable

Un objeto de la clase Variable encierra un tensor. El tensor se puede 
recuperar invocando el atributo ``.data'' de una Variable.

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

Una Variable sirve para almacenar el gradiente de un escalar (por 
ejemplo la funci\'on de p\'erdida). Se accede al gradiente por medio del 
atributo ``.grad''.

Un tercer atributo que almacena una Variable es ``grad\_fn'', un objeto 
funci\'on que crea la variable.

Ver

\texttt{tensor\_tutorial.ipynb}

el cual se basa en

 \texttt{http://pytorch.org/tutorials/beginner/blitz/tensor\_tutorial.html}

Tambi\'en el notebook

\texttt{PytorchTests.ipynb}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{}

Algunos paquetes del pytorch son:

\begin{tabular}{ll}
torch & a Tensor library like NumPy, with strong GPU support\\
torch.autograd & a tape based automatic differentiation library\\
 & that supports all differentiable Tensor operations in torch\\
torch.nn & a neural networks library deeply integrated with\\
 & autograd designed for maximum flexibility\\
torch.optim & an optimization package to be used with torch.nn \\
 & with standard optimization methods such as SGD, RMSProp, LBFGS, Adam etc.\\
torch.multiprocessing & python multiprocessing,\\
 & for data loading and hogwild training.\\
torch.utils & DataLoader, Trainer and other utility functions for \\
 & convenience\\
torch.legacy(.nn/.optim) & legacy code that has been ported over\\
 & from torch for backward compatibility reasons
\end{tabular}
los cuales se discuten en,
 \texttt{https://pytorch.org/about/}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Ejemplo Para Entrenar un Clasificador}

 \texttt{https://pytorch.org/tutorials/beginner/blitz/cifar10\_tutorial.html}
 
All\'{\i} se considera el problema de reconocimiento de im\'agenes 
mediante una red neuronal con muchas capas ocultas.

El problema empieza con el entrenamiento de un clasificador. Requiere: 
Disponer de los datos de entrenamiento, definir la red neuronal, 
calcular funciones de p\'erdida y actualizar los pesos de la red.

Considera el conjunto de im\'agenes dados en CIFAR10. All\'{\i} se 
tienen las clases `avi\'on', `automobil', `p\'ajaro', `gato', `cabra', 
`perro', `rana', `caballo', `barco', `cami\'on'.

Del enlace

 \texttt{https://pytorch.org/tutorials/beginner/blitz/cifar10\_tutorial.html}

se extrae el notebook

 \texttt{EnsayoPytorchVision.ipynb}

 \end{frame}

%-------------------------------------------------------------------

 \begin{frame}{Algunos Notebooks}

 \centerline{\bf Los Notebooks de Jupyter}
 \centerline{\texttt{https://hub.mybinder.org/user/ipython-ipython-in-}}
 \centerline{\texttt{depth-mhc42hba/tree}}

 \centerline{\bf LIGO}
 \centerline{\texttt{http://nbviewer.jupyter.org/urls/losc.ligo.org/s/events/}}
 \centerline{\texttt{GW150914/GW150914\_tutorial.ipynb}}

 \centerline{\bf Ejemplos Con Pytorch}
 \centerline{\texttt{NOT.ipynb $\longrightarrow$ NOT.pdf}}
 \centerline{\texttt{PytorchTests.ipynb $\longrightarrow$ PytorchTests.pdf}}
 \centerline{\texttt{two\_layer\_net\_tensor-PyTorch.ipynb $\longrightarrow$ two\_layer\_net\_tensor-PyTorch.pdf}}
 \centerline{\texttt{CNOT.ipynb $\longrightarrow$ CNOT.pdf}}
 \centerline{\texttt{xor.ipynb $\longrightarrow$ xor.pdf}}
 \centerline{\texttt{EnsayoPytorchVision.ipynb $\longrightarrow$ EnsayoPytorchVision.pdf}}

 \end{frame}

%-------------------------------------------------------------------

 \section{Conclusiones}
 \begin{frame}{Algunas Conclusiones}

Se han estudiado algunos conceptos importantes de la teor\'{\i}a del 
aprendizaje automatizado.

Los m\'etodos llamados de ``m\'aquinas con soporte vectorial'' (SVM) 
permiten realizar la clasificaci\'on de diferentes datos.

Las llamadas ``redes neuronales'' presentan gran versatilidad, lo cual 
determina su uso en muchas aplicaciones.

Entre las aplicaciones de las redes neuronales se distinguen el 
reconocimiento de im\'agenes y el reconocimiento de voz.

Cada vez son m\'as comunes las aplicaciones en f\'{\i}sica, entre las 
cuales se destaca la determinaci\'on de propiedades de materiales basada 
en datos experimentales o en modelos te\'oricos. De una imagen de 
microscop\'{\i}a de barrido de efecto tunel, por ejemplo, es posible 
determinar ciertas propiedades del material.

 \end{frame}

%-------------------------------------------------------------------

 \section{Referencias}
 \begin{frame}{Referencias}

\begin{thebibliography}{99}

\bibitem{rojas} R. Rojas. \textit{Neural Networks\/}. Springer, Berlin, 
1996.

\bibitem{nielsen} M. Nielsen. \textit{Neural Networks and Deep 
Learning\/}. 2017, 
\texttt{http://neuralnetworksanddeeplearning.com/index.html}

 \end{thebibliography}

 \end{frame}

%-------------------------------------------------------------------

 \end{document}

%-------------------------------------------------------------------
